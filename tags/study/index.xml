<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>study on しさく</title><link>https://iimuz.github.io/scrapbook/tags/study/</link><description>Recent content in study on しさく</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Mon, 30 Dec 2019 12:14:12 +0900</lastBuildDate><atom:link href="https://iimuz.github.io/scrapbook/tags/study/index.xml" rel="self" type="application/rss+xml"/><item><title>MobileNetV2: Inverted Residuals and Linear Bottlenecks</title><link>https://iimuz.github.io/scrapbook/study/mobilenetv2/</link><pubDate>Mon, 30 Dec 2019 12:14:12 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/mobilenetv2/</guid><description> 2018.4.3: MobileNetV2: The Next Generation of On-Device Computer Vision Networks</description></item><item><title>論文</title><link>https://iimuz.github.io/scrapbook/study/paper/</link><pubDate>Mon, 30 Dec 2019 11:48:40 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/paper/</guid><description> Wikipeida: 論文</description></item><item><title>Deep Learning</title><link>https://iimuz.github.io/scrapbook/study/deep_learning/</link><pubDate>Mon, 30 Dec 2019 10:41:15 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/deep_learning/</guid><description> Wikipedia: Deep Learning</description></item><item><title>arXiv.org</title><link>https://iimuz.github.io/scrapbook/study/arxiv/</link><pubDate>Mon, 30 Dec 2019 10:34:30 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/arxiv/</guid><description> arXiv.org</description></item><item><title>Machine Learning</title><link>https://iimuz.github.io/scrapbook/study/machine_learning/</link><pubDate>Mon, 30 Dec 2019 10:34:15 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/machine_learning/</guid><description> Wikipedia: Machine Learning</description></item><item><title>TensorFlow</title><link>https://iimuz.github.io/scrapbook/study/tensorflow/</link><pubDate>Mon, 30 Dec 2019 03:20:39 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/tensorflow/</guid><description> TensorFlow.org Wikipedia: TensorFlow</description></item><item><title>Network Architecture</title><link>https://iimuz.github.io/scrapbook/study/network-architecture/</link><pubDate>Mon, 30 Dec 2019 03:16:04 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/network-architecture/</guid><description> Deep Learning のネットワークアーキテクチャ</description></item><item><title>Knowledge Distillation</title><link>https://iimuz.github.io/scrapbook/study/knowledge_distillation/</link><pubDate>Mon, 30 Dec 2019 03:11:03 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/knowledge_distillation/</guid><description>蒸留とは? Deep Learning における知識の蒸留
学習時には deep なネットワークで学習することで、精度が高くなる。 しかしながら、推論時には計算資源などの問題から軽量なネットワークを使いたい。 これには、相反する関係となっている。 軽量であるということは精度が犠牲になっている。 そこで、 deep なネットワークでの出力を模擬するような軽量なネットワークを学習する。 これにより、単純に軽量なネットワークを学習するよりも、 よい精度のモデルを学習することができる。</description></item><item><title>Generative adversarial network</title><link>https://iimuz.github.io/scrapbook/study/gan/</link><pubDate>Mon, 30 Dec 2019 02:04:48 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/gan/</guid><description> Wikipeida: Generative Adversarial Network</description></item><item><title>Dataset</title><link>https://iimuz.github.io/scrapbook/study/dataset/</link><pubDate>Mon, 30 Dec 2019 01:59:45 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/dataset/</guid><description> Wikipedia: Data set Wikipedia: List of datasets for machine learning research</description></item><item><title>feature</title><link>https://iimuz.github.io/scrapbook/study/feature/</link><pubDate>Mon, 30 Dec 2019 01:57:11 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/feature/</guid><description> Wikipedia: Feature(Machine Learning) パターン認識や機械学習の特徴量。</description></item><item><title>Point Cloud</title><link>https://iimuz.github.io/scrapbook/study/point_cloud/</link><pubDate>Mon, 30 Dec 2019 01:54:54 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/point_cloud/</guid><description>-Wikipedia: Point Cloud</description></item><item><title>Machine Vision</title><link>https://iimuz.github.io/scrapbook/study/machine_vision/</link><pubDate>Mon, 30 Dec 2019 01:47:19 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/machine_vision/</guid><description> Wikipeidia: Machine Vision</description></item><item><title>Reinforcement Learning</title><link>https://iimuz.github.io/scrapbook/study/reinforcement_learning/</link><pubDate>Mon, 30 Dec 2019 01:43:15 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/reinforcement_learning/</guid><description> Wikipedia: Reinforcement Learning</description></item><item><title>Benchmarking Model-Based Reinforcement Learning</title><link>https://iimuz.github.io/scrapbook/study/benchmarking-model-based-reinforcement-learning/</link><pubDate>Tue, 13 Aug 2019 23:34:25 +0000</pubDate><guid>https://iimuz.github.io/scrapbook/study/benchmarking-model-based-reinforcement-learning/</guid><description>論文情報 title: Benchmarking Model-Based Reinforcement Learning author: Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen, Eric Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, Jimmy Ba year: 2019/7/3 arxiv issue vanity Google Translate: vanity 比較データなど どんなものか 強化学習の 14 手法に関して、同一のデータセットを利用して性能を比較した。
Figure 3: The relative performance with different planning horizon. 先行研究と比べてどこがすごいのか 従来は、各手法で優位性を述べており、同一のデータセットで比較し、 相対的な性能の優位性を適切に述べているものがなかった。
技術や手法のキモどこか OpenAI Gym という強化学習用のデータセットを利用して、 15 の環境で評価している。 また、ノイズを加えた状態も評価している。</description></item><item><title>Cold Case: the Lost MNIST Digits</title><link>https://iimuz.github.io/scrapbook/study/cold-case-the-lost-mnist-digits/</link><pubDate>Thu, 01 Aug 2019 11:54:22 +0000</pubDate><guid>https://iimuz.github.io/scrapbook/study/cold-case-the-lost-mnist-digits/</guid><description>軽く読んだが再構成はして、評価しなおしているがデータセットが公開されているわけではないらしい。
arXiv issue vanity</description></item><item><title>ブラックホール撮影にも使えるスパースモデリングとは</title><link>https://iimuz.github.io/scrapbook/study/sparse_modeling_blackhole/</link><pubDate>Sun, 21 Apr 2019 11:17:18 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/sparse_modeling_blackhole/</guid><description>少々スパースモデリングがブラックホール撮影に使われているということで面白かったのでメモです。
ブラックホール撮影にも使える「スパースモデリング」とは？【機械学習】 要は、取得できる画像が低解像度なので高解像度にするのにスパースモデリングを使ったよということを起点としています。 この記事自体は実際に使われた手法に関して説明しているわけではなく、 スパースモデリングの基本的なことを説明しています。 Lasso を利用して下記の式を最適化しているようです。
$$ L(\bold{I}) = \parallel \bold{V} - \bold{F}\bold{I} \parallel_2^2 + \parallel \bold{I} \parallel_1 $$
$ \bold{I} $: ブラックホールの高解像度画像 $ \bold{V} $: 撮影した画像 (フーリエ変換済み) $ \bold{F} $: フーリエ変換 かなり以前から知られている範囲での説明に終わっているため、 実際には、これ以上の方法が用いられているようです。
復元結果 (引用 1) (引用 1) 本間ら「スパースモデリング天文学 ― ブラックホール撮像から時間変動減少まで」， 科学研究費補助金新学術領域研究「スパースモデリングの深化と高次元データ駆動科学の創成」 最終成果報告会 (2017/12/18-20)</description></item><item><title>三次元点群を扱うニューラルネットワークのサーベイ (ver.2)</title><link>https://iimuz.github.io/scrapbook/study/point_cloud_deep_servey/</link><pubDate>Sun, 21 Apr 2019 10:59:20 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/point_cloud_deep_servey/</guid><description>資料 資料リンク 著者などの情報 橋本、鏡研究室 どちらの方も 3 次元点群を利用する系統を研究されているようです。 産業用ロボットやプロジェクションマッピングなどを研究されています。 千葉 直也 2019/4 月現在は D3 の方</description></item><item><title>Object Recognition in 3D Scenes with Occlusions and Clustter by Hough Voting</title><link>https://iimuz.github.io/scrapbook/study/objectrecognitionin3dsceneswithocclusionsandclustterbyhoughvoting/</link><pubDate>Tue, 13 Nov 2018 13:28:54 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/objectrecognitionin3dsceneswithocclusionsandclustterbyhoughvoting/</guid><description>Abstract 2010 Fourth Pacific-Rim Symposium on Image and Video Technology
Federico Tombari, Luigi Di Stefano
In this work we propose a novel Hough voting approach for the detection of free-form shapes in a 3D space, to be used for object recognition tasks in 3D scenes with a significant degree of occlusion and clutter. The proposed method relies on matching 3D features to accumulate evidence of the presence of the objects being sought in a 3D Hough space.</description></item><item><title>Unique Signatures of Histograms for Local Surface Description (SHOT)</title><link>https://iimuz.github.io/scrapbook/study/uniquesignaturesofhistogramsforlocalsurfacedescription_shot/</link><pubDate>Tue, 06 Nov 2018 18:18:47 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/uniquesignaturesofhistogramsforlocalsurfacedescription_shot/</guid><description>Unique Signatures of Histograms for Local Surface Description (SHOT) Abstract Federico Tombari, Samuele Salti, and Luigi Di Stefano
ECCV 2010
Abstract
This paper deals with local 3D descriptors for surface matching. First, we categorize existing methods into two classes: Signatures and Histograms. Then, by discussion and experiments alike, we point out the key issues of uniqueness and repeatability of the local reference frame. Based on these observations, we formulate a novel comprehensive proposal for surface representation, which encompasses a new unique and repeatable local reference frame as well as a new 3D descriptor.</description></item><item><title>Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</title><link>https://iimuz.github.io/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/</link><pubDate>Sun, 02 Sep 2018 11:27:34 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/</guid><description>arXivTimes で見つけた論文です。 GAN を利用した異常検知技術を調べていた時に見つけました。
AnoGAN というネットワークを提案しています。 医療用画像を対象に、正常画像のみから、 GAN で学習していくようです。 このとき、 Generator は潜在空間から画像生成されると仮定します。 面白いのは、 GAN だけで完結しており、 検査時の入力画像は Auto Encoder のように再構成せず、 Generator から近い画像を生成するようにしているようです。 GAN は、潜在空間から画像は生成できるが、画像から潜在空間は変換できないはずです。 そこで、潜在空間は連続的に変化することから最初はランダムランプリングで潜在空間から画像を生成し、 近い画像へ潜在空間上を移動させるという処理を行うようです。 そのため、検査時に時間がかかる可能性はあるように思います。 また、残差誤差だけでなく、 Descriminator 側の出力も考慮して異常スコアを算出しているようです。
実装例: LeeDoYup/AnoGAN 日本語で解説してくれている記事です。 GAN による医療画像の異常検知 【論文読み】GAN を利用した異常検知まとめ その他に、論文を読んでいるときに調べながら見つけた論文 Unsupervised Adversarial Anomaly Detection using One-Class Support Vector Machines One-Class Adversarial Nets for Fraud Detection</description></item></channel></rss>