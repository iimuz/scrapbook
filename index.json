[{"categories":null,"contents":" Wikipedia: Google フォト  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/google_photos/","tags":["software"],"title":"Google Photos"},{"categories":null,"contents":" Google Compute Engine  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gce/","tags":["software"],"title":"Google Compute Engine"},{"categories":null,"contents":" Wikipedia: Google Chrome  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/chrome/","tags":["software"],"title":"Google Chrome"},{"categories":null,"contents":" Wikipedia: Google Apps Script  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gas/","tags":["software"],"title":"Google Apps Script (GAS)"},{"categories":null,"contents":" Wikipedia: Microsoft Windows  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/windows/","tags":["software"],"title":"Microsoft Windows"},{"categories":null,"contents":" Wikipedia: GPU  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/gpu/","tags":["hardware"],"title":"Graphic Processer Unit"},{"categories":null,"contents":" Wikipedia: Unity(ゲームエンジン)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/unity/","tags":["software"],"title":"Unity"},{"categories":null,"contents":" Wikipedia: Visual Studio Code  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/vscode/","tags":["software"],"title":"Visual Studio Code"},{"categories":null,"contents":" Wikipedia: Microsoft Visual Studio  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/visualstudio/","tags":["software"],"title":"Microsoft Visual Studio"},{"categories":null,"contents":" Neovim Wikipedia: Vim#Neovim  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/neovim/","tags":["software"],"title":"Neovim"},{"categories":null,"contents":" Wikipedia: Vim  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/vim/","tags":["software"],"title":"vim"},{"categories":null,"contents":" Wikipedia: Qt  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/qt/","tags":["software"],"title":"Qt"},{"categories":null,"contents":" Wikipedia: Point Cloud Library  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/point-cloud-library/","tags":["software"],"title":"Point Cloud Library"},{"categories":null,"contents":" Minecraft Wikipedia: Minecraft  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/minecraft/","tags":["software"],"title":"Minecraft"},{"categories":null,"contents":" Wikipedia: Jenkins  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/jenkins/","tags":["software"],"title":"Jenkins"},{"categories":null,"contents":" Wikiepdia: Jekyll(Software)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/jekyll/","tags":["software"],"title":"Jekyll"},{"categories":null,"contents":" Hyper  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hyper/","tags":["software"],"title":"Hyper"},{"categories":null,"contents":" Hugo  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hugo/","tags":["software"],"title":"Hugo"},{"categories":null,"contents":" Wikipedia: Homebrew(パッケージ管理システム)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/homebrew/","tags":["software"],"title":"Homebrew"},{"categories":null,"contents":" [Wikipedia: Heroku][heroku]  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/heroku/","tags":["software"],"title":"Heroku"},{"categories":null,"contents":" Wikipedia: Git  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/git/","tags":["software"],"title":"git"},{"categories":null,"contents":" Wikipedia: Google Cloud Platform  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gcp/","tags":["software"],"title":"Google Cloud Platform"},{"categories":null,"contents":" Wikipedia: Project Jupyter#Colaboratory  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/colaboratoy/","tags":["software"],"title":"Google Colaboratory"},{"categories":null,"contents":" Wikipedia: Blender  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/blender/","tags":["software"],"title":"Blender"},{"categories":null,"contents":" [GitHub.co.jp][gihtub-jp] Wikipedia: GitHub  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/github/","tags":["software"],"title":"GitHub"},{"categories":null,"contents":" Atom Wikipedia: Atom(テキストエディタ)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/atom/","tags":["software"],"title":"Atom"},{"categories":null,"contents":" Wikipedia: 画像処理  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/image_processing/","tags":["software"],"title":"画像処理"},{"categories":null,"contents":" Wikipedia: Google  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/organization/google/","tags":["organization"],"title":"Google LLC"},{"categories":null,"contents":" Python Japan Wikipedia: Python  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/python/","tags":["software"],"title":"Python"},{"categories":null,"contents":" Ruby Wikipedia: Ruby  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/ruby/","tags":["software"],"title":"Ruby"},{"categories":null,"contents":" Wikipedia: 日本電信電話  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/organization/ntt/","tags":["organization"],"title":"NTT"},{"categories":null,"contents":" 日本マイクロソフト Wikipedia: マイクロソフト  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/organization/microsoft/","tags":["organization"],"title":"Microsoft Corporation"},{"categories":null,"contents":" Preffered Networks Wikipedia: Preffered Networks  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/organization/pfn/","tags":["organization"],"title":"Preffered Networks"},{"categories":null,"contents":" Wikipedia: Docker  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/docker/","tags":["software"],"title":"Docker"},{"categories":null,"contents":" iRobot JP Wikipedia: iRobot  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/organization/irobot/","tags":["organization"],"title":"iRobot"},{"categories":null,"contents":" Wikipedia: ルンバ(掃除機)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/roomba/","tags":["hardware"],"title":"Roomba"},{"categories":null,"contents":" Oculus Wikipedia: Oculus Rift  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/oculus-rift/","tags":["hardware"],"title":"Occulus Rift"},{"categories":null,"contents":" [Apple][apple-ja] Wikipedia: アップル(企業)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/organization/apple/","tags":["organization"],"title":"Apple Inc."},{"categories":null,"contents":" Wikipedia: macbook  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/macbook/","tags":["hardware"],"title":"MacBook"},{"categories":null,"contents":" Wikipedia: Word2vec  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/word2vec/","tags":["study"],"title":"Word2Vec"},{"categories":null,"contents":" Google Cloud Functions  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gcf/","tags":["software"],"title":"Google Cloud Functions"},{"categories":null,"contents":" Google Cloud Build  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/google_cloud_build/","tags":["software"],"title":"Google Cloud Build"},{"categories":null,"contents":" Wikipedia: Kernel-based Virtual Machine  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/kvm/","tags":["software"],"title":"Kernel-based Virtual Machine"},{"categories":null,"contents":" 2018.4.3: MobileNetV2: The Next Generation of On-Device Computer Vision Networks  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/mobilenetv2/","tags":["study"],"title":"MobileNetV2: Inverted Residuals and Linear Bottlenecks"},{"categories":null,"contents":" Chiner.org 2019.12.5: Preferred Networks、深層学習の研究開発基盤をPyTorchに移行 Wikipeida: Chainer  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/chainer/","tags":["software"],"title":"Chainer"},{"categories":null,"contents":" Wikipeida: 論文  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/paper/","tags":["study"],"title":"論文"},{"categories":null,"contents":" Wikipedia: Deep Learning  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/deep_learning/","tags":["study"],"title":"Deep Learning"},{"categories":null,"contents":" arXiv.org  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/arxiv/","tags":["study"],"title":"arXiv.org"},{"categories":null,"contents":" Wikipedia: Machine Learning  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/machine_learning/","tags":["study"],"title":"Machine Learning"},{"categories":null,"contents":" TensorFlow.org Wikipedia: TensorFlow  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/tensorflow/","tags":["study"],"title":"TensorFlow"},{"categories":null,"contents":" RaspberryPi.org Wikipedia: Raspberry Pi  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/raspberrypi/","tags":["hardware"],"title":"Raspberry Pi"},{"categories":null,"contents":" Deep Learning のネットワークアーキテクチャ  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/network-architecture/","tags":["study"],"title":"Network Architecture"},{"categories":null,"contents":"蒸留とは? Deep Learning における知識の蒸留\n学習時には deep なネットワークで学習することで、精度が高くなる。 しかしながら、推論時には計算資源などの問題から軽量なネットワークを使いたい。 これには、相反する関係となっている。 軽量であるということは精度が犠牲になっている。 そこで、 deep なネットワークでの出力を模擬するような軽量なネットワークを学習する。 これにより、単純に軽量なネットワークを学習するよりも、 よい精度のモデルを学習することができる。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/knowledge_distillation/","tags":["study"],"title":"Knowledge Distillation"},{"categories":null,"contents":" Idein Inc.  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/organization/idein/","tags":["organization"],"title":"Idein Inc."},{"categories":null,"contents":" Wikipeida: Generative Adversarial Network  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/gan/","tags":["study"],"title":"Generative adversarial network"},{"categories":null,"contents":" Wikipedia: Data set Wikipedia: List of datasets for machine learning research  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/dataset/","tags":["study"],"title":"Dataset"},{"categories":null,"contents":" Wikipedia: Feature(Machine Learning) パターン認識や機械学習の特徴量。  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/feature/","tags":["study"],"title":"feature"},{"categories":null,"contents":"-Wikipedia: Point Cloud\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/point_cloud/","tags":["study"],"title":"Point Cloud"},{"categories":null,"contents":" Wikipeidia: Machine Vision  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/machine_vision/","tags":["study"],"title":"Machine Vision"},{"categories":null,"contents":" Wikipedia: Reinforcement Learning  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/reinforcement_learning/","tags":["study"],"title":"Reinforcement Learning"},{"categories":null,"contents":" docker 19.03 より rootless docker が使えるようになっていました。 幾つかの制限はあるようですが、 rootless で実際に環境構築をしてみました。\n実行環境 実行用には下記のコマンドで GCE のインスタンスを作成して利用しています。\ngcloud compute \\  instances create rootless-docker-test \\  --machine-type=n1-standard-1 \\  --subnet=default \\  --network-tier=PREMIUM \\  --no-restart-on-failure \\  --maintenance-policy=TERMINATE \\  --preemptible \\  --image=centos-7-v20190916 \\  --image-project=centos-cloud \\  --boot-disk-size=50GB \\  --boot-disk-type=pd-standard \\  --boot-disk-device-name=$INSTANCE_NAME CentOS で動かすスクリプト CentOS で最初から環境構築する場合は、下記の順に実行することで動作することを確認しました。\ncat \u0026lt;\u0026lt;EOF | sudo sh -x cat \u0026lt;\u0026lt;EOT \u0026gt; /etc/sysctl.d/51-rootless.conf user.max_user_namespaces = 28633 EOT sysctl --system EOF sudo bash -c \u0026#39;echo \u0026#34;username:100000:65536\u0026#34; \u0026gt;\u0026gt; /etc/subuid\u0026#39; sudo bash -c \u0026#39;echo \u0026#34;username:100000:65536\u0026#34; \u0026gt;\u0026gt; /etc/subgid\u0026#39; curl -fsSL https://get.docker.com/rootless | sh echo \u0026#34;export DOCKER_HOST=unix:///run/user/$(id -u)/docker.sock\u0026#34; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc ~/bin/dockerd-rootless.sh --experimental --storage-driver vfs \u0026amp; 環境構築 環境構築は、 curl -fsSL https://get.docker.com/rootless | sh で自動的に行えます。 ただし、いくつか必要な設定があるようで、設定が足りない場合は、何をしてくれということをきちんと表示してくれます。 例えば、下記のようなパターンがありました。\nsystem requirements system 上必要な作業があると下記のように実行すべきコマンドと一緒に表示されました。\n$ curl -fsSL https://get.docker.com/rootless | sh # Missing system requirements. Please run following commands to # install the requirements and run this installer again. # Alternatively iptables checks can be disabled with SKIP_IPTABLES=1 cat \u0026lt;\u0026lt;EOF | sudo sh -x cat \u0026lt;\u0026lt;EOT \u0026gt; /etc/sysctl.d/51-rootless.conf user.max_user_namespaces = 28633 EOT sysctl --system EOF 実行すると下記のようなログが出力されます。\n+ cat + sysctl --system * Applying /usr/lib/sysctl.d/00-system.conf ... * Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ... kernel.yama.ptrace_scope = 0 * Applying /etc/sysctl.d/11-gce-network-security.conf ... net.ipv4.tcp_syncookies = 1 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.all.secure_redirects = 1 net.ipv4.conf.default.secure_redirects = 1 net.ipv4.ip_forward = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.conf.default.send_redirects = 0 net.ipv4.conf.all.rp_filter = 1 net.ipv4.conf.default.rp_filter = 1 net.ipv4.icmp_echo_ignore_broadcasts = 1 net.ipv4.icmp_ignore_bogus_error_responses = 1 net.ipv4.conf.all.log_martians = 1 net.ipv4.conf.default.log_martians = 1 net.ipv4.tcp_rfc1337 = 1 kernel.randomize_va_space = 2 kernel.panic = 10 * Applying /usr/lib/sysctl.d/50-default.conf ... kernel.sysrq = 16 kernel.core_uses_pid = 1 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.all.rp_filter = 1 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.promote_secondaries = 1 net.ipv4.conf.all.promote_secondaries = 1 fs.protected_hardlinks = 1 fs.protected_symlinks = 1 * Applying /etc/sysctl.d/51-rootless.conf ... user.max_user_namespaces = 28633 * Applying /etc/sysctl.d/99-sysctl.conf ... * Applying /etc/sysctl.conf ... subuid と subgid の不足 subuid と subgid がないと言われます。 作っていないので、言われたとおりに作ります。\n# subuid の不足を指摘される curl -fsSL https://get.docker.com/rootless | sh Could not find records for the current user username from /etc/subuid . Please make sure valid subuid range is set there. For example: echo \u0026#34;username:100000:65536\u0026#34; \u0026gt;\u0026gt; /etc/subuid # subuid を作成する(sudo 権限が必要) sudo bash -c \u0026#39;echo \u0026#34;username:100000:65536\u0026#34; \u0026gt;\u0026gt; /etc/subuid\u0026#39; # subgid の不足を指摘される $ curl -fsSL https://get.docker.com/rootless | sh Could not find records for the current user username from /etc/subgid . Please make sure valid subuid range is set there. For example: echo \u0026#34;username:100000:65536\u0026#34; \u0026gt;\u0026gt; /etc/subgid # subgid を作成する(sudo 権限が必要) sudo bash -c \u0026#39;echo \u0026#34;username:100000:65536\u0026#34; \u0026gt;\u0026gt; /etc/subgid\u0026#39; インストール作業 正常にインストールできると下記のようなログが出力します。 ~/bin にバイナリがインストールされていました。\n$ curl -fsSL https://get.docker.com/rootless | sh % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 58.7M 100 58.7M 0 0 12.2M 0 0:00:04 0:00:04 --:--:-- 16.1M % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 18.0M 100 18.0M 0 0 5903k 0 0:00:03 0:00:03 --:--:-- 5905k # systemd not detected, dockerd daemon needs to be started manually ~/bin/dockerd-rootless.sh --experimental --storage-driver vfs # Docker binaries are installed in ~/bin # Make sure the following environment variables are set (or add them to ~/.bashrc):\\n export DOCKER_HOST=unix:///run/user/1001/docker.sock インストールが完了した段階で、指摘通りに export DOCKER_HOST=unix:///run/user/1001/docker.sock を .bashrc に追加します。 その後、 docker daemon を起動します。 ~/bin/dockerd-rootless.sh --experimental --storage-driver vfs\nその他 ファイルの権限 rootless docker でなければ起動時にユーザ id を指定しても、既存のフォルダをどこにでも mount 出来ました。 しかしながら、 rootless docker の場合は、 docker run の起動時に -v オプションでマウントするときに、 ユーザ id を指定していると root 権限しかないところにマウントできませんでした。\n# uid を指定するとマウント先のディレクトリが作成されていて、権限が足りていないとマウントできないと怒られる。 docker run --rm -it -v $(pwd):/src:rw -u $(id -u):$(id -g) hoge_image bash # 普通に起動できるが、内部では root 権限となる。 docker run --rm -it -v $(pwd):/src:rw hoge_image bash ただ、 docker 内では root ユーザになっていますが、 作成したファイルは daemon を起動したユーザ id でホストと共有されるようです。\n# docker 内でファイルの権限をみた場合 docker run --rm -it -v $(pwd):/src:rw ubuntu:18.04 bash touch test ls -la total 96 drwxrwxr-x. 2 root root 4096 Oct 13 05:17 . drwxrwxr-x. 3 root root 24 Oct 13 05:09 .. -rwxrwxr-x. 1 root root 189 Oct 13 05:09 test exit # ホスト側からファイルを見た場合 ls -la total 96 drwxrwxr-x. 2 hoge hoge 4096 Oct 13 05:17 . drwxrwxr-x. 3 hoge hoge 24 Oct 13 05:09 .. -rwxrwxr-x. 1 hoge hoge 189 Oct 13 05:09 test 参考資料  Docker 19.03 新機能 (root 権限不要化、GPU 対応強化、CLI プラグイン…) Rootless モードで Docker をより安全にする [DockerCon 発表レポート] Docker CE から Rootless Docker へ移行してみる on EC2  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/rootless_docker/","tags":["software"],"title":"Rootless Docker を動かす"},{"categories":null,"contents":"当初は複数のリポジトリに分割して作成していたが、 途中から単一のリポジトリでよくなる場合があります。 その場合に、複数のリポジトリの履歴を残して一つのリポジトリに統合する方法です。\n変更前には、リポジトリ A, B, C がそれぞれ別にあるとします。\n- repository A - repository B - repository C 最終的に、統合用に作ったリポジトリにリポジトリ A, B, C のフォルダと git の履歴を残すようにします。\n- repository parent |- repository A |- repository B |- repository C 下記のコマンドを順に実行することで実現できます。\n# 親リポジトリのクローン $ git clone https://example.com/username/repository_parent.git # 子リポジトリの取り込み(リポジトリ A の場合を記載するが、 B, C についても同じように行う) $ git remote add repo_a https://example.com/username/repository_a.git $ git fetch repo_a $ git read-tree --prefix=repo_a/ repo_a/master $ git checkout -- . $ git add . $ git commit -m \u0026#34;add repo_a\u0026#34; $ git merge -s subtree repo_a/master --allow-unrelated-histories 参考資料\n Qiita: 複数のGitリポジトリを一つにまとめる  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/merge_git_repositories/","tags":null,"title":"複数の git リポジトリの履歴を残して単一のリポジトリに統合する"},{"categories":null,"contents":"論文情報  title: Benchmarking Model-Based Reinforcement Learning author: Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen, Eric Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, Jimmy Ba year: 2019/7/3 arxiv issue vanity Google Translate: vanity 比較データなど  どんなものか 強化学習の 14 手法に関して、同一のデータセットを利用して性能を比較した。\n   Figure 3: The relative performance with different planning horizon.         先行研究と比べてどこがすごいのか 従来は、各手法で優位性を述べており、同一のデータセットで比較し、 相対的な性能の優位性を適切に述べているものがなかった。\n技術や手法のキモどこか OpenAI Gym という強化学習用のデータセットを利用して、 15 の環境で評価している。 また、ノイズを加えた状態も評価している。\nどうやって有効だと検証したのか 手法比較の時に特に下記の点に関して調査している。\n dynamics bottleneck the planning horizon dilemma the early-termination dilemma  議論はあるか これらの評価が適切であるかどうかを議論できるほど強化学習に関する知識がない。\n次に読むべき論文は何か 比較されている下記論文。\n Dyna-Style Algorithms  Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) Stochastic Lower Bound Optimization (SLBO) Model-Based Meta-Policy-Optimzation (MB-MPO)   Policy Search with Backpropagation through Time  Probabilistic Inference for Learning Control (PILCO) Iterative Linear Quadratic-Gaussian (iLQG) Guided Policy Search (GPS) Stochastic Value Gradients (SVG)   Shooting Algorithms  Random Shooting (RS) Mode-Free Model-Based (MB-MF) Probabilistic Ensembles with Trajectory Sampling (PETS-RS and PETS-CEM)   Model-free Baselines  Trust-Region Policy Optimization (TRPO) Proximal-Policy Optimization (PPO) Twin Delayed Deep Deterministic Policy Gradient (TD3) Soft Actor-Critic (SAC)    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/benchmarking-model-based-reinforcement-learning/","tags":["study"],"title":"Benchmarking Model-Based Reinforcement Learning"},{"categories":null,"contents":"TL;DR Google の転職エントリとして勉強内容が非常によくまとまったブログがポストされました。 読み物としてもとても楽しいのですが、勉強内容の部分だけをまとめておきます。\n作者個人の勉強 ここでは、作者の趣味に関連して行っている勉強内容に関してのみ記載します。 理由は、何を行いたいかという点に関しては、人によりけりだと思うためです。\nポーカーの戦略分析に python を使いたいという要求から勉強を始めたようです。 youtube 動画や note 記事によるアウトプットを行ったようです。\n ポーカーの勝率計算プログラム  一般化できそうな勉強内容 書籍  キタミ式イラスト IT 塾 IT パスポート キタミ式イラスト IT 塾 基本情報技術者 世界で戦うプログラミング力を鍛える本 数学ガール/乱択アルゴリズム アルゴリズム図鑑 絵で見て分かる 26 のアルゴリズム python チュートリアル 第 3 版: Kindle はないが、 O'Reilly の online store で買うことはできる。 最強最速アルゴリズマー養成講座 プログラミングコンテスト攻略のためのアルゴリズムとデータ構造 CPU の創り方: Kindle 版なし マスタリング TCP/IP 入門編 第 5 版 岩波講座 ソフトウェア科学 オペレーティングシステム: Kindle 版なし Web を支える技術 32 ビットコンピュータをやさしく語る 初めて読む 486 普通のコンパイラをつくろう     . . .                               勉強用 web サイト  System Design for Tech Interviews システム設計入門 GCI データサイエンティスト育成講座  Web での教育サイト  有料: R and python: DataCamp での自習: 4 か月 Google ML Study Jams: おそらく期間限定なため現在は利用できない picoCTF: セキュリティ系のコンテストっぽい。お試しがあれば試してみるのが良い。  プログラミングを解くサイト  Codewars: 初回: 5 級(368 points) -\u0026gt; 752 points HackerRank (Problem Solving): 初回: Silver level(200 points) -\u0026gt; 476 points  HackerRank Interview Preparation Kit を完了   Project Euler: 初回: 14 問 -\u0026gt; 55 問 AtCoder  \u0026ldquo;Atcoder の問題を分類しました\u0026rdquo; を全問終了 500 問以上の過去問 レートが水色   LeetCode  LeetCode Learn (教育用コンテンツ) を全問終了 LeetCode Problems: 100 問    個人作成物  覆面算ソルバーの作成 練習用 web サイト (HTML, CSS, Javascript, React) 英文レジュメ  資格  python エンジニア認定基礎試験  他にも下記のような試験が同一団体から提供されている。 データ分析試験    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/others/google_onsite_info/","tags":["job"],"title":"Google 入社エントリのまとめ"},{"categories":null,"contents":" スクラム開発におけるプロジェクト管理ツール比較  優良なら Jira 無料なら OpenProject   Redmine の Scrum プラグイン KPT には mindmap を使う事例もある  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/scrum_tools/","tags":["software"],"title":"スクラム開発用ツール"},{"categories":null,"contents":"memo  cloud build のトリガーを scratchpad リポジトリに対して設定する。 coudbuild.yml を利用する設定とした。  image には gcloud のほかに docker hub も指定できる。\nGCP の公式イメージは、 GitHub cloud-builders にある。\nCloud Build を使って Hugo をビルド＆デプロイする\ncloud build で複数行書く場合は下記のようにする。\n限定公開 GitHub リポジトリへのアクセス\n# Decrypt the file containing the key steps: - name: \u0026#34;gcr.io/cloud-builders/gcloud\u0026#34; args: - kms - decrypt - --ciphertext-file=id_rsa.enc - --plaintext-file=/root/.ssh/id_rsa - --location=global - --keyring=my-keyring - --key=github-key volumes: - name: \u0026#34;ssh\u0026#34; path: /root/.ssh # Set up git with key and domain. - name: \u0026#34;gcr.io/cloud-builders/git\u0026#34; entrypoint: \u0026#34;bash\u0026#34; args: - \u0026#34;-c\u0026#34; - | chmod 600 /root/.ssh/id_rsa cat \u0026lt;\u0026lt;EOF \u0026gt;/root/.ssh/config Hostname github.com IdentityFile /root/.ssh/id_rsa EOF mv known_hosts /root/.ssh/known_hosts volumes: - name: \u0026#34;ssh\u0026#34; path: /root/.ssh ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/deploy-hugo-project-using-cloud-build/","tags":["software"],"title":"Hugo でビルドした結果を Cloud Build を利用してデプロイ"},{"categories":null,"contents":"軽く読んだが再構成はして、評価しなおしているがデータセットが公開されているわけではないらしい。\n arXiv issue vanity  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/cold-case-the-lost-mnist-digits/","tags":["study"],"title":"Cold Case: the Lost MNIST Digits"},{"categories":null,"contents":"vscode の remote development 機能で git fetch origin を実行したときに以下の警告が発生した。\nperl: warning: Setting locale failed. perl: warning: Please check that your locale settings: LANGUAGE = (unset), LC_ALL = (unset), LANG = \u0026#34;en_US.UTF-8\u0026#34; are supported and installed on your system. perl: warning: Falling back to the standard locale (\u0026#34;C\u0026#34;) docker の環境で locale がうまく設定できていないようで、下記のようにすることで警告は発生しなくなった。\nsudo apt install -y --no-install-recommends locales locales-all  Can't configure locale in Docker image  失敗方法 最初は、 locale-gen などで必要なもののみ追加しようとしたが、うまくいかなかった。 下記の方法では失敗しました。\nsudo apt install locales locale-gen en_US.UTF-8  docker ubuntu /bin/sh: 1: locale-gen: not found  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/vscode/vscode-locale-error/","tags":["vscode"],"title":"VSCode の Remote development で locale 警告が発生したときの対処"},{"categories":null,"contents":"RaspberryPi の環境で cv2 の imshow 関数を利用したところ、下記のエラーが発生した。\nWARNING **: Error retrieving accessibility bus address: org.freedesktop.DBus.Error.ServiceUnknown: The name org.a11y.Bus was not provided by any .service files 対処法としては、下記のようにパッケージを追加すればよいようです。\nsudo apt-get install at-spi2-core  [solved ]Warning **: Error retrieving accessibility bus address  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/raspberrypy-cv2-dbuss-error/","tags":["hardware"],"title":"RaspberryPi で cv2.imshow を利用したときに DBUS エラーが発生した場合の対処"},{"categories":null,"contents":"$ sudo vi /etc/dhcpcd.conf interface eth0 static ip_address=192.168.10.xxx/24 static domain_name_servers=8.8.8.8  デフォルトゲートウェイはroute -nで探す  参考資料  【Raspberry Pi 3B/3B+】スタティックなIPアドレス（固定IPアドレス）を設定する  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/raspberrypi_static_ip/","tags":["hardware"],"title":"RaspberryPiで静的IPを利用する"},{"categories":null,"contents":"メモ  Google APIを利用可能にする  Get Started with REST 方法は2つ紹介されているが、今回はプロジェクトの設定なども行うため後者(B)の手法を利用した。 おそらく、こっちの方法の方がめんどくさい。  Go to the Google API Console. From the menu bar, select a project or create a new project. To open the Google API Library, from the Navigation menu, select APIs \u0026amp; Services \u0026gt; Library. Search for \u0026ldquo;Google Photos Library API\u0026rdquo;. Select the correct result and click Enable.     OAuth2認証用のjsonを取得する  今回の場合は、認証用jsonを利用してブラウザ経由でアクセス権を付与する。 ここで、アクセス権の付与にはブラウザが必要だが、今回はコンソール上に認証用のURLを出力し、 URLへは別の環境でアクセスし、認証用のtokenだけをコンソールから入力するようにしている。 これは、Raspberry Piで利用することが前提のため、UI付きの環境ではない可能性があるため。 SSHなどで入っていても対応できるようにするためです。    参考資料  [追記あり] Google Photos APIsでアルバム作成と写真のアップロード Google Photos API を使用した画像の自動アップロード nasu-tomoyuki/mugencamera  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/google_photos_api/","tags":["software"],"title":"Google Photoへの自動画像アップロード"},{"categories":null,"contents":"概要 複数プロジェクトある場合に設定を保存しておいて一括で変更する方法。\n最初だけ行うこと\n$ gcloud config configurations create hoge # hoge 設定の追加 $ gcloud config configurations activate hoge # hoge 設定に変更 # hoge 設定に設定情報を追加 $ gcloud config set compute/region asia-northeast1 $ gcloud config set compute/zone asia-northeast-a $ gcloud config set core/account hoge@example.com $ gcloud config set core/project hoge-project $ gcloud cofnig set core/disable_usage_reporting False # 設定を作った後に認証が必要なため認証は実行しておく $ gcloud auth login 設定ができてしまえば、あとは切り替えるだけ。\n$ gcloud config configurations activate hoge 参考情報  gcloud configで複数の設定を持って切り替える  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gcloud_change_account/","tags":["software"],"title":"gcloud のプロジェクト設定の変更"},{"categories":null,"contents":"概要  ディープラーニング入門  メモ  ニューラルネットワークは、部分可能な変換をつなげて作られた計算グラフである。     ニューラルネットワークのイメージ dummy      .     層は、入力層、出力層と、中間層または隠れ層からなる。 上図は、 3 層アーキテクチャとなる。 各層には、全結合型 (fully-connected)、畳み込み型 (convolutional)、再起型 (recurrent) などがある。 一つのネットワークでは、異なる層の型を用いることが普通である。  入力層近くは、 covolutional であり、出力層近くは fully-connected であったりする。   ネットワークを入力層から出力層までたどることを順伝搬と呼ぶ。 活性化関数  シグモイド関数: $ h = \\frac{1}{1 + \\exp(-u)} $  シグモイド関数は近年では、層の数が多くなると使わない。 理由は、勾配消失が発生し、学習が進行しにくくなるため。   ReLU: $ h = max(0, u) $  勾配消失問題に効くことが知られている。         シグモイド関数 ReLU           数式から実際の値を利用することなく求まる答えを解析解と呼ぶ。 繰り返し計算により数値的に求まる解を数値解と呼ぶ。 目的関数の主な種類  平均二乗誤差 交差エントロピー: $ - \\sum_k t_k \\log y_k $  全サンプルを考慮すると $ L = - \\sum_n \\sum_k t_k \\log y_k $     最適化手法  勾配降下法  勾配とは、 L を増加させる方向を示す。 最適化では、 L を減少させたいため、 - 方向へ進める。     ミニバッチ学習  複数のデータを入力し、それぞれの勾配を計算する。その後、勾配の平均値で更新する。 全体を一度の学習に使うとバッチ学習と呼ぶ。 ミニバッチを用いた学習方法を確率的勾配降下法 (stochastic gradient descent: GSD) と呼ぶ。   誤差逆伝搬法 勾配消失  シグモイド関数では、原点から離れるに従い勾配の値が小さくなる。 シグモイド関数の勾配は最大でも 0.25 となるため、 1 層深くなるたびに 0.25 倍された値になるため、 非常に小さな値となりやすい。   Chainer の基礎  パラメータを持つ関数は、 chainer.links モジュールの下にある  全層結合などの層   パラメタを持たない関数は、 chainer.functions モジュールの下にある。  シグモイド関数や ReLU 関数   softmax 関数 cross entropy chaer.functions.accuracy の計算方法は? chiner.using_config(\u0026quot;train\u0026quot;, False) は、対象のデータを使用した訓練を行わない場合に指定する chainer.using_config(\u0026quot;enable_backprop\u0026quot;, False) は、計算グラフの構築を行わない場合に指定する。   Chainer の応用  __init__() における init_scope() によって作るコンテキストの中で L.Linear を作る。 こうすることで、オプティマイザによるパラメータ更新の対象となる。 init_scope() 外で属性に代入を行っても、パラメータの更新対象にならない。 正則化項を加えた場合に重み減衰はバイアスの更新式には通常は適用しない。 chainer はパラメータ更新計算の方法を 2 つ用意している。  ネットワークが持つすべてに対して一様に更新処理を行う Optimizer オブジェクトの add_hook() パラメータ毎に別々の処理を行いたい場合に使う UpdateRule というオブジェクトにフック関数を追加する   GPU を利用する場合に気を付けること  ネットワークを to_gpu() を用いて GPU メモリ上に転送しておく ネットワークに入力するデータを CuPy の ndarray に変換しておく     トレーナ  訓練ループで行う　while 文をオブジェクトにまとめたもの エクステンションが用意されており、訓練曲線の可視化やログ保存が容易に可能である。       トレーナの概要 dummy      .     レイヤーの入力次元数を None にすると、入力されたときに決定されるようになる。 エクステンション  LogReport: 指定された周期で、レポータがレポートした値を自動的に集計し、 Trainerオブジェクトのout引数で指定したディレクトリに集計結果を json で出力する。 snapshot: トレーナオブジェクトを指定されたタイミングで保存する。 訓練済みモデルを取り出して推論だけ行いたい場合にもスナップショットをとっておく必要がある。 dump_graph: Variable オブジェクトからたどることができる計算グラフを Graphviz で描画可能な DOT 形式で保存する  例で利用している \u0026quot;main/loss\u0026quot; は L.Classifier で損失につけられている名前   Evaluator: 検証用データセットのイテレータを指定すると、訓練中の指定タイミングで検証用データセットを用いたネットワーク評価を行う PrintReport: LogReport で集計した値を標準出力する PlotReport: 指定した値を matplotlib で描画して保存する ParameterStatistics: 指定した Link が持つパラメータの平均・分散・最小値・最大値などの統計量を計算して、レポートする。  パラメータの勾配を統計量の計算対象にする場合は、 report_grasd を True にする。   詳細は 公式ドキュメント を参照のこと。   レポータで記録する値は、ネットワーク内に記述することで、規定値以外も出力可能である。  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/chainer_tutorial_chapter03/","tags":["software"],"title":"Chainer Tutorial Chapter 3: ディープラーニング入門"},{"categories":null,"contents":"概要  機械学習とデータ分析入門  メモ  単回帰分析と重回帰分析  この辺から実装が出てくると書かれている。 それぞれの実装はあるようです。 単回帰分析と重回帰分析は、ディープラーニングの基礎である。 機械学習手法は、教師あり学習、教師なし学習、強化学習に大別される。 単回帰分析は教師あり学習に分類される。 チュートリアルは大体教師あり学習だよ。 教師あり学習も、実測値を予測する回帰 (regression) と カテゴリを予測する分類 (classification) に大別される。 単回帰分析は、 1 変数を入力として、 1 変数を予測する。 重回帰分析は、多変数を入力として 1 変数を予測する。 データの前処理  平均 0 による中心化 (centering) メリットは、調整すべきパラメータを減らすことができる。 バイアス項がなくなるため単に 1 変数になる。 以降では中心化はしてある前提とする。   目的関数は二乗誤差 (sum of squares error) を利用する。 $ L = \\sum_{n=1}^N (t_n wx_n)^2 $ $ \\frac{\\partial}{\\partial w} L = - \\sum_{n=1}^N 2x_n(t_n - wx_n) $ 導関数が 0 となる点で、目的関数が最小となるため、 $ \\frac{\\partial}{\\partial w} L = 0 $ を求める。  結局 $ w = \\frac{\\sum_n x_n t_n}{\\sum_n x_n^2} $ になる。   重回帰分析: $ \\bold{y} = \\bold{w}^T \\bold{x} $  交換法則が成り立つので、 $ \\bold{y] = \\bold{x}^T \\bold{w} $ $ \\bold{y} = \\bold{X} \\bold{w} $  各列が各入力変数を表す行列 $ \\bold{X} $ をデザイン行列と呼ぶ。     目的変数: $ L = (\\bold{t} - \\bold{y})^T (\\bold{t} - \\bold{y}) $  変形すると、 $ L = (\\bold{t}^T - \\bold{w}^T\\bold{X}^T)(\\bold{t} - \\bold{X}\\bold{w}) $   導出すると $ \\bold{w} = (\\bold{X}^T \\bold{X})^{-1} \\bold{X}^T \\bold{t} $ となる。  導出には $ \\bold{X}^T \\bold{X} $ に逆行列が存在することを仮定している。 この式を正規方程式と呼ぶ。   導出で謝りやすい点として $ \\bold{X}^T $ の逆行列をかけて単位行列とするパターンがある。 $ \\bold{X} $ に逆行列が存在するためには、正方行列である必要があり、 $ \\bold{X} $ はサンプルデータと独立変数の数が一致する必要があり、 一般には成り立たない。   NumPy 入門   python の int 型は自動的に Numpy の int64 型\n  同様に float 型は Numpy の float64 型\n  要素ごとの加減乗除算は単純に +-*/ を利用する。\n  ブロードキャスト\n numpy は自動的に小さいほうの配列をブロードキャストする。 ブロードキャストは、コピーして大きい配列を用意しなくてよい点でメリットがある。 また、 c 言語実装が利用されるため高速である。 条件は、 2 つの配列の各次元が同じ大きさになっているか、どちらかが 1 であること。    行列積\n np.dot を利用する。 A.dot(B) とする。    重回帰分析の計算は、 $ \\bold{w} = (\\bold{X}^T \\bold{X})^{-1} \\bold{X}^T \\bold{t} $ で求まる。 これを numpy で求めるには下記のようにする。\nw_ = np.lialg.inv(X.T.dot(X)).dot(X.T).dot(t) ただし、上記では逆行列を陽に求めたが一般には、求めず、連立一次方程式を解くことで計算できる np.linalg.solve を用いるほうが、速度も精度もよい。\nw_ = np.lialg.solve(X.T.dot(X), X.T.dot(t)) 逆行列を求める前後を第一引数と第二引数に入れる。\n   scikit-learn 入門  データを使ってモデルを学習するまでに下記のステップが必要となる。  データセットの準備 モデルを決める 目的関数を決める 最適化手法を選択する モデルを訓練する   LinearRegression クラスは、 score() メソッドを持つ。 決定係数を取得することができる。 決定係数は、次式で算出する。 $ R^2 = 1 - \\frac{\\sum_n (t_n - y_n)^2}{\\sum_n (t_n - \\hat{t})^2} $ 値が大きいほどモデルに対する当てはめが良いことになる。 訓練データに対して、よくあてはまるパラメータとなっていても、 テストデータに対して当てはめが良くない場合は、 overfitting (過学習) と呼ぶ。 各ステップの改善  標準化: 平均 0, 分散 1 となるようにスケーリングする  scikit-learn には sklearn.processing.StandardScalar というのがある。   べき変換: sklearn.preprocessing.PowerTransformer というほうが、今回はよい結果となる。   パイプライン化   CuPy 入門  NumPy とほぼ同等の機能を GPU で利用できる。 時間計測の際は、 cu.cuda.Stream.null.synchronize() を書いておかないと、 GPU が非同期で行われるので時間計測が正しくできない。   Pandas 入門  統計量算出に describe 関数も便利だが、相関を算出する corr もある。 並べ替えは、 sort_value(by=\u0026quot;hoge\u0026quot;) で行う。 インデックスアクセスは iloc を利用する。 1 行または 1 列を要求するとシリーズオブジェクトが返る。 条件選択: df[mask]  複数条件洗濯の場合は、先に df[\u0026quot;hoge\u0026quot; \u0026gt; 10] \u0026amp; df[\u0026quot;hoge\u0026quot; \u0026lt; 100] として mask を生成する。   loc を利用すると mask と同時に 列名指定とかできる。 df.loc[mask, \u0026quot;taret\u0026quot;] = 1 欠損値の除去は dropna を利用する。 ndarray への変換は、 df.values とすればアクセスできる。   Matplotlib 入門  散布図は scatter ヒストグラムは hist 箱ひげ図は boxplot 折れ線グラフは plot seaborn を利用するときれいなグラフになる    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/chainer_tutorial_chapter02/","tags":["software"],"title":"Chainer Tutorial Chapter 2: 機械学習とデータ分析入門"},{"categories":null,"contents":"概要 準備編\n医療用のオンライン講義資料と前半部は、ほとんど一緒な気がする。 行列の参考資料も一緒だった。\nメモ  大学の学部生向け deep learning が開始できるところまで一通り網羅する予定。 Google Colaboratory の使い方説明 python の説明  チュートリアルは python 3.6 以上を対象としている。 変数宣言と代入 コメントの書き方 変数の型 エラーメッセージを読みましょう。 浮動小数点が as_integer_ratio() という関数を持つ。 これは、 0.5 という値に対して、 (1, 2) というように、 分数での分子と分母を返す。 list の説明 tuple の説明  list は mutable であり、 tuple は immutable   dict の説明  for, if, while enumerate で idx が取れるよ。 他によく使うものとして、 zip で複数のペアを作れるよ。   関数  引数の書き方 引数のデフォルト値 返り値 変数のスコープ   クラス  定義 継承     機械学習に使われる数学  教師あり学習の考え方   微分の基礎  微分は接線の傾きを求めるよ。 何気に lim が出てくるよ。 簡単な微分の公式 線形性の説明 合成関数の微分。要は、一時変数を置いて、 2 回微分する。 偏微分   線形代数の基礎  スカラー、ベクトル、行列、テンソル 加算、減算、スカラー倍 内積 行列積  高校くらいで習う積の計算。 その他に、外積、要素積 (アダマール積) などがある。   転置 単位行列 逆行列  逆行列が存在すれば正則行列である。   線形結合と二次形式  線形結合: $ \\bold{b}^T \\bold{x} $ 二次形式: $ \\bold{x}^T \\bold{A} \\bold{x} $   ベクトルの微分 合成関数の微分 (ベクトルバージョン)   確率と統計の基礎  確率変数と確率分布 同時確率: $ p(X=x, Y=y) $ 周辺化: $ p(Y=y) = \\sum_x p(X=x, Y=y) $ 条件付き確率: $ p(Y=y | x) $ ベイズの定理: $ p(y, x) = p(y | x) p(x) $  $ p(x) $: 事前確率 $ p(y | x) $: 事後確率   尤度と最尤推定  対数尤度: $ L(\\theta) = \\prod_{i=1}^N f(x_i; \\theta)$   コイントスのパラメータ推定 Maximum a posteiori(MAP) 推定  事前確率を定義し、事前条件を有効にすることで効果的な推定を行う   統計量  平均 分散  不偏分散 ($ n-1 $ で割る) と標本分散 ($ n $ で割る)   標準偏差 相関係数: $ r = \\frac{E[(X - \\mu_x)(Y - \\mu_y)]}{\\sqrt{(E[(X - \\mu_x)^2(Y - \\mu_y)^2])}} $  相関の有り無しは、無相関検定などの手法が必要となる。        ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/chainer_tutorial_chapter01/","tags":["software"],"title":"Chainer Tutorial Chapter 1: 準備編"},{"categories":null,"contents":"候補  パナソニック NA-VX9900L: 2018/10 243,728  パナソニック NA-VX9900:   パナソニック 斜めドラム式洗濯機 Cuble NA-VG2300 日立 ビッグドラム BD-SX110CL: 2018/9 159,500  日立アプライアンス ビッグドラム BD-NX120C   東芝 ZABOON TW-127V7L: 2018/9 154,854  東芝 ライフスタイル ZABOON TW127X7   シャープ ES-W111-SL: 2018/11 208,591  コンパクトタイプ  シャープ コンパクトドラム ES-S7C-WL: 2018/2 129,800 パナソニック Cuble NA-VG730L: 2018/11 170,700 日立アプライアンス ビッグドラム BD-SG100CL: 2018/9 132,800  《2019年》洗濯機おすすめ10選！乾燥機能、洗浄力が強いドラム式・縦型の“買い”はこれ!! 《2019年》洗濯機おすすめ10選！乾燥機能、洗浄力が強いドラム式・縦型の“買い”はこれ!!\n ドラム式の方が使用する水は少ないが、縦型の方が泥などは落とせる。 縦型の方が最上位モデルで 5 ~ 8 万円安い。 ドラム式には乾燥機能がある。 乾燥時間や電力使用量がドラム式の方が少なくて済む。 一般人で一日に発生する洗濯物の量は 1.5kg となる。 そのため、 1.5 kg x 人数 が一日に出る洗濯物の量。 シーツや毛布を洗うならば 8kg くらいあると安心できる。 糸くずフィルタや乾燥フィルタの手入れのしやすさは大事。 乾燥方式に違いがある。  ヒートポンプ乾燥式とヒート乾燥式 ヒートポンプ乾燥式の方が便利。消費電力が抑えられる。  年間換算でヒートポンプ乾燥式の方が 1 日 1 回使うと 1 万円くらい抑えられる。 ヒートポンプ方式の方が低めの温度で乾かすため衣類へのダメージが少ない     パナソニック NA-VX9900L  洗剤と柔軟剤の自動投入機能付き   日立 ヒートサイクル 風アイロン ビッグドラム BD-SX110CL  風アイロンはしわのない仕上がりが期待できる。 BD-NX120CL、BD-NV120CL、BD-SX110CL、BD-SV110CL、BD-SG100CL あたりのモデルもある。   東芝 ZABOON TW-127V7L シャープ ES-W111  乾燥フィルターの自動お掃除機能  週に一回だけたまったゴミを捨てるだけになるらしい。      洗井家にドラム式洗濯機がやってきた 洗井家にドラム式洗濯機がやってきた\n漫画でパナソニックのドラム式洗濯機を広告している。\nおすすめドラム式洗濯乾燥機5選｜家電ライターに取材 おすすめドラム式洗濯乾燥機5選｜家電ライターに取材\n パナソニック 斜めドラム式洗濯機 NV-VX9900 日立アプライアンス ビッグドラム BD-NX120C シャープ プラズマクラスター 洗濯乾燥機 ES-W111 東芝 ライフスタイル ZABOON TW127X7 パナソニック 斜めドラム式洗濯機 Cuble NA-VG2300  アパートなどにおけるコンパクトタイプ\n シャープ コンパクトドラム ES-S7C パナソニック Cuble NA-VG730 日立アプライアンス ビッグドラム BD-SG100C  タテ型洗濯機からドラム式洗濯乾燥機に変えたお話 タテ型洗濯機からドラム式洗濯乾燥機に変えたお話\n個人の家庭でドラム式に変更したときのお話。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/washing_machine/","tags":["hardware"],"title":"洗濯機の比較"},{"categories":null,"contents":"概要 Google が提供している学習サイトです。 Machine Learning 関連以外にもあり、結構広範な内容をカバーしています。 働き方改革、 YouTuber 向けなどがありました。\n Glow with Google JP Glow with Google  Machine Learning Machine Learning 関連に関しては 2 コース用意されています。 初心者と中級者に分かれているのですが、中級者の方はほとんどのコースが英語のみになっています。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/grow_with_google/","tags":["software"],"title":"Grow with Google"},{"categories":null,"contents":"メモ  github.com/gohugoio/hugoBasicExample 公式 Theme の作り方 github.com/vjeantet/hugo-theme-docdock Hugoのテーマを何個か作ったので知見をまとめてみる  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hugo_create_theme/","tags":["software"],"title":"Hugo の Theme 作成"},{"categories":null,"contents":"リンク  2. 機械学習ライブラリの基礎  メモ ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/medical-ai002/","tags":["software"],"title":"2. 機械学習ライブラリの基礎"},{"categories":null,"contents":"概要  5. 実践編: MRI画像のセグメンテーション  メモ  画像セグメンテーションには2種類ある。  Instance-aware Segmentation: 個別の物体を区別する Semantic Segmentation: 同一物体クラスであれば個を区別しない    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/medicalai_chap5/","tags":["software"],"title":"5. 実践編: MRI画像のセグメンテーション"},{"categories":null,"contents":"リンク  1. 機械学習に必要な数学の基礎  メモ 大体は、覚えている範囲で済んでいます。 ただ、公式系は結構忘れています。あとは、たまに導出をやってみると意外と思い出す感じです。\n 機械学習は関数のパラメータ決定である。  ex.) $ f(x; a, b) = ax + b $ ex.) $ L(\\theta) = \\sum_{n=1}^N (y_i - f(x_i; \\theta))^2 $   テンソルは、ベクトルや行列の一般化概念である。  1 階テンソル = ベクトル 2 階テンソル = 行列   逆行列が存在する = 正則行列 $ \\bold{b}^T \\bold{x} $: 線形結合 $ \\bold{x}^T \\bold{A} \\bold{x} $: 二次形式 ベクトル微分  $ \\frac{\\partial}{\\partial \\bold{x}}( c ) = 0 $ $ \\frac{\\partial}{\\partial \\bold{x}}(\\bold{b} \\bold{x}) = \\bold{b} $ $ \\frac{\\partial}{\\partial \\bold{x}}(\\bold{x}^T \\bold{A} \\bold{x}) = (\\bold{A} + \\bold{A}^T)\\bold{x} $    memo dummy      .       行列をかけた場合のヤコビ行列は、その転置となることが多い。 行列計算の参考資料: Matix Cookbook さらに詳しい参考資料: Arxiv: The Matrix Calculus You Need For Deep Learning 尤度: 事象 u の尤度: $ p(x=u; \\theta) $ 最尤推定では下記のようなパラメータ $ \\theta $ を求める。 ただし、 $ \\log $ は、対数とすることで極端に値が小さくなることを防いでいる。  $ L(\\theta) = p(X; \\theta) = \\prod_{i=1}^N p(x^{(i)}; \\theta) $ $ \\arg\\max_{\\theta} \\log L(\\theta) $   懐かしの MAP 推定  要はベイズの定理に則り、事前確率にあらかじめわかっている情報を載せることで、 ただ最尤推定するよりも良いパラメータを探索する。   標本分散と不偏分散  要は、母集団に対する分散を求める場合は不偏分散であり、 サンプリングした標本集団に対する分散を求める場合は標本分散を用いる。   正規分布  $ \\mu + \\sigma $ で 68.3 % $ \\mu + 2 \\sigma $ で 95.4 % $ \\mu + 3 \\sigma $ で 99.7 %   外れ値除去  正規分布を仮定して、 $ \\mu + 3 \\sigma $ 以上の値を外れ値とする。 外れ値に影響を受けて $ 3 \\sigma $ が大きくなるような場合は、 ±5% の値を削除などをする。    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/medical-ai001/","tags":["software"],"title":"1. 機械学習に必要な数学の基礎"},{"categories":null,"contents":"少々スパースモデリングがブラックホール撮影に使われているということで面白かったのでメモです。\n ブラックホール撮影にも使える「スパースモデリング」とは？【機械学習】  要は、取得できる画像が低解像度なので高解像度にするのにスパースモデリングを使ったよということを起点としています。 この記事自体は実際に使われた手法に関して説明しているわけではなく、 スパースモデリングの基本的なことを説明しています。 Lasso を利用して下記の式を最適化しているようです。\n$$ L(\\bold{I}) = \\parallel \\bold{V} - \\bold{F}\\bold{I} \\parallel_2^2 + \\parallel \\bold{I} \\parallel_1 $$\n $ \\bold{I} $: ブラックホールの高解像度画像 $ \\bold{V} $: 撮影した画像 (フーリエ変換済み) $ \\bold{F} $: フーリエ変換  かなり以前から知られている範囲での説明に終わっているため、 実際には、これ以上の方法が用いられているようです。\n   復元結果 (引用 1)          (引用 1) 本間ら「スパースモデリング天文学 ― ブラックホール撮像から時間変動減少まで」， 科学研究費補助金新学術領域研究「スパースモデリングの深化と高次元データ駆動科学の創成」 最終成果報告会 (2017/12/18-20)\n ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/sparse_modeling_blackhole/","tags":["study"],"title":"ブラックホール撮影にも使えるスパースモデリングとは"},{"categories":null,"contents":"Speaker Deck の Embed リンクをそのまま利用すると、 横幅を全て使うようにスライドが埋め込まれます。 その結果、非常に巨大な資料が埋め込まれる場合があります。 資料のサイズは、親の要素に影響を受けているようですので、 下記のように div 要素でサイズを指定して囲むことでサイズ指定が可能となります。\n\u0026lt;div style=\u0026#34;width: 50%\u0026#34;\u0026gt; \u0026lt;script async class=\u0026#34;speakerdeck-embed\u0026#34; data-id=\u0026#34;55cac880f4d34c31b145afeffba11a77\u0026#34; data-ratio=\u0026#34;1.33333333333333\u0026#34; src=\u0026#34;//speakerdeck.com/assets/embed.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;div\u0026gt; 資料は、ちょうど読んでいたスライドを使わせていただいております。\nサイズ指定しない場合の埋め込み \u0026lt;script async class=\u0026#34;speakerdeck-embed\u0026#34; data-id=\u0026#34;55cac880f4d34c31b145afeffba11a77\u0026#34; data-ratio=\u0026#34;1.33333333333333\u0026#34; src=\u0026#34;//speakerdeck.com/assets/embed.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; サイズ指定した場合の埋め込み \u0026lt;div style=\u0026#34;width: 50%\u0026#34;\u0026gt; \u0026lt;script async class=\u0026#34;speakerdeck-embed\u0026#34; data-id=\u0026#34;55cac880f4d34c31b145afeffba11a77\u0026#34; data-ratio=\u0026#34;1.33333333333333\u0026#34; src=\u0026#34;//speakerdeck.com/assets/embed.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;div\u0026gt; ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/speaker_deck_slide_size/","tags":null,"title":"Speaker Deck のスライド埋め込み (Embed) でサイズ指定"},{"categories":null,"contents":"資料  資料リンク  著者などの情報  橋本、鏡研究室  どちらの方も 3 次元点群を利用する系統を研究されているようです。 産業用ロボットやプロジェクションマッピングなどを研究されています。   千葉 直也  2019/4 月現在は D3 の方    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/point_cloud_deep_servey/","tags":["study"],"title":"三次元点群を扱うニューラルネットワークのサーベイ (ver.2)"},{"categories":null,"contents":"主要リンク  オンライン資料 GitHub  メモ  前半は、 chainer tutorials と一緒で読み物になっています。  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/medical_ai/","tags":["software"],"title":"Medical AI 専門コース オンライン講義資料"},{"categories":null,"contents":"セル操作  Markdownモードへ変更: Ctrl + M → M Codeモードへ変更: Ctrl + M → Y セルの実行: Shift + Enter セルを上に追加: Ctrl + M → A セルを下に追加: Ctrl + M → B セルのコピー: Ctrl + M → C セルの貼り付け: Ctrl + M → V セルの消去: Ctrl + M → D コメントアウト: Ctrl + /  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/colab_cheatsheet/","tags":["software"],"title":"Google Colaboratory のチートシート"},{"categories":null,"contents":"主要リンク  Chainer Tutorials Chainer Tutorials の Github  メモ  google colaboratory を利用する前提で進められています。 初学者向けであることが強調されています。 前半は、ほぼ読み物のようです。通勤時間にでも読むようにします。  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/chainer_tutorial/","tags":["software"],"title":"Chainer Tutorial"},{"categories":null,"contents":"DCGAN で MNIST 以外を動かすとしたらどういうデータがありそうか調査。 本当は、最終的に Style GAN で適当な画像を入れたら、 それのアイコン(漫画チック)な画像を生成するようにしたい。\narXiveTimes がまとめているデータセット一覧\n 日本語の崩し文字: MNIST の日本語版みたいな感じか。 The Art Institute of Chicago THE COLLECTION: シカゴ美術館の絵画などの画像。絵画以外も入っている。 Painter by Numbers(PBN): 36GB くらいあるが絵画の画像が手に入るっぽい。 Kaggle データ。 How Do Humans Sketch Objects? (TU-Berlin dataset): スケッチ画像が載っています。 Manga109: 漫画データのようです。 ただし、利用にあたり学術目的のみであり、引用元の表記などが必要になるようです。 AnimeFace Character Dataset アニメの顔画像を集めたデータセット。 LLD - Large Logo Dataset: GAN を想定しているデータセットとのこと。 favicon のような画像を集めています。 Favicons: Kaggle のデータセットで favicon の寄せ集め。 Cartoon Set 2 次元のアバターイメージのデータセット。  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/training_data_dcgan/","tags":["machine learning","dataset"],"title":"DCGAN のためのデータセット調査"},{"categories":null,"contents":"万葉で必須とされるRuby on Railsと その周辺技術の基礎を習得するための新入社員教育用カリキュラムです。\n el-training  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/el_training/","tags":["software"],"title":"Ruby on Rails の基礎習得するための教材 el-training"},{"categories":null,"contents":"CUDA の atomic 関数では、 CUDA Kernel 内において、 他のスレッドとは排他的に読み書き処理が可能となります。 atomicAdd や atomicSub などの基本的な関数は一通り用意されています。\nただし、 公式ドキュメント には、注意点として下記が書かれています。\n Atomic functions do not act as memory fences and do not imply synchronization or ordering constraints for memory operations\n Memory funces や同期、制御順に関する制約は行わないです。\n Atomic functions can only be used in device functions.\n atomic 関数は、デバイス関数の中でのみ有効となります。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/cuda/cuda_atomic_function/","tags":["cuda"],"title":"CUDA の atomic 関数"},{"categories":null,"contents":"Module Introduction ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/coursera_gcp002/","tags":["software"],"title":"Chapter 2"},{"categories":null,"contents":"WSL 環境で突然に curl が通じなくなって、下記エラーが出ました。 直前まで使えていたので、理由が分からずだったので調べました。\ncurl: (6) Couldn\u0026#39;t resolve host \u0026#39;www.google.co.jp\u0026#39; 調べたところ、 /etc/resolv.conf の nameserver がおかしくなっていたようです。 下記の行を追加したところ、正常に curl が使えるようになりました。\nnameserver 8.8.8.8 8.8.8.8 は Google Public DNS です。 上記以外でも有効な DNS を指定すれば動作します。\n再起動の方法は、 sudo netplan apply でできます。\nUbuntu 18.04 Server の場合 Ubuntu 18.04 Server の場合は、 /etc/resolv.conf には記載しておらず、 /etc/system.d/resolved.conf に下記のように記載する必要があります。\n[Resolve] DNS=8.8.8.8 そして再起動の方法は、 systemctl restart systemd-resolved になります。\n/etc/resolv.conf を修正した場合 WSL のように /etc/resolv.conf を修正し、 sudo netplan apply を利用した場合は、 設定をしても自動で書き換えられるため、有効な設定になりませんでした。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/bash/curl_cloud_not_resolve_host/","tags":["bash"],"title":"curl で Cloudn't resolve host エラーが出た時の対処法"},{"categories":null,"contents":"Visual Studio 2010 でデバッグ実行時に例外が発生したときに、 発生した時点で中断する設定です。 例外は発生したところがわからないとデバッグしにくく調べました。\n\u0026ldquo;デバッグ\u0026rdquo; -\u0026gt; \u0026ldquo;例外\u0026rdquo; をクリックし、 出てきたウィンドウでチェックを ON にすれば例外発生時に中断できます。\n   例外設定画面         ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/visualstudio/debugexception/","tags":["software"],"title":"VS2010 のデバッグ時に例外発生時で中断する方法"},{"categories":null,"contents":"Introducing Google Cloud Platform ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/coursera_gcp001/","tags":["software"],"title":"Chapter 1"},{"categories":null,"contents":" course  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/coursera_gcp/","tags":["software"],"title":"Google Cloud Platform Fundamentals: Core Infrastructure"},{"categories":null,"contents":"概要 Nikkei Robotics 2019/3 において、RasPiZero で Mobilenet v2 の 10fps を実現できたことの紹介。 日本の Idein というベンチャー企業が成し遂げた。 これにより、 1000 円前後の環境で物体認識ができるということになり、エッジデバイスの単価が下がっている。 実現のためには、 RasPi に搭載している GPU を利用できるように、独自の RasPi 用の GPU ライブラリを作成し利用している。\nトピック  全ての RasPi は GPU Broadcom 社製 VideoCore を標準搭載 VideoCore は 24 ～ 28.8[GFLOPS]と最新のスマホの 1/10 以下とはいえ初代 XBox よりは高速 RasPi の大ヒットを受けて 2014 年に Broadcom 社が仕様書を公開 日ベンチャー Idein 社は仕様書を読み込み VideoCore ハードウェアからソフトウェアスタックを積み上げ TensorFlow および Chainer で叩ける【VideoCore 版 CUDA のようなもの】を内製 VideoCore の DL 実行効率は 40%に達し 1GB のメインメモリに展開できるモデルならだいたい現実的な速度で叩けるらしい  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/dl_time_raspizero_mobilenet_10fps/","tags":["software"],"title":"600円のRasPiZero【単体で】Mobilenetv2 1000 class object detection【10fps弱】を達成"},{"categories":null,"contents":"GAS を使うべきか否かの判断材料 GAS を使うべきか否かの判断材料\n選択する理由\n Google サービスへのアクセス  Google Calendar Spread Sheet Google Drive Admin Directory (G Suite 限定)   定期実行 開発環境の準備が不要  エディタとバージョン管理の問題から、結局ローカル管理 (clasp?) を利用したくなる。    あきらめたほうがいい理由\n 処理時間が 6 分を超える場合 大量の処理をする必要がある  Google Apps Script Quotas トリガーの実行時間は 90 min / day  処理時間が 1 回で 5 分とすると 18 回のみ   UrlFetch の実行時間は無料アカウントの場合で 20,000 回 / day   大容量のデータを扱う  体感的には 40 ~ 50 MB あたりが限界のようです。   複数人開発がしにくい  結局 clasp で git 管理にして対応する必要がありそう。   複数人トリガーの管理  G Suite とかだと関係してくるようです。   複数人での Web アプリケーション公開設定の管理 ローカルファイルへのアクセス  GAS でよくはまる制約まとめ GAS でよくはまる制約まとめ\n上記に Quotas の日本語まとめのようなものが載っています。\n複数のユーザがアクセスする場合を想定した書き方 GASを用いた簡単Twitterアプリケーション for Web\nTwitter API を利用した例ですが、 アクセスする人ごとに認証を行い、結果を保持しておく機能が紹介されています。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gas_survey/","tags":["software"],"title":"Google Apps Script (GAS) の調査"},{"categories":null,"contents":" Circle CI で Cloud Function をデプロイする Circle CI で Cloud Function をデプロイする\nCircle CI を利用した方法ですが、 GCF のデプロイ方法が載っています。 GitHub から Circle CI で Google Cloud Source Repository へ push し、 その結果から GCF でデプロイすることになっているようです。\nGoogle Cloud Functions(Beta)の基本的な仕組み、使い方を学ぶ Google Cloud Functions(Beta)の基本的な仕組み、使い方を学ぶ\nCloud Functions のデプロイ方法を学ぶために利用しました。 とりあえず、初めて Cloud Functions をデプロイしてみました。\nhttps://hogehoge.cloudfunctions.net/gcf-deploy-sample\n上記 URL でデプロイされたようです。\ncurl https://hogehoge.cloudfunctions.net/gcf-deploy-sample とすることで Hello World と表示されることを確認しました。 また、 gcloud コマンドを利用しても呼び出せることを確認しました。\ngcloud functions call gcf-deploy-sample --region asia-northeast1 記事では、 beta 関数となっていますが、現在は既に通常レベルに公開されているようです。 あと、 region を付けないと authrized されている環境でも us-east あたりの region を確認しに行っていました。\ngcloud 関数を利用したデプロイ ソースコードをコピーしてきて、 git 環境下で管理を始めました。 そして、 gcloud コマンドを利用してデプロイ関数の更新が出来るかチェックしています。\ngcloud functions deploy gcf-deploy-sample --verbosity debug --region asia-northeast1 上記関数も同様にデフォルトの region が us-east1 あたりなので、 region を付与してあげる必要がありました。 そうしないと、新規関数を作ろうとして引数が足りないと怒られます。\nDEBUG: Running [gcloud.functions.deploy] with arguments: [--verbosity: \u0026#34;debug\u0026#34;, NAME: \u0026#34;gcf-deploy-sample\u0026#34;] DEBUG: (gcloud.functions.deploy) One of arguments [--trigger-topic, --trigger-bucket, --trigger-http, --trigger-event] is required: You must specify a trigger when deploying a new function. Traceback (most recent call last): File \u0026#34;/usr/lib/google-cloud-sdk/lib/googlecloudsdk/calliope/cli.py\u0026#34;, line 987, in Execute resources = calliope_command.Run(cli=self, args=args) File \u0026#34;/usr/lib/google-cloud-sdk/lib/googlecloudsdk/calliope/backend.py\u0026#34;, line 795, in Run resources = command_instance.Run(args) File \u0026#34;/usr/lib/google-cloud-sdk/lib/surface/functions/deploy.py\u0026#34;, line 191, in Run return _Run(args, track=self.ReleaseTrack()) File \u0026#34;/usr/lib/google-cloud-sdk/lib/surface/functions/deploy.py\u0026#34;, line 73, in _Run trigger_util.CheckTriggerSpecified(args) File \u0026#34;/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/functions/deploy/trigger_util.py\u0026#34;, line 75, in CheckTriggerSpecified \u0026#39;You must specify a trigger when deploying a new function.\u0026#39; OneOfArgumentsRequiredException: One of arguments [--trigger-topic, --trigger-bucket, --trigger-http, --trigger-event] is required: You must specify a trigger when deploying a new function. ERROR: (gcloud.functions.deploy) One of arguments [--trigger-topic, --trigger-bucket, --trigger-http, --trigger-event] is required: You must specify a trigger when deploying a new function. gcloud コマンドでデプロイした場合は、自動的に .gcloudignore を生成し、 .git を無視するように設定するようです。\ntravis ci からの gcloud deploy travis ci からデプロイするためにサービスアカウントを用意し、権限を付与しました。 付与した権限は下記になります。\n cloud functions 開発者 Service Account User  こっちは、サービスアカウントのところから情報パネルを表示し、 新しいメンバーにサービスアカウントを追加して、 役割のところから追加する必要があります。 設定方法    travis ci の gcloud バージョンが古すぎる なぜか Travis CI の gcloud が 176.0.0 を利用しています。 現時点での最新バージョンは 232.0.0 なので使えないコマンドが多くて当然です。 強制的にインストールして変わるか確認します。\n Travis 環境下での gcloud の更新方法 Travis CI + google-cloud-sdk + updated kubectl + Docker  Google Cloud Source Repository からのデプロイ URL Cloud Source Repository の URL を設定する場合は下記のようにする必要がある要で鵜s。\nhttps://source.developers.google.com/projects/${PROJECT}/repos/${REPO} ただ、上記だと失敗する場合もあったので、 master を見る場合でも下記の方がいいかもしれません。\nhttps://source.developers.google.com/projects/${PROJECT}/repos/${REPO}/moveable-aliases/master/paths// 最後のスラッシュ 2 個は、パス指定を削除はできないらしいので、 ルートを指定しているということでブランクで設定しています。\nCloud Container Builder google の CI ツール Container Builder からデプロイしたほうがいいような気がしてきました。\ngensim のモデルデータ モデルデータが重すぎて cloud functions にアップロードできない。 とりあえず storage をベースに利用できるか調べる。\nCan a Cloud Function read from Cloud Storage?\nvar storage = require(\u0026#39;@google-cloud/storage\u0026#39;); const gcs = storage({projectId: \u0026#34;\u0026lt;your_project\u0026gt;\u0026#34;}); const bucket = gcs.bucket(\u0026#34;\u0026lt;your_bucket\u0026gt;\u0026#34;); const file = bucket.file(\u0026#34;\u0026lt;path/to/your_file\u0026gt;\u0026#34;) exports.gcstest = (event, callback) =\u0026gt; { file.download({destination:\u0026#34;/tmp/test\u0026#34;}, function(err, file) { if (err) {console.log(err)} else{callback();} }) }; python を利用して storage から読み込んでいるっぽい例。\nGetting Started with Python for Google Cloud Functions\nfrom wand.image import Image from google.cloud import storage client = storage.Client() THUMBNAIL_BUCKET = \u0026#39;\u0026lt;your thumbnail bucket\u0026gt;\u0026#39; def make_thumbnail(data, context): # Get the file that has been uploaded to GCS bucket = client.get_bucket(data[\u0026#39;bucket\u0026#39;]) blob = bucket.get_blob(data[\u0026#39;name\u0026#39;]) imagedata = blob.download_as_string() # Create a new image object and resample it newimage = Image(blob=imagedata) newimage.sample(200,200) # Upload the resampled image to the other bucket bucket = client.get_bucket(THUMBNAIL_BUCKET) newblob = bucket.blob(\u0026#39;thumbnail-\u0026#39; + data[\u0026#39;name\u0026#39;]) newblob.upload_from_string(newimage.make_blob()) requirements.txt\ngoogle-cloud-storage Wand google 公式のストレージへのアクセス\nオブジェクトのダウンロード\ndef download_blob(bucket_name, source_blob_name, destination_file_name): \u0026#34;\u0026#34;\u0026#34;Downloads a blob from the bucket.\u0026#34;\u0026#34;\u0026#34; storage_client = storage.Client() bucket = storage_client.get_bucket(bucket_name) blob = bucket.blob(source_blob_name) blob.download_to_filename(destination_file_name) print(\u0026#39;Blob {} downloaded to {}.\u0026#39;.format( source_blob_name, destination_file_name)) モデルデータ 当初持っていた word2vec のモデルは重すぎるので利用できないです。 幾つか調べたところ、 ここ で幾つかの公開モデルを列挙していました。 白ヤギコーポレーション のモデルは小さいので使えそうです。 解凍してみたところ 25MB 以内というところでした。\ncloud function で python を利用して json を返す How to I return JSON from a Google Cloud Function\nfrom flask import jsonify def my_function(request): data = ... return jsonify(data) requirements.txt\nflask==1.0.2 Flaskのjsonify によると jsonify を使うときは、 dict で作らないとダメと書かれていました。 ただ、実際のところは別のエラーがかかわっていた可能性があり、不明です。\ncore error ブラウザで受けようとすると一部で追加しないといけないフラグがあったようです。\n Google Cloud Functionsでcorsを有効にする。 Google Cloud FunctionsにPython3.7が追加されてる件  参考資料  Qiita: CircleCIでmasterにmergeされた場合のみビルドしたバイナリをCloud Source Repositoresへpushする  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gcf-continuous-deploy/","tags":["software"],"title":"Google Cloud Functions に Travis CI からデプロイする"},{"categories":null,"contents":"kvm で構築し GPU Passthrough した windows 環境で、 OpenGL を利用したソフトウェアを動かしました。 そのとき、 Spice というリモート接続するソフトウェアを利用したのですが、 windows 版のインストーラのダウンロード方法が分かりにくかったので、メモしておきます。\nwindows の SPICE クライアントインストールは、なぜか virt viewer のインストールで行います。 (わかる人には分かるのでしょうが、インストールも SPICE Client とかの名称なら直感的に分かったのですが。) virt viewer というソフトウェアがそのまま spice のクライアントになります。 そのため、インストールには下記の手順でたどった先のファイルをダウンロードする必要があります。\n SPICE へ行く \u0026ldquo;Download\u0026rdquo; を開く 下記画像中(SPICE ダウンロードページ)の \u0026ldquo;virt-manager download page\u0026rdquo; を開く 下記画像中(Virt Manager ダウンロードページ)の \u0026ldquo;Win64 MSI\u0026rdquo; をクリックしてダウンロード     SPICE ダウンロードページ Virt Manager ダウンロードページ          ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/install-spice-win/","tags":["software"],"title":"Windows に SPICE のクライアントをインストールする"},{"categories":null,"contents":"Qt Creator を利用した場合にリモートデバッグを行うこと自体は公式に方法がああります。\nLaunching the Debugger\nサンプルの OpenGL を利用していると思われるプロジェクトでリモートデバッグできることを確認しました。 下記のような用語を用いるとします。\n ホスト PC: 開発した exe を実行する PC  exe の実行に必要なバイナリやインストールのみを実行   サーバ PC: 開発用環境を構築した PC  ビルドするために QtCreator や Visual Studio をインストール    事前条件として下記の作業を行っています。\n ホスト PC  Visual Studio Professional 2013 Update5 のインストール QtCreator 5.6.4 のインストール Windows SDK のインストール(他のチェックボックスはすべて外しています。)   サーバ PC  Windows SDK の Remote Debugger ツールをインストール(他のチェックボックスはすべて外しています。) サーバ PC の qtcreatorcdbext.dll (32bit or 64bit) を任意のディレクトリ (qtlib) へコピー    その上で下記のような手順でデバッガを起動します。\n  ホスト PC: windeployqt.exe を利用して実行に必要なバイナリを集める\n$ windeployqt.exe -qmldir \u0026lt;proc_dir\u0026gt; \u0026lt;debug_binary_dir\u0026gt;   サーバ PC: ホスト PC から実行に必要なバイナリ一式 (debug_binary_dir 内のファイル一式) を コピーして、任意の場所 (server_debug_binary_dir) に配置する。\n  サーバ PC: powershell を起動\n  サーバ PC(powershell): 環境変数 _NT_DEBUGGER_EXTENSION_PATH に qtlib へのパスを追加\n$ $env:_NT_DEBUGGER_EXTENSION_PATH = \u0026#39;C:\\qtlib\u0026#39;   サーバ PC(powershell): cdb を用いてバイナリを実行し、 QtCreator からのアクセスを待ち受ける\n$ cdb.exe -server tcp:port=1234 \u0026lt;server_debug_binary_dir\u0026gt;\\run.exe   ホスト PC: Qt Creator から \u0026ldquo;デバッグ\u0026rdquo; -\u0026gt; \u0026ldquo;デバッグ開始\u0026rdquo; -\u0026gt; \u0026ldquo;リモートCDBセッションにアタッチ\u0026rdquo; を選択\n  ホスト PC: サーバ PC の IP と cdb 起動時に設定したポート番号を設定\n  上記手順を踏むことでサーバ PC にてバイナリが実行され、 ホスト PC のブレークポイントを設定しておいた場所で停止や次のステップへの移動などができることを確認しました。\nVisual Studio のリモートデバッガと違い、 実行ファイルの場所などはビルド場所と同じにする必要はないようです。 また、自分の環境で作っていたアプリケーションに関しても、普通にデバッグできることを確認しました。\n参考資料  Setting Visual Studio 2015 debugger  windows 環境におけるリモートデバッグの方法は、こちらの Q\u0026amp;A が参考になりました。    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/qt/qt-remote-debug/","tags":["software"],"title":"Qt におけるリモートデバッグ"},{"categories":null,"contents":"概要 現在、 自然言語処理 100 本ノック に取り組んでいます。その中で、構文解析に CaboCha を使う必要がありました。実行環境には Google Colaboratory を使っています。 Ubuntu 環境へのインストール方法などは、見つかったのですが Colaboratory 用のインストール方法が見つかりませんでした。もしかしたら、どこかに記載があるのかもしれませんが、今回は覚書のためにも残しておきます。 Ubuntu などへのインストールでは、ソースコードの修正が必要と書かれていましたが、私が試したバージョンと環境では不要でした。手順としては、下記のようになります。\n MeCab のインストール CRF++ のインストール Cabocha のインストール  MeCab をインストールする 最初に MeCab をインストールします。ここまでは、色々な所にインストール方法が記載されていました。ただ、後半で swig が必要となるため、ここでインストールしてしまっています。\n!apt install -y \\ curl \\ file \\ git \\ libmecab-dev \\ make \\ mecab \\ mecab-ipadic-utf8 \\ swig \\ xz-utils !pip install mecab-python3 CRF++ をインストールする 次に、 Cabocha の依存パッケージである CRF++ をインストールします。最新版の CRF++ はダウンロードページ(Google Drive)から取得できます。\nimport os filename_crfpp = \u0026#39;crfpp.tar.gz\u0026#39; !wget \u0026#34;https://drive.google.com/uc?export=download\u0026amp;id=0B4y35FiV1wh7QVR6VXJ5dWExSTQ\u0026#34; \\ -O $filename_crfpp !tar zxvf $filename_crfpp %cd CRF++-0.58 !./configure !make !make install %cd .. os.environ[\u0026#39;LD_LIBRARY_PATH\u0026#39;] += \u0026#39;:/usr/local/lib\u0026#39; CRF++ のインストール後にライブラリへのパスを追加する必要があります。これをしないと、 CaboCha のインストール時に CRF++ の共有ファイル (.so) が見つからないというかエラーが発生します。最初は、コマンド形式でインストールしていたため、パスの追加に export を使って書いたのですが、変更されませんでした。結局、 os.environ で設定を書き換えることで、認識できました。\nCaboCha のインストール 最後に、今回使いたい Cabocha をインストールします。上記の CRF++ までが、正常にインストール出来ていれば、うまく行くはずです。\nurl_cabocha = \u0026#39;https://drive.google.com/uc?export=download\u0026amp;id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU\u0026#39; filename_cabocha = \u0026#39;cabocha.tar.bz2\u0026#39; !wget \u0026#34;$url_cabocha\u0026#34; -O $filename_cabocha !bzip2 -dc $filename_cabocha | tar xvf - %cd cabocha-0.69 !./configure --with-mecab-config=`which mecab-config` --with-charset=UTF8 !make !make check !make install %cd .. !cabocha --version CaboCha の python バインディングを有効化する もし、 python から呼び出す必要がある場合は、下記のコマンドが追加で必要となります。\n%cd cabocha-0.69/python !python setup.py build_ext !python setup.py install !ldconfig %cd ../.. まとめ MeCab に比べてインストール手順が長くなりましたが、 Colaboratory 上で CaboCha をインストールできました。これで、ローカルに環境を用意しなくても自然言語処理 100 本ノックを行えます。 Colaboratory は、本当に便利です。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/install-cabocha-in-colaboratory/","tags":["colaboratory","cabocha"],"title":"Colabratory に Cabocha をインストールする"},{"categories":null,"contents":"WSL がインストールできない環境で、 git for windows をインストールしたところ、 nc コマンドが使えず git の proxy 指定ができなかったので調べました。 nc コマンドの代わりに connect.exe が利用できるようです。\nProxyCommand connect.exe -H hoge.proxy.jp:8080 %h %p 22番ポートが使えなくても、SSHでGitしたい！\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/proxy-using-git-for-windows/","tags":["software"],"title":"Git for Windows で proxy を設定する"},{"categories":null,"contents":"Qt で開発されているソフトウェアのデバッグ作業で調べたので、メモしておきます。 単にデバッグ実行するだけであれば、 Qt の開発環境をデバッグ実行するだけなので、意識する事はないと思います。 今回は開発環境が入っている PC では実行できなかったため、 リモート PC で実行して開発環境からチェックするということを行いました。 Visual Studio だと、開発環境からリモートの操作ができるのですが、 Qt 開発環境の場合は、リモート PC のコマンドラインからステップ実行などをする必要がありました。 ブレークポイントの設定などは Qt 環境からできますが、 なぜか、一回止めると、再度進めるためにはコマンドラインの入力待ちになってしまいました。 変数のチェックとかは、 Qt 開発環境からできます。\ncdb/Windbgの使い方のメモ にまとめられていました。\nコマンド一覧の取得は単純に ? でできます。\n0:000\u0026gt; ?  実行関連\n順にgdbにおけるcontinue、nexti（関数の中に入らない）、stepi（関数の中に入る）、finish（リターンするまで進める）に対応する。\n 0:000\u0026gt; g 0:000\u0026gt; p 0:000\u0026gt; t 0:000\u0026gt; gu ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/qt/cdb-debug/","tags":["software"],"title":"CDB の使い方を調べた時のメモ"},{"categories":null,"contents":" いろいろな方法を試しましたが、結局上記スクリプトでないとダウンロードできませんでした。\nPower Shell でファイルをダウンロードする で基本のダウンロードスクリプトが見つかったのですが、 https からのダウンロードのせいか SSL/TLS のチャネル生成失敗エラーが発生していました。\n\u0026#34;2\u0026#34; 個の引数を指定して \u0026#34;DownloadFile\u0026#34; を呼び出し中に例外が発生しました: \u0026#34;要求は中止されました: SSL/TLS のセキュリティで保護されているチャネルを作成できませんでした\u0026#34; SSL/TLS のセキュリティ用に Invoke-RestMethod、Invoke-WebRequestが失敗する の方法で SecurityProtocol の 2 行を追加する必要がありました。 SSL/TLS 関連では、 PowershellのInvoke-RestMethodをhttpsに実施すると失敗する の方法では失敗してしまいました。 よくわかっていないので求めていることが違ったのかもしれません。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/powershell/download-using-powershell/","tags":["software"],"title":"powershell でファイルをダウンロードする"},{"categories":null,"contents":"svn の中が歴史的経緯により複雑な環境となっている場合があります。 例えば、下記のような構成です。\nroot |- trunk | |- project_a | |- project_b |- branches | |- project_a | |- project_b |- tags |- project_a_v1.0.0 |- project_b_v1.0.1 root の下にプロジェクトごとの trunk などがあるわけではなく、各プロジェクトの turnk が trunk ディレクトリの下に配置されています。\nこの場合は、下記のようなコマンド群を使っていく必要があります。\ngit svn clone -T project_a svn://hoge/trunk/ trunk の直前までの URL を書き、最後の trunk フォルダ名を -T オプションにつなげます。 branches とかの取得方法もあるのかもしれませんが、あきらめました。\n上記方法論だと、 branch は取り込め無いのが問題ですが、とりあえず trunk だけは移行できます。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/git-svn-for-strange-folder/","tags":["software"],"title":"svn のリポジトリ構成がデフォルトではない場合における git svn コマンド"},{"categories":null,"contents":"画像処理エンジニア検定  画像処理エンジニア検定 Qiita: 画像処理初心者が、画像処理エンジニア検定エキスパートに合格した時の学習法  G 検定 日経経済新聞: AIの知識を問う「G検定」 合格者の裾野広がる\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/skills/","tags":["software"],"title":"情報系の資格"},{"categories":null,"contents":"Rentio 社: もらえるレンタル Rentio 社、もらえるレンタル\nルンバ 960\n 月額レンタル料: 8,000 1 年間の支払額: 96,000  iRobot 社のレンタル iRobot レンタル\n Roomba 980: 7,000 2 週間 Roomba 885: 5,000 2 週間  価格.com 価格.com\n ルンバ 960: 81,696 ルンバ 980: 109,990  Amazon 価格  Roomba960: 87,000 Roomba980: 121,000  比較ブログ 【2018年最新比較】ルンバの違いと価格。おすすめはコレ！\n 112畳以上の広いお家やオフィスをピカピカに掃除してほしい人はルンバ980。 小さなお子さんやペットがいるご家庭で、3部屋以上をまとめてルンバでピカピカに掃除したい人はルンバ885。 小さなお子さんやペットがいるご家庭で、1部屋ずつルンバを使って掃除したい人はルンバ875もしくはルンバ876。 とりあえずロボット掃除機に掃除してもらって、自分でも掃除する人はルンバ680。  価格に関して 2018年4月25日現在、Amazonでのルンバの価格を書いておきます。 値段は日によって変動しますので、あくまでも参考程度にお考えください。\n ルンバ980 114,815 ルンバ960 84,899 ルンバ880 79,980 ルンバ890 66,980 ルンバ885 64,092 ルンバ870 53,000 ルンバ876 52,150 ルンバ875 49,800 ルンバ690 46,980 ルンバ622 41,000 ルンバ680 38,800  900 シリーズと 800 シリーズの違い 900シリーズ（980/960）と800シリーズ（880/885/870/875/876/890）の違いは、掃除できる広さです。 900シリーズは112畳掃除できるのに対して、800シリーズが掃除できるのは25畳までです。\n900シリーズは、自分で充電器のところまで帰って、充電が終わったら自動でお掃除を再開します。 900シリーズには、カメラが付いていて間取りを把握することができる。\n800 シリーズと 600 シリーズの違い 800シリーズ（890/880/885/870/875/876）と600シリーズ（622/680/690）では、吸引力と手入れのしやすさが違います。\n800シリーズは、600シリーズに比べて吸引力は5倍、ごみを集める効率は1.5倍です。\n980 と 960 の違い 何が違うかというと、まずは稼働時間です。 980は1回の充電につき120分稼働しますが、960は75分の稼働です。 ただし、自動再生はついているので戻って再開が可能。\nいちばん大きな違いは、カーペットブーストモードがあるかないかです。 カーペットブーストモードというのは、カーペットの上を通るときは、 吸引力を強くする機能のことです。 これは980にはついていますが、960にはついていません。 カーペットも完璧にきれいにしたいのであれはルンバ980、 元々吸引力はあるので、 べつにそこまで強力にごみを吸わなくてもいいなぁという方はルンバ960でいいと思います。\n880 と 870 の違い 880番台と870番台はライトハウスモードがついているかいないかの違いがあります。 ライトハウスモードと言うのは『お部屋ナビ』という付属品を置くことで、 部屋を区切って認識する機能のことです。 3部屋以上をまとめて掃除する場合、 ライトハウスモードがないと、3つの部屋を大きな1つの部屋と認識して掃除します。\nライトハウスモードがなくても、3部屋同時にお掃除はできますが、 効率が悪くなりますし、 部屋によってはルンバが1回も通らない部分も出てきます。 ですので、確実に1部屋ずつしか掃除しない！ と言う人以外はルンバ885にしておいた方がいいでしょう。\n870/880/890 と 875/876/885 の違い ルンバ870と880は2014年発売、ルンバ875と885は2015年に発売されました。 何が違うかと言うと、バッテリーの持ちと無料メンテナンスがあるかないかです。\n1の位が0のモデルは、バッテリーの持ちが3年なのに対し、 1の位が5のモデルはバッテリーの持ちが倍の6年になり、 無料メンテナンスがつきました。 替えのバッテリーはAmazonで純正品は8,500円くらい、 互換品なら4,000円くらいで買えます\nルンバの870番台は、2016年に新しくルンバ876が発売されています。 ルンバ875とルンバ876の違いは、バーチャルウォールの形の違いです。 バーチャルウォールと言うのは、 付属の機械でルンバに壁がない所でも壁があると認識させて、 ルンバを入らせない機能です。 ルンバ875のバーチャルウォールは直線状のみなのに対し ルンバ876では円形のバーチャルウォールも選べるようになりました！ （もちろん直線状のバーチャルウォールも使えます）\n2017年夏に発売したルンバ890は、 ルンバ876をアプリで操作できるようにしたものと考えて下さい。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/comparison_roomba/","tags":["hardware"],"title":"ルンバの調査"},{"categories":null,"contents":"Go 言語を使っていて、テストカバレッジが簡単に 100% にならなかったので、 どこが通過させられていないのか調べるのに使いました。\n下記のコマンドでテスト実行時に、プロファイルを出力し、 html に変換できました。\n$ go test --cover ./... -coverprofile=./bin/cover.out $ go tool cover -html=./bin/cover.html 上記で出力先として、 bin フォルダを指定しているのは、 出力結果をトップディレクトリに作成したくなかったからです。 (git で変更履歴として検出されてしまうので) 別に出力先はどこでもよいと思います。\n Goのテスト作成とカバレッジ率＆カバレッジ行表示をしてみる  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/go/go-coverage/","tags":null,"title":"Go 言語でテストカバレッジを可視化する"},{"categories":null,"contents":"Windows10 において、 \u0026ldquo;オプション機能の追加\u0026quot;から OpenSSH Server をインストールしたら失敗したので、 対処したときのメモです。\n結論としては、 WSUS (Windows Server Update System) が有効になっていて、 インストールできない場合があるようなので、 一時的に WSUS を無効にしてあげることで対応できるようです。\nOpenSSH Server のインストール手順 下記に手順を示します。\n  Win + R を押して、 regedit で OK を押す。\n  管理者権限に昇格してレジストリエディタを開く。\n  HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\WindowsUpdate\\AU に移動する。\n  UseWUServer の値を 0 とする。\n  WSUS を再起動する。\n$ net stop wuauserv \u0026amp;\u0026amp; net start wuauserv   OpenSSH Server をインストールする。\n$ Get-WindowsCapability -Online | ? { $_.Name -like \u0026#39;OpenSSH*\u0026#39; } $ Add-WindowsCapability -Online -Name \u0026#39;OpenSSH.Server~~~~0.0.1.0\u0026#39;   Firewall から 22 番ポートを開放する\n$ New-NetFirewallRule -Protocol TCP -LocalPort 22 -Direction Inbound -Action Allow -DisplayName SSH   C:\\Windows\\System32\\OpenSSH に sshd_conf_default があるので、 コピーして sshd_conf にする。\n$ cd C:\\Windows\\System32\\OpenSSH $ cp sshd_conf_default sshd_conf   OpenSSH を起動する。\n$ Restart-Service sshd   参考情報  TechNet: Win10 1709 Add feature fails with error 0x800F0954 OpenSSHサーバーがWindows10に正式にやってきた(April 2018 Update/1803)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/install-windows-openssh-under-domain/","tags":["windows","software"],"title":"Windows で OpenSSH をドメイン環境下でインストール"},{"categories":null,"contents":" アジャイルソフトウェア開発宣言 アジャイルソフトウェア開発宣言の原文\n 私たちは、ソフトウェア開発の実践あるいは実践を手助けをする活動を通じて、 よりよい開発方法を見つけだそうとしている。この活動を通して、私たちは 以下の価値に至った。\n プロセスやツールよりも 個人と対話 を、 包括的なドキュメントよりも 動くソフトウェア を、 契約交渉よりも 顧客との協調 を、 計画に従うことよりも 変化への対応 を、  価値とする。すなわち、左記のことがらに価値があることを認めながらも、 私たちは右記のことがらにより価値をおく。\nKent Beck,Mike Beedle,Arie van Bennekum,Alistair Cockburn, Ward Cunningham,Martin Fowler,James Grenning,Jim Highsmith, Andrew Hunt,Ron Jeffries,Jon Kern,Brian Marick,Robert C. Martin, Steve Mellor,Ken Schwaber,Jeff Sutherland,Dave Thomas\n© 2001, 上記の著者たち\nこの宣言は、この注意書きも含めた形で全文を含めることを条件に自由にコピーしてよい。\n アジャイル宣言の背後にある原則 アジャイル宣言の背後にある原則の原文\nアジャイル宣言の背後にある原則\n私たちは以下の原則に従う:\n 顧客満足を最優先し、価値のあるソフトウェアを早く継続的に提供します。 要求の変更はたとえ開発の後期であっても歓迎します。 変化を味方につけることによって、お客様の競争力を引き上げます。 動くソフトウェアを、2-3週間から2-3ヶ月という できるだけ短い時間間隔でリリースします。 ビジネス側の人と開発者は、プロジェクトを通して 日々一緒に働かなければなりません。 意欲に満ちた人々を集めてプロジェクトを構成します。 環境と支援を与え仕事が無事終わるまで彼らを信頼します。 情報を伝えるもっとも効率的で効果的な方法は フェイス・トゥ・フェイスで話をすることです。 動くソフトウェアこそが進捗の最も重要な尺度です。 アジャイル･プロセスは持続可能な開発を促進します。 一定のペースを継続的に維持できるようにしなければなりません。 技術的卓越性と優れた設計に対する不断の注意が機敏さを高めます。 シンプルさ（ムダなく作れる量を最大限にすること）が本質です。 最良のアーキテクチャ・要求・設計は、自己組織的なチームから生み出されます。 チームがもっと効率を高めることができるかを定期的に振り返り、 それに基づいて自分たちのやり方を最適に調整します。  なぜアジャイル宣言が誕生したのか 下記のまとめによると、 アジャイル宣言とは文字通り\u0026quot;宣言\u0026quot;であり、 細かいことは何も決めていないということになります。 技術変化の速い現代において、変化に適応し、 適切な選択をもって対応していこうといっていることになるようです。\nQiita: アジャイル宣言とは？新しい価値観の提示\n アジャイル宣言とは一言でいうと「新しい価値観の提示」です。 これを理解することで『自分たちがやっていることが良い？悪い？方向に向かっているのか？ どこに向かえばいいか？を判断できる』ようになります。 （現実のシステム開発はそんなに簡単なものではないので「判断できる」と言い切るのは大げさかもしれません。 ですが、少なくとも「より良いシステム開発への道しるべ」にはなってくれるはずです）\n例えば、いろいろなキーワード(スクラム、Docker、CI/CD など)について考えていると 「結局何が重要なのか？どれを採用すればいいのか？」まるで、 迷路の中で迷子になってしまうような感覚になってしまいます。 そんなとき、アジャイル宣言（新しい価値観）という視点に立ち、 改めて考え直すことで、迷路から抜け出すキッカケを与えてくれます。\n    アジャイル宣言があるとき          「特定の開発手法/技術だけでは、世の中の変化と戦うことができなくなった」という現実を受け入れ、 「世の中の激しい変化にさらされても、使う開発手法/技術を素早く柔軟に変え続けることで、成果を出し続けるぞ！」という宣言\n 未読資料  IPA: アジャイルソフトウェア開発宣言の読みとき方  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/agile-software-development/","tags":["software"],"title":"アジャイルソフトウェア開発"},{"categories":null,"contents":"Hugo で baseurl を有効にする場合の設定です。 root のみで運用する場合は、 baseURL を設定するだけでよいそうですが、 baseurl にサブディレクトリを指定する場合は、追加の設定が必要になります。\nIssue when baseurl have subdirectory によると、 config.toml において、 baseURL の指定に加えて、 RelativeURLs と CanonifyURLs を有効にする必要があります。\nbaseURL = https://example.com/ RelativeURLs = true CanonifyURLs = true Using Hugo によると、 server モードの起動時に設定する場合は下記のようなコマンドになります。\n$ hugo server --baseURL=http://yoursite.org/ \\  --port=80 \\  --appendPort=false \\  --bind=xxx.xxx.xxx.xxx 注意点として、 1024 番以下のポートを利用する場合は、 sudo でないと権限がなく失敗するようです。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/hugo-baseurl/","tags":null,"title":"Hugo で baseurl を有効にする"},{"categories":null,"contents":"GCP で作成したインスタンスを起動する場合に、 下記のようなエラーが発生する場合があります。\nStarting instance(s) ubuntu-dev...failed. ERROR: (gcloud.compute.instances.start) The zone \u0026#39;projects/hoge/zones/asia-northeast1-b\u0026#39; does not have enough resources available to fulfill the request. Try a different zone, or try again later. プリエンプティブインスタンスである場合に、 GCP 側で起動できないようにすることがあるようです。\nGCP(GCE)でプリエンプティブインスタンスが起動しない場合の対処法\n上記情報によれば復活するまでに 2 日とかかかる場合もあるようです。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gcp-resource-error/","tags":["software"],"title":"GCP のインスタンス起動でエラーが発生する"},{"categories":null,"contents":"はじめに Qiita API を利用してローカルの markdown ファイルを記事としてアップロードする python スクリプトを作成しました。作成したスクリプトのテストも兼ねて、作業内容をまとめてみます。\n 投稿内容の作成 投稿用のヘッダ情報の作成 投稿処理 投稿後のレスポンス情報から ID 情報を取得 投稿内容が書かれたファイルのヘッダ部分に ID を追加  背景 以前から自分で書いたメモなどの単純なドキュメントファイルに関しては、一括して GitLab.com のプライベートリポジトリで管理していました。今回、 Qiita に投稿してみようと思ったのですが、 Qiita に投稿する内容は、都度書いて Qiita で管理するということも考えました。が、やはりローカル環境でテキストを書きたいということもあり、 Qiita API を活用して、ローカル環境から投稿するようにしました。まだまだ粗削りですが、とりあえず投稿して、記事を修正した場合は、修正版をコミットすることまではできました。\n$ python3 --version Python 3.6.6 投稿内容の作成 ローカルのファイル群は Hugo を活用しています。そのため、投稿する内容以外にヘッダ情報が付与されています。ここを活用して、 Qiita に投稿するヘッダ情報も管理するようにします。 今回は、下記のようなヘッダ情報と投稿内容を作成していると仮定します。\n(hoge.md)\n+++ title = \u0026#34;テスト投稿\u0026#34; draft = true tags = [\u0026#34;test\u0026#34;] [qiita] coediting = false gist = false tweet = false id = \u0026#34;\u0026#34; +++ hogehoge 投稿用のヘッダ情報の作成 上記で作成した hoge.md からヘッダ部分を読み込み、投稿用のヘッダ情報を作成します。\nimport re import toml def load_file(filepath): # ファイル内容の読み込み with open(filepath) as f: buf = f.read() # ヘッダ部分と投稿する内容を分離します。 # ここでは、 \u0026#39;+++\u0026#39; がヘッダ部分の範囲を指定すると決め打ちしています。 # また、 hugo の関係上ヘッダが toml で記載されているので、 # toml パーサで内容を読み込んでいます。 header = re.match( r\u0026#39;^\\+\\+\\+$.+?^\\+\\+\\+$\u0026#39;, buf, flags=(re.MULTILINE | re.DOTALL)) body = buf[header.end() + 1:] header = buf[header.start() + 4:header.end() - 4] header = toml.loads(header) # ヘッダ情報から Qiita へ投稿するヘッダ情報へ修正します item = { \u0026#39;title\u0026#39;: header[\u0026#39;title\u0026#39;], \u0026#39;private\u0026#39;: header[\u0026#39;draft\u0026#39;], \u0026#39;tags\u0026#39;: [{\u0026#39;name\u0026#39;: tag} for tag in header[\u0026#39;tags\u0026#39;]], \u0026#39;coediting\u0026#39;: header[\u0026#39;qiita\u0026#39;][\u0026#39;coediting\u0026#39;], \u0026#39;gist\u0026#39;: header[\u0026#39;qiita\u0026#39;][\u0026#39;coediting\u0026#39;], \u0026#39;tweet\u0026#39;: header[\u0026#39;qiita\u0026#39;][\u0026#39;tweet\u0026#39;], \u0026#39;id\u0026#39;: header[\u0026#39;qiita\u0026#39;][\u0026#39;id\u0026#39;] if \u0026#39;id\u0026#39; in header[\u0026#39;qiita\u0026#39;] else \u0026#39;\u0026#39;, } # 投稿内容を格納 item[\u0026#39;body\u0026#39;] = body return item 新規投稿の作成 Qiita API を利用して、 load_file 関数で取得する内容を投稿します。投稿には、 requests を利用して post 処理を行います。\nimport requests def post(item): url = \u0026#39;https://qiita.com/api/v2/items\u0026#39; token = \u0026#39;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#39; headers = {\u0026#39;Authorization\u0026#39;: \u0026#39;Bearer {}\u0026#39;.format(token)} res = requests.post(url, headers=headers, json=item) return res Qiita API を利用して新規の投稿を作成する場合は、アクセストークンが必要となります。 token の部分に自分で取得したアクセストークンを設定してください。\n投稿したレスポンスから ID を取得しヘッダを更新 投稿に成功するとレスポンスに ID 情報が付与されます。この ID を自分のローカル環境にあるファイルのヘッダ情報に入れておけば、 Qiita の記事との対応関係が取れることになります。そこで、今回はレスポンスに入っている情報をもとに、ヘッダ部分を書き換えるようにしています。\nimport toml def add_qiita_id(filepath, item, res): item[\u0026#39;qiita\u0026#39;][\u0026#39;id\u0026#39;] = res.json()[\u0026#39;id\u0026#39;] data = \u0026#39;+++\\n{}+++\\n{}\u0026#39;.format(toml.dumps(header), body) with open(filepath, mode=\u0026#39;w\u0026#39;) as f: f.write(item) Qiita から返ってくる ID を記録しておくと、後から記事を修正した場合に、ローカルの内容を同じ記事に反映することが可能となります。\n処理フロー if __name__ == \u0026#34;__main__\u0026#34;: filepath = \u0026#39;hoge.md\u0026#39; item = load_file(filepath) res = post(item) add_qiita_id(filepath, item, res) 最後に これでローカル環境で書いた内容をそのまま投稿することができるようになりました。ただ、まだまだ課題はありますし、エラー処理やらアクセストークンの管理やら対応していない部分が多いです。ざっと考えられる課題を挙げておきます。\n アクセストークンの管理がテキストファイル想定 タグがついていないとエラーする hoge.md に必要なヘッダ情報が抜けた場合のエラー処理 toml を利用してしまったので標準環境以外が入ってしまった ローカル環境は改行を無視するが、 Qiita では改行が改行として扱われるので、表示形式が異なってしまう エラー処理が抜けている 自動投稿への対応  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/python/post-from-qiita-api/","tags":["QiitaAPI","python"],"title":"Qiita API を利用して記事を投稿する"},{"categories":null,"contents":"Abstract 2010 Fourth Pacific-Rim Symposium on Image and Video Technology\nFederico Tombari, Luigi Di Stefano\nIn this work we propose a novel Hough voting approach for the detection of free-form shapes in a 3D space, to be used for object recognition tasks in 3D scenes with a significant degree of occlusion and clutter. The proposed method relies on matching 3D features to accumulate evidence of the presence of the objects being sought in a 3D Hough space. We validate our proposal by presenting a quantitative experimental comparison with state-of-the-art methods as well as by showing how our method enables 3D object recognition from real-time stereo data.\n pdf  手法 2D Hough 変換では、平面上の 1 点を通る直線をパラメータ空間で表現し、 パラメータ空間を量子化した範囲に投票を行うことで平面中の直線を検出します。 2D Hough 変換を単純に 3D に拡張することで、 3 次元空間中から平面を推定することができます。 しかしながら、本論分はハフ投票によって平面を求めるのではなく、 モデルデータ中に設定した基準点の位置をシーン中に求めます(図 3)。 最終的に、同一のビンに投票した点群を利用して、 シーン中で見つけたモデルデータの回転を計算しますが、 投票時には回転は考慮されていません。 同一の基準点の位置になるならば、別の姿勢でも同じように投票します。 論文中では、同一のビンに分類された点群から RMSE(Root Mean Square Error) によって、 回転の推定を行っています。\n   処理フロー(図 1) 投票(図 3) LR の射影(図 4)           実験結果    実験結果(図 7)         ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/objectrecognitionin3dsceneswithocclusionsandclustterbyhoughvoting/","tags":["study"],"title":"Object Recognition in 3D Scenes with Occlusions and Clustter by Hough Voting"},{"categories":null,"contents":"Unique Signatures of Histograms for Local Surface Description (SHOT) Abstract Federico Tombari, Samuele Salti, and Luigi Di Stefano\nECCV 2010\nAbstract\nThis paper deals with local 3D descriptors for surface matching. First, we categorize existing methods into two classes: Signatures and Histograms. Then, by discussion and experiments alike, we point out the key issues of uniqueness and repeatability of the local reference frame. Based on these observations, we formulate a novel comprehensive proposal for surface representation, which encompasses a new unique and repeatable local reference frame as well as a new 3D descriptor. The latter lays at the intersection between Signatures and Histograms, so as to possibly achieve a better balance between descriptiveness and robustness. Experiments on publicly available datasets as well as on range scans obtained with Spacetime Stereo provide a thorough validation of our proposal.\n pdf pcl CV Lab  GitHub: CVLAB-Unibo   GitHub: fedassa/SHOT     ヒストグラム算出のための空間分割 実験結果          PCLで三次元物体認識 Qiita: PCLで三次元物体認識\nPCL のチュートリアル を解説しています。 ここから、中京大学 橋本先生の SHOT 解説 pdf へのリンクを見つけました。\n中京大学 橋本先生 の SHOT 解説 2013年 高速物体検出 ～ ロボットに使える2次元・3次元センシング ～\n文献自体では、 2D の特徴抽出や 3D の特徴抽出に関して記載されています。 その中で、 p.61 に SHOT 特徴量の説明があります。\n   SHOT         主成分分析により主方向の推定が入っているため、 SIFT のように回転不変に近くなるはずです。 一方で、スケール不変ではない特徴量になるはずです。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/uniquesignaturesofhistogramsforlocalsurfacedescription_shot/","tags":["study"],"title":"Unique Signatures of Histograms for Local Surface Description (SHOT)"},{"categories":null,"contents":"Golang で一括で各プラットフォー用のバイナリを生成するコマンドの書き方を調べた時のメモです。 結論としては、下記のコードで一括でバイナリを生成できます。 対象のプラットフォームを増やす場合は、 for 文の要素を増やせばできます。\n一点だけ問題があり、 windows のみ実行ファイルの拡張子として .exe を付ける必要があります。 そのため、上記のままでは windows 側で実行ファイルとして認識してくれません。 リネームすればよいのですが、 簡単な if 文程度で分岐できないでしょうか。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/go/golang-cross-build/","tags":null,"title":"Golang でクロスビルドする Makefile の設定"},{"categories":null,"contents":"Hyper を利用している場合に、たまに最終行付近が見切れることがあります。 どうも、タブを追加したときに一段下がる動作をするのですが、 この時に描画範囲がうまくリセットされないために起こっているようです。 Ctrl + L とかで再描画してもダメな場合が多かったですが、 単に Window サイズを変更してあげると、描画サイズのリセットがかかるようです。\nWindows とかの場合は、 Win + ↓ とかを押して、 いったん画面サイズを小さくしてから Win + ↑ とかで最大化すると正常に描画されます。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hyper-sytle-reflesh/","tags":["software"],"title":"Hyper で最終行付近が見切れる場合の対処法"},{"categories":null,"contents":"GitHub と GitLab に加えて、社内リポジトリで git の履歴にのこるユーザ名やメールを変更したい場合があります。 今までは、 git clone してから git config --local で設定をリポジトリ単位でしていました。 しかしながら、 Go 言語のディレクトリ構成をとっているため、 あるフォルダしたからは全て一定になります。 また、数が増えてくると設定し忘れることが良くあります。 どうしたら管理が楽になるか調べていたところ、 include に条件設定できることが分かりました。 これを用いれば解くてフォルダ下は全て任意の設定にできます。\ngit 2.13.0 から git config の include で if が利用できます。 書き方は下記のようになります。\n[includeIf \u0026#34;\u0026lt;条件\u0026gt;\u0026#34;] path = \u0026lt;設定ファイル\u0026gt; GitHub と GitLab でユーザ名やメールアドレスが異なる場合は、下記のように設定します。 ghq を利用してディレクトリを管理していると想定します。\n[includeIf \u0026#34;gitdir:~/src/github.com/\u0026#34;] path = ~/.gitconfig.github [includeIf \u0026#34;gitdir:~/src/gitlab.com/\u0026#34;] path = ~/.gitconfig.gitlab ~/.gitconfig.github\n[user] name = hoge.github email = hoge.github@example.com ~/.gitconfig.gitlab\n[user] name = hoge.gitlab email = hoge.gitlab@example.com 上記のように設定すると githab.com 下では .gitconfig.github が読み込まれます。 一方で、 gitlab.com 下では、 .gitconfig.github が読み込まれず、 .gitconfig.gitlab のみ読み込まれます。 結果として、それぞれにユーザ名とメールアドレスを記載しておけば、 それぞれ別の設定を適用することができます。\n参考文献: git configをプロジェクトによって使い分ける\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/git-config-include-if/","tags":null,"title":"プロジェクト単位で git config の設定を変更する"},{"categories":null,"contents":"hyper.js に下記のようにターミナルの設定を入れるといいようです。\nenv: { TERM: \u0026#39;msys\u0026#39;, }, Hyper の起動時に cmd と powershell なども選択して起動できるようにしているため、 起動するシェルによって TERM の設定を変えなければいけないような気がします。 powershell と cmd の範囲では、 TERM に msys を設定したままでも、普通に動いているように見えます。 WSL と Git for Windows の両方を選択する状況は発生していないため、 これは設定しっぱなしでもよいのかもしれません。\n参考情報: \u0026ldquo;clear\u0026rdquo; broken on Windows when using with Git BASH\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/reflesh-git-for-windows-on-hyper/","tags":["software"],"title":"Hyper のシェルとして git for windows を利用した場合の画面リフレッシュ方法"},{"categories":null,"contents":"git for windows の bash を利用していて日本語文字列が文字化けする場合は、 エンコーディングを UTF-8 に変更すればよいそうです。 コマンドラインから利用する場合などでも同様に修正できるようです。\n変更方法は、下記のようになります。\n$ export LANG=ja_JP.UTF-8 恒常的に適用する場合は、 git for windows の場合の .bashrc は C:\\Program Files\\Git\\etc\\bash.bashrc になるので、 これに書いておけばよさそうです。\n参考文献\n Git for Windows で漢字等非ASCII文字が文字化けする場合 Windows Git 2.6.1で~/.bashrcがGit Bashから読み込まれるようにする  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/encoding-git-for-windows/","tags":null,"title":"git for windows の ターミナル出力で文字化けする場合の対処法"},{"categories":null,"contents":"ライブラリを動的リンクではなく、強制的に静的リンクをしてしまいたい場合があります。 そういう時は、 gcc のオプションで \u0026ndash;static を利用します。 pkg-config を利用している場合は、 pkg-config が対応していれば、 下記のように記載することで適切に処理してくれます。\n`pkg-config --static hoge` ただ、 pkg-config が対応してない場合もあるため、 対応していない場合は、下記のように直前に \u0026ndash;static を記載しても静的リンクできるようです。\n--static `pkg-config hoge` 参考文献: How to use pkg-config to link a library statically\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/cpp/gcc-static-link/","tags":null,"title":"gcc でライブラリを静的リンクする方法"},{"categories":null,"contents":"docker で必要なバイナリのみを移動するときに、 依存するライブラリを調べるために利用しました。 linux では、 ldd コマンドが使えます。 ldd コマンドは、下記のようにして利用します。\n$ ldd hoge.so 例えば、適当に共有ライブラリのファイルを調べると下記のような結果になります。\n$ ldd libhandle.so.1.0.3 linux-vdso.so.1 (0x00007fffef3c2000) libc.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007ffc79340000) /lib64/ld-linux-x86-64.so.2 (0x00007ffc79a00000) ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/bash/ldd-shared-library/","tags":null,"title":"linux 環境の場合は、共有ライブラリの依存関係は ldd コマンドで調べられる"},{"categories":null,"contents":"いったんは、下記の手順で CUDA をインストールできることを確認しました。 ただ、その後、バージョンアップなどでもインストールに失敗したので、 OS のクリーンインストールを行い、 windows ドライバのアップデートを初期に切ってから行うと、 アップデートなども正常にできるようになりました。 たぶん、他にも影響がある項目があるのだと思いますが、 詳細は分かっていないです。 できれば最初に windows のデバイスドライバの自動アップデートを 切ってしまったほうが楽だと思います。\n解決策としては、下記に記載の方法をとりました。\n CUDA 9.1 cannot install due to failed Visual Studio Integration  上記のうち実行したのは下記のような手順です。\n NVIDIA ドライバで動いているディスプレイをデバイスマネージャからドライバの更新で別のドライバに設定する NVIDIA と名前の付くアプリをすべてアンインストール NVIDIA 関連のディレクトリを Program Files, Program Files (x86), ProgramData から削除 再起動 ここで、ディスプレイに NVidia のドライバが当たっていないことを確認 CUDA をインストール  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/cuda-vs-integration/","tags":null,"title":"windows10 環境で cuda + visual studio integration のインストールが失敗する"},{"categories":null,"contents":"KVM + GPU Passthrough ができることまでは確認しました。 これに加えて、 docker を利用することで、 GPU の passthrough 設定のみしておけば、 package 類はインストールしなくても利用できました。\ndocker image を生成する Dockerfile と、 docker-compose.yml のサンプルを下に置いておきました。\nGitHub: iimuz/docker-kvm\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/docker-kvm-privileged/","tags":["software"],"title":"docker 環境で KVM を利用する"},{"categories":null,"contents":"windows 環境を仮想化し、 GPU を利用可能な環境を作成する方法です。 windows10 を利用した場合は、 GPU Passthrough が正常に動作することを確認しました。 一方で、 windows7 では GPU Passthrough が正常に動いていないです。\nあと、今回の試し範囲では GPU Passthgough した後に、 再起動なしで GPU をホスト PC で利用する方法が分かっていません。 そのため、 NVIDIA Docker などと使い分けができていないです。 多分、普通に使うなら GCP とかで GPU インスタンスを利用したほうが簡単です。\n環境構築手順 ハードウェア要件 GPU Passthrough するにあたり、ホスト PC には2つ以上の GPU が必要となります。 ひとつは、ホスト PC の UI を出力するためのグラフィックボードであり、 もうひとつはゲスト PC に Passthrough するグラフィックボードになります。 ホスト PC のグラフィックボードは、 CPU などに内蔵されているオンボード GPU でも可能です。\nその他に、 Intel VT や AMD-V などの仮想化に対応している CPU か マザーボードである必要があります。 また、 UEFI ブートに対応している必要もあります。 これらは BIOS の設定画面から有効化することができますが、 有効化できない場合は、そのホスト PC では GPU Passthrough した仮想環境を用意することができないことになります。\nBIOS 設定  UEFI ブートに設定 Intel VT または AMD-V の有効化 デフォルトの UI 出力をオンボード GPU に変更する  OS 設定  Ubuntu 18.04 Server をインストールする  Ubuntu 18.04 Server 以外での動作は確認していません。 他の OS でも動作するはずですが、 NVIDIA GPU を Passthrough する場合には、 CPU のベンダー ID を偽装する必要があります。 そのため、パッケージとして QEMU 2.5 以上であり libvirt 1.3.0 以上である必要があります。\nホスト PC での GPU の 無効化設定 GPU Passthrough するにあたり、ホスト PC 側で Passthrough する GPU を無効化する必要があります。\n$ sudo vim /etc/default/grub GRUB_CMDLINE_LINUX=\u0026#34;intel_iommu=on\u0026#34; $ sudo grub-mkconfig -o /boot/grub/grub.cfg # GPU の [ベンダーID:デバイスID] を調べる $ lspci -nn | grep -i nvidia 01:00.0 VGA compatible controller [0300]: NVIDIA Corporation Device [10de:1b80] (rev a1) 01:00.1 Audio device [0403]: NVIDIA Corporation Device [10de:10f0] (rev a1) # ids=*** に調べた [ベンダーID:デバイスID] を指定する $ sudo vim /etc/modprobe.d/vfio.conf options vfio-pci ids=10de:1c03,10de:10f1 $ sudo sh -c \u0026#34;echo \u0026#39;vfio-pci\u0026#39; \u0026gt; /etc/modules-load.d/vfio-pci.conf\u0026#34; # modules に下記の設定を追加する $ sudo vim /etc/initramfs-tools/modules vfio vfio_iommu_type1 vfio_pci kvm kvm_intel $ sudo update-initramfs -u $ sudo bash -c \u0026#34;echo blacklist nouveau \u0026gt; /etc/modprobe.d/blacklist-nvidia-nouveau.conf\u0026#34; $ sudo bash -c \u0026#34;echo options nouveau modeset=0 \u0026gt;\u0026gt; /etc/modprobe.d/blacklist-nvidia-nouveau.conf\u0026#34; $ sudo update-initramfs -u $ sudo reboot 正しい設定となっているかは下記の項目を確認してください。\n# 起動時に IOMMU が enabled になっていれば OK $ dmesg | grep -E \u0026#34;DMAR|IOMMU\u0026#34; [ 0.000000] ACPI: DMAR 0x00000000DE9F4248 000080 (v01 INTEL SNB 00000001 INTL 00000001) [ 0.000000] DMAR: IOMMU enabled [ 0.000000] DMAR: Host address width 36 [ 0.000000] DMAR: DRHD base: 0x000000fed90000 flags: 0x1 [ 0.000000] DMAR: dmar0: reg_base_addr fed90000 ver 1:0 cap c9008020660262 ecap f0105a [ 0.000000] DMAR: RMRR base: 0x000000de880000 end: 0x000000de88cfff [ 0.000000] DMAR-IR: IOAPIC id 2 under DRHD base 0xfed90000 IOMMU 0 [ 0.000000] DMAR-IR: HPET id 0 under DRHD base 0xfed90000 [ 0.000000] DMAR-IR: Queued invalidation will be enabled to support x2apic and Intr-remapping. [ 0.000000] DMAR-IR: Enabled IRQ remapping in x2apic mode [ 0.788522] DMAR: No ATSR found [ 0.788553] DMAR: dmar0: Using Queued invalidation [ 0.788560] DMAR: Setting RMRR: [ 0.788616] DMAR: Setting identity map for device 0000:00:14.0 [0xde880000 - 0xde88cfff] [ 0.788655] DMAR: Setting identity map for device 0000:00:1a.0 [0xde880000 - 0xde88cfff] [ 0.788691] DMAR: Setting identity map for device 0000:00:1d.0 [0xde880000 - 0xde88cfff] [ 0.788698] DMAR: Prepare 0-16MiB unity mapping for LPC [ 0.788730] DMAR: Setting identity map for device 0000:00:1f.0 [0x0 - 0xffffff] [ 0.788795] DMAR: Intel(R) Virtualization Technology for Directed I/O # 起動時に vfio-pci が有効になっていれば OK dmesg | grep -i vfio [ 8.501615] VFIO - User Level meta-driver version: 0.3 [ 8.525419] vfio_pci: add [10de:1b80[ffff:ffff]] class 0x000000/00000000 [ 8.544020] vfio_pci: add [10de:10f0[ffff:ffff]] class 0x000000/00000000 # Kernel driver in use が vfio-pci になっていれば OK $ lspci -vs 0000:01:00 01:00.0 VGA compatible controller: NVIDIA Corporation Device 1b80 (rev a1) (prog-if 00 [VGA controller]) Subsystem: Micro-Star International Co., Ltd. [MSI] Device 3362 Flags: bus master, fast devsel, latency 0, IRQ 16 Memory at f6000000 (32-bit, non-prefetchable) [size=16M] Memory at e0000000 (64-bit, prefetchable) [size=256M] Memory at f0000000 (64-bit, prefetchable) [size=32M] I/O ports at e000 [size=128] [virtual] Expansion ROM at 000c0000 [disabled] [size=128K] Capabilities: \u0026lt;access denied\u0026gt; Kernel driver in use: vfio-pci Kernel modules: nvidiafb, nouveau, nvidia_384_drm, nvidia_384 01:00.1 Audio device: NVIDIA Corporation Device 10f0 (rev a1) Subsystem: Micro-Star International Co., Ltd. [MSI] Device 3362 Flags: bus master, fast devsel, latency 0, IRQ 15 Memory at f7080000 (32-bit, non-prefetchable) [size=16K] Capabilities: \u0026lt;access denied\u0026gt; Kernel driver in use: vfio-pci Kernel modules: snd_hda_intel KVM 用パッケージのインストール $ sudo apt install --no-install-recommends -y qemu-kvm libvirt-bin virtinst bridge-utils cpu-checker virt-manager ovmf $ sudo reboot Windows 環境の構築 下記コマンドを用いて仮想環境を起動し、 ISO ファイルから windows をインストールします。\n# windows をインストールする領域を確保 (80GB) $ dd if=/dev/zero of=_mnt/primary.uefi.raw bs=10M count=8k # UEFI 用の設定をコピー $ cp /usr/share/OVMF/OVMF_VARS.fd /tmp/my_vars.fd # 仮想環境を起動 $ sudo qemu-system-x86_64 \\  -name win10 \\  -machine type=q35,accel=kvm \\  -balloon none \\  -rtc clock=host,base=localtime \\  -cpu host,kvm=off \\  -smp 4,sockets=1,cores=2,threads=2 \\  -m 4096 \\  -spice port=5900,disable-ticketing,agent-mouse=off \\  -vga qxl \\  -serial none \\  -parallel none \\  -drive if=pflash,format=raw,readonly,file=/usr/share/OVMF/OVMF_CODE.fd \\  -drive if=pflash,format=raw,file=/tmp/my_vars.fd \\  -boot order=dc \\  -drive file=./_mnt/primary.uefi.raw,if=virtio,index=1 \\  -drive file=./_mnt/windows10.iso,media=cdrom,index=2 \\  -drive file=./_mnt/virtio-win.iso,media=cdrom,index=3 \\  -redir tcp:3389::3389 windows でリモートデスクトップを有効にするまでは、リモートデスクトップ接続ができないため、 spice という VNC の次世代版を利用してください。 windows 用クライアントが存在します。\nwindows がインストールできたら、リモートデスクトップを有効化します。 その後、一旦 windows をシャットダウンしてください。 そして、仮想環境に GPU を Passthrough して再起動します。\n$ sudo qemu-system-x86_64 \\  -name win10 \\  -machine type=q35,accel=kvm \\  -balloon none \\  -rtc clock=host,base=localtime \\  -cpu host,kvm=off \\  -smp 4,sockets=1,cores=2,threads=2 \\  -m 4096 \\  -vga none \\  -nographic \\  -serial none \\  -parallel none \\  -drive if=pflash,format=raw,readonly,file=/usr/share/OVMF/OVMF_CODE.fd \\  -drive if=pflash,format=raw,file=/tmp/my_vars.fd \\  -boot order=c \\  -drive file=./_mnt/primary.uefi.raw,if=virtio,index=1 \\  -drive file=/mnt/vm/windows7/primary.uefi.raw,if=virtio,index=1 \\  -device vfio-pci,host=01:00.0,multifunction=on,x-vga=on \\  -redir tcp:3389::3389 起動した windows にリモートデスクトップで接続し、 GPU のドライバをインストールしてください。 ドライバのインストール後に windows を再起動すると、 GPU が認識できた仮想環境が構築できています。\n参考情報  KVM : GPU パススルー Ubuntu KVM virtualization with GPU Passthrough GPU Passthrough with vfio-pci still uses nouveau driver nvidia-driverをubuntu18.04にインストールする  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/docker-kvm-windows/","tags":["software"],"title":"KVM + GPU Passthrough + windows で仮想環境を構築"},{"categories":null,"contents":"windows 環境において、 コード中の特定位置で現在のプロセスが利用しているメモリ使用量を取得したかったので、 調べた時のメモです。\n結論 windows.h と psapi.h を利用して、 PROCESS_MEMORY_COUNTERS_EX という構造体にメモリ使用量が取得できます。 psapi.h は psapi.lib をリンクする必要がありましたが、 下記のようなコードで構造体中にメモリ使用量を取得できます。\n GetProcessMemoryInfo メモリを取得する際には、 GetProcessMemoryInfo という関数を利用します。 GetProcessMemoryInfo は、プロセスのハンドルを渡す必要があります。 実際に作った exe を動かし、その時のメモリ情報を必要とする場合は、 GetCurrentProcess で取得できます。\n一方で、他のプロセスのハンドルを取得すれば、そのプロセスのメモリを取得することも可能です。 ただ、多くの場合はリソースモニタとかで取得したり記録しておけば十分な気もします。\nPROCESS_MEMORY_COUNTERS_EX メモリ情報は PROCESS_MEMORY_COUNTERS_EX という構造体に取得できます。 結構色々取得できるのですが、 private usage を取得しておけば、 とりあえずのメモリ量監視としては十分な気がします。\n各種用語の開設に関しては、下記が非常に参考になりました。\nWindows の使われてるメモリの量\nvisual studio でのお試しプロジェクト 動作テストのために、 Visual Studio 2010 と古いですが、プロジェクトを作成したサンプルを置いておきます。\n iimuz/visualstudio-private-bytes-sample  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/cpp/cpp-windows-memory-usage/","tags":null,"title":"windows で c++ を用いてメモリ使用量を取得する"},{"categories":null,"contents":"VS Code 上で vim キーバインドが使えないか調べたら、 GitHub: VSCodeVim/Vim というのがありました。 ほかのキーバインドとかぶったり、いくつか挙動が怪しかったりしますが、 モードの切り替えができるようになったので楽になりました。 本格的な作業自体は、 vim を使うのでちょっとした編集とかができれば十分なので、 これで問題ないような気がします。\n一点だけちょっと使いにくかったのが、 w での単語移動が日本語が続いていると次の行まで行ってしまいます。 多分半角スペースとか改行で判定されています。 せめて、ひらがなとかカタカナ、漢字の変わり目で止まってくれると嬉しいのですが。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/vscode-vim/","tags":null,"title":"VS Code 上で vim キーバインドの実現"},{"categories":null,"contents":"MSDN のサブスクリプションとかに登録していると windows キーが複数手に入るのですが、 どの環境にどのキーを入れているかわからなくなって、 位置から対応させたくなったので、 windows のプロダクトキーを修正する方法です。 基本的には、下記のコマンドで登録・削除などができるようです。\n 参考情報\n （違法じゃなく）無理やりプロダクトキーを変更する方法  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/change_windows_product_key/","tags":null,"title":"windows のプロダクトキーを変更する"},{"categories":null,"contents":"chrome でテキスト入力が多くなってくると、ローカルのエディタで編集したくなってきたので、 Chrome拡張のGhostText導入手順(Visual Studio Code編) に書いてあった GhostText と VSCode で実現できることを確認しました。 Chrome と VSCode のそれぞれにプラグインを導入すると chrome 側でテキスト入力したいときに、 Ctrl + K + L を押すと下記のような青枠がついた状態となって、 VSCode にテキストが同期されます。 すでに入力済みのテキストがあっても動作するので楽です。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/ghosttext/","tags":null,"title":"chrome のテキスト入力をローカルのエディタで行う"},{"categories":null,"contents":"win32api を利用するときに CreateHandle は CloseHandle を呼部必要のある Handle を返すのですが、 Handle 型で返すために単純に std::unique_ptr でいつも通りのデリータを指定することができませんでした。\nstd::unique_ptr, deleters and the Win32 API によると、 CreateHandle のようにポインタ以外が帰ってきてしまう場合に std::unique_ptr を利用したい場合は、 下記のように関数オブジェクトを定義してデリータに指定すると利用できることが分かりました。\n 普通にポインタを返してくれるタイプであれば、 デリータ指定自体は、一般的には下記の方法が利用できるはずです。\n関数オブジェクト\n default_delete の特殊化\n 関数\n 状況により使い分けは必要ですが、関数版が一番記述量が少なくて好きです。 default_delete の特殊化は、どこに書くべきなのかがよくわからなくて、使ったことがないです。 cpp ファイルの方に書くと、必要なところで毎回記述が必要になります。 自作クラスならヘッダファイルに宣言して、 cpp に実体を記述することもできますが、 自作クラスを std::unique_ptr で利用する前提で書くのも何かなと思ったりします。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/cpp/cpp-unique-ptr-deleter/","tags":null,"title":"c++ の std::unique_ptr におけるデリータ指定"},{"categories":null,"contents":"arXivTimes で見つけた論文です。 GAN を利用した異常検知技術を調べていた時に見つけました。\nAnoGAN というネットワークを提案しています。 医療用画像を対象に、正常画像のみから、 GAN で学習していくようです。 このとき、 Generator は潜在空間から画像生成されると仮定します。 面白いのは、 GAN だけで完結しており、 検査時の入力画像は Auto Encoder のように再構成せず、 Generator から近い画像を生成するようにしているようです。 GAN は、潜在空間から画像は生成できるが、画像から潜在空間は変換できないはずです。 そこで、潜在空間は連続的に変化することから最初はランダムランプリングで潜在空間から画像を生成し、 近い画像へ潜在空間上を移動させるという処理を行うようです。 そのため、検査時に時間がかかる可能性はあるように思います。 また、残差誤差だけでなく、 Descriminator 側の出力も考慮して異常スコアを算出しているようです。\n 実装例: LeeDoYup/AnoGAN 日本語で解説してくれている記事です。  GAN による医療画像の異常検知 【論文読み】GAN を利用した異常検知まとめ   その他に、論文を読んでいるときに調べながら見つけた論文  Unsupervised Adversarial Anomaly Detection using One-Class Support Vector Machines One-Class Adversarial Nets for Fraud Detection    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/","tags":["study"],"title":"Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery"},{"categories":null,"contents":"HTTPSとSSL、TLSで何が違うのかよくわかっていなかったので、簡単に調べた時のメモです。 結論としては、下記のような感じでしょうか。\n TLSは、暗号化などのセキュリティ機能を実現する方法の規約 TLSは、SSLのバージョンアップ版  SSL3.0は脆弱性が分かっているので、利用してはいけない wikipedia TLS#SSL3.0   HTTPS = HTTP + TLS  SSLとTLSはセキュア通信のための仕組みであり、SSLにはバージョンが1.0(非公開)、2.0、3.0とあった。 ただし、SSL3.0は脆弱性が見つかっているので利用してはいけないことになっている。 TLS1.0はSSLの進化系になる。 そのため、TLS1.0はSSL3.1と呼ばれることもあるとのことです。\nTLSが提供する機能は主に下記のようになるそうです。\n 通信相手の認証 通信内容の暗号化 改竄の検出  現在の最新バージョンはTLS1.3であり、ネゴシエーションに利用するバージョンはSSL3.4になるそうです。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/js/https-ssl-tls/","tags":null,"title":"httpsとSSLとTLSのメモ"},{"categories":null,"contents":"powershellにおいてシンボリックリンクをpowershellのコマンドで作ることができるようです。 従来はcmdの mklink を利用していた部分を new-item で置き換えることができます。\n$ cmd /c mklink dst src # 従来のcmdによるコマンド $ New-Item -Type SymbolicLink -Path dst -Value src ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/powershell/ps1-symboliclink/","tags":null,"title":"powershell でシンボリックリンクを生成する"},{"categories":null,"contents":"windows環境ではsshのようなことが Enter-PSSession コマンドにより可能になります。 (ただし、リソース制限などいくつかできないことがあります。) Enter-PSSession 後の操作において New-PSDrive というネットワークドライブのマウント作業において、 権限情報が不足し使用できなくなります。 そのため、 New-PSDrive を Enter-PSSession 後に利用する場合は -Credential オプションを付与する必要があるみたいです。\n$ Enter-PSSession ip $ New-PSDrive DriveName -PSProvider FileSystem -Root \\\\remote-address -Credential domain@username 最後の -Credential オプションがないとマウントできなくなっています。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/powershell/new-psdrive/","tags":null,"title":"Enter-PSSession後のNew-PSDrive"},{"categories":null,"contents":"git で作業中に複数の作業を並行しなければならない場合があります。 例えば、バグを修正中に、別件の依頼を受けて別のバグ修正や動作確認をしなければならないような場合です。 そのような場合は、 git stash を利用していったん変更を保存して、必要な環境にcheckoutするという方法も可能です。 ただ、c++とかビルドする場合は、stashを利用してしまうと、ビルドの中間ファイルはコミット対象外なので、 戻ってきたときに一からビルドが必要になります。 一瞬でビルドが終わるようなプロジェクトならいいのですが、 一からビルドすると1時間以上かかるようなプロジェクトだとスイッチする気がうせてしまいます。 そのような場合に、 git worktree を利用することで、 もう一つ別のディレクトリを作成して作業ができるようになるので便利です。\nコマンドとしては、下記のような構文になります。\n$ git worktree add path/to/dir -b new/branch source/branch 上記のようにすると、 source/branch をもとにして new/branch を作成し、 path/to/dir に新規でファイルが作成されます。 作業ディレクトリが干渉しないため、非常に使いやすいです。\n作業が終わったら作成したディレクトリは削除して、pruneすることでworktreeは削除できます。\n$ rm -rf path/to/dir $ git worktree prune ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/git-worktree/","tags":null,"title":"git worktree を用いた別作業ディレクトリの用意"},{"categories":null,"contents":"Qiita: ロシアの天才ハッカーによる【新人エンジニアサバイバルガイド】 が心にとどめておいたほうがよさそうな部分が結構あったので抜粋しておきます。\n コードのクオリティに腹をたてるな。同僚の2倍のスピードでリリースをするよう心がけろ。   この部分は痛いほどわかりますが、どうしてもできないときもあります。 でも今後なるべく気を付けようと思います。 (別プロジェクトに参加していきなりエラーのデバッグを割り当てられて、 コードを見た時によく思ってしまう。)\n Chef,Ansible,Puppetを学ぼう。運用エンジニアの時間を浪費するのはやめよう。   環境には寄ると思いますが、Dockerというのもありかな。\n 常に４つの環境を用意しておこう。   開発環境で動いても、本番環境で想定通りに動くかは別問題だからテスト環境はよく準備するようにします。\n 常にTLSを使おう。社内サービスであってもだ。   社内利用だとあまりTLSを気にしていませんでした。 どうしても甘くなってしまいます。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/russia-engineer-survival-guide/","tags":null,"title":"Qiita: ロシアの天才ハッカーによる【新人エンジニアサバイバルガイド】を読んで"},{"categories":null,"contents":"C#で一定時間内に処理が終わらなければ終了する中断する処理を書きたかったので、調べた時のメモです。 タスクを起動し、キャンセル処理を一定時間後に起動するようにします。 本来のタスクとキャンセル処理のいずれかが完了した時点で、処理を終了するようにすることで、 タイムアウト処理が実現できるようです。\n ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/csharp/cs-cancellation-task/","tags":null,"title":"C#でキャンセル処理を利用したタイムアウトの実現"},{"categories":null,"contents":"Qiita: [翻訳] 技術向上ガイドにGoogleのTechnical Development Guideの翻訳があったので読んだ感想です。 色々と書かれているのですが、英語文献が多いので読むのには時間がかかりそうです。 ただ、その中でも課題プロジェクトに取り組むという部分はとっかかりやすいように思いました。\n ウェブサイトを作成し維持する、自分自身のサーバーを構築する、またはロボットを構築する\n\u0026hellip;\nCodeJamやACMの国際大学対抗プログラミングコンテストのようなコーディング競技を通して自分のアルゴリズム知識を磨く\n 例えば、プログラミングコンテストで日本語でやりやすそうなのはAtCoderやISUCONなどでしょうか。 この辺であれば、過去問なども記載されており取り組むのによいような気がします。\nその他に系統は違いますが、Kaggleなどは機械学習の知識をつけるにはよさそうです。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/google-technical-guide/","tags":["software"],"title":"技術向上ガイド"},{"categories":null,"contents":"docker-composeを利用していたりすると環境変数ファイル(.env)とかに、 ローカル環境の変数をまとめていたりします。 その状態で、環境に合わせて環境変数ファイルを変更すると、 コミットしなくてよい変更が検出された状態になります。 add対象を慎重に選ぶという方法もあるのですが、 git statusとかで検出しないほうが楽なので、検出を停止する方法です。\n$ git update-index --assume-unchanged {ファイル名} # 除外 $ git update-index --no-assume-unchanged {ファイル名} # 解除 $ git ls-files -v | grep ^h # 設定ファイルの確認 注意点として、対象ファイルを本当に変更したときにコミット対象から外れていることに気づけないので、 そこは若干問題です。\n参考情報  A4 WORKS Official BLOG: Gitで一時的に”Changes not staged for commit”リストから外す  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/stop-git-temp-diff/","tags":null,"title":"gitで一時的に変更の検出を止める"},{"categories":null,"contents":"プログラマが知るべき97のことという内容で著名な方々のコメント(?)がまとめられたページがありました。 \u0026ldquo;シンプルさは美に宿る\u0026quot;とか\u0026quot;リファクタリングの際に注意すべきこと\u0026quot;ととか、 結構ためになる内容なので一通り目を通すと面白いです。\n プログラマが知るべき97のこと  97のことと言いつつ、107個のっている理由は不明です。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/97-things-that-programmers-should-know/","tags":["others"],"title":"プログラマが知るべき97のこと"},{"categories":null,"contents":"ブランチの最初で、下記のような空コミットを作成することで、 メインブランチへ取り込まれたときにクローズできます。\n$ git commit --allow-empty -m \u0026#34;resolve #id\u0026#34; また、このクローズ動作はGitHubの設定画面で指定したメインブランチに対してマージされたときに発生するようです。 そのため、例えばmasterブランチはCIなどによって自動でコミットされる対象となっている場合は、 可能ならばメインの開発ブランチ(developとか?)をメインブランチに設定しておくと対象のブランチにマージされた段階で発生します。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/close-issues-when-merge/","tags":null,"title":"GitHub の Issue をコミットのマージ時に自動でクローズする"},{"categories":null,"contents":"概要 アクセスするだけなら GCE は cloud console でできます。 ポートフォワードしたい場合は、 secure shell という chrome アプリを利用すればできます。\nフロー  GCE の cloud console でアクセス用のキーを作成(ssh-keygen)し、メタデータとして登録  本当はよくないかもしれないが、とりあえず動かしたいだけなら gce 用のキーがすでにあるのでそれで対応する。   secure shell では public キーと pvivate キーの両方が必要となるため、両方ダウンロード ssh client として chrome app の secure shell を利用する。 設定画面では、 user name と ip (外部IP)、port を指定する ID(Identify?)のところに pub と private の両方のキーを import する SSH 引数に -L 8888:localhost:8888 gce 側で何かport 8888で待ち受けさせる(適当なweb serverを立てる) client pc 側でブラウザから localhost:8888 にアクセス  所感 手元の端末の環境(Linux, Windows, Mac)によらず動かせるようにしたかったので試してみました。 これで chromebook とかの安いPCに移行することができるかもしれません。 (chromebook の開発者モードを利用するとかいろいろありそうですが、 できれば通常モードの範囲でやりくりしたいのです。)\nただし、 google cloud console の動作が環境のせいかもっさりしているので、 常に chrome の secure shell を使ったほうがストレスは少ないかもしれません。 (でもやっぱり日本語入力すると位置ずれが起こったりするのは若干我慢なのかもしれません。)\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/gce_ssh_using_chrome/","tags":["software"],"title":"chrome のみで GCE にアクセスする環境構築した時のメモ"},{"categories":null,"contents":"このサイトを元記事をmarkdownで書いたらTravisCIでビルドするようにしたので、その際に行ったことのメモです。\n概要  TravisCIの登録 TravisCIから自動ビルド対象のリポジトリを設定 Travis Clientをインストールしてsshキーの暗号化 .travis.ymlからビルド方法を設定  sshキーの暗号化 TravisCIからpushするためには、sshを用いる設定としました。 この時、対象とするリポジトリのみに公開鍵を設定し、最悪秘密鍵が漏洩しても他には影響がないようにします。 また、秘密鍵はリポジトリに含める必要があるので、TravisClientを用いて暗号化します。\n暗号化するための環境 今回は、dockerを利用してtravis clientの環境を用意しました。 rubyが必要なので、ベースをrubyにして簡単に用意できます。\nFROMruby:2.5.0-stretchRUN gem install travis -v 1.8.8 --no-rdoc --no-ri上記で作成したイメージを利用して、下記のように起動すればtravisコマンドが利用できる環境が使えます。\n$ docker run --rm -it -v $(pwd):/src:rw localhost:travis-client bash 暗号化方法 travisコマンドを利用して暗号化します。\n$ travis login $ ssh-keygen -f travis_key $ travis encrypt-file travis_key 出来上がった.encファイルをコミットします。 また、作成時に openssl ... という行が出力されるのでコピーしておきます。 これは.travis.ymlに記載します。\ntravis_key.pubはgithubに登録したら消してしまっていいと思います。 また、travis_keyはコミットせずに消去します。\n.travis.ymlの記述 ビルド方法はいろいろあると思います。 ビルドし終わった後のデータをpushする部分のみを下記に記載します。\nafter_success: - openssl # ここに先ほどコピーした内容を記述します。 - chmod 600 ~/.ssh/id_rsa # 権限を書き換えないと正しく動作しないです。 - echo -e \u0026#34;Host github.com\\n\\tStrictHostKeyChecking no\\n\u0026#34; \u0026gt;\u0026gt; ~/.ssh/config - git config --global user.email \u0026#34;example@example.com\u0026#34; - git config --global user.name \u0026#34;example\u0026#34; - git clone -b master git@github.com:repository@path.git - cd path - rm -rf ./* - cp -aR ../public/* . - git add --all - git commit -m \u0026#34;by Travis CI (JOB $TRAVIS_JOB_NUMBER)\u0026#34; - git push origin master 参考資料  Travis CI から GitHub へ git push を行う設定  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/travis-ci-blog/","tags":null,"title":"Travis CIから更新する設定を行った時のメモ"},{"categories":null,"contents":"powershellで、ncコマンドのようなことをするために調べたメモです。\n成果物 下記のようなpowershellスクリプトを用意し、実行することでncコマンドのようなことが実現できました。\n 参考資料  bashでtcpや利用して文字列を送信する方法 ncコマンドの使い方 windowsでtcpのポート確認方法 powershellでnetcatスクリプト powershellで繰り返しバッファ送信  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/powershell/powershell-tcp/","tags":null,"title":"powershell で tcp のテスト用にサーバとクライアントを用意する方法のメモ"},{"categories":null,"contents":"C#でasyncとawaitを利用して並列処理を行ったので、その時のメモです。 結構簡単に並列処理を記述できた感じがします。\n最終的なコードの雛形 複数のタスクが完了した段階で次のタスクを起動する場合の書き方です。\npublic async Task methodAsync() { var task1 = Task.Run(() =\u0026gt; { // 何か処理1  }); var task2 = Task.Run(() =\u0026gt; { // 何か処理2  }); var taskAll = Task.WhenAll(task1, task2).ContinueWith(() =\u0026gt; { // 何か処理3  }); return await taskAll.ConfigureAwait(false); } Task Taskは、一連の処理をひとまとまりにした単位になるようです。 また、Taskは呼び出した際に別スレッドで実行されるようになっているようで、 連続で記述した場合は、どんどん別スレッドで並列処理されるようになっているようです。\nTask.WhenAll と ContinueWith TaskはContinueWith関数を利用して、その後の処理を連続して実行できるようです。 そのため、2つ以上の関数を実行して、両方が終わった場合に続きの処理を書く場合は、 ContinueWithを利用するか、awaitで全て終了するのを待つかの2パターンありそうです。\n(パターン1)\nvar task1 = Task.Run(() =\u0026gt; { // 何か処理  }); var task2 = Task.Run(() =\u0026gt; { // 何か処理  }); var taskAll = Task.WhenAll(task1, task2).ContinueWith(task3); (パターン2)\nvar task1 = Task.Run(() =\u0026gt; { // 何か処理  }); var task2 = Task.Run(() =\u0026gt; { // 何か処理  }); await task1.ConfigureAwait(false); await task2.ConfigureAwait(false); // task3を普通に記述 状況によりけりな気もしますが、 個別の処理がそこそこ多くなると見通しが悪いので、 先に関数でまとめて処理を記述し、 関数を呼び出すだけでタスク間の関係性が見通せるパターン1の方が好きな書き方でした。\nさらにキャンセル処理とか書き足すと、パターン2だと、囲む範囲が大きくなったりして見づらかったです。\nConfigureAwait(false) Wait関数やResultは、デフォルトで元のスレッドへ戻ろうとします。 そのため、下記のように記述すると簡単にデッドロックが発生します。\npublic void callMethod() { methodAsync().Wait(); } public Task waitAsync() { return await Task.Delay(1000); } 上記の場合、 methodAsync().Wait() を読んだ時点で親スレッドがスリープします。 その後、 waitAsync() 関数が終わり、親スレッドに戻ろうとしますが、 この時点で既に親スレッドがスリープしているため処理を続けることができなくなります。 結果として、親スレッド( callMethod() )は、子スレッド( waitAsync )を待ち、 子スレッドは親スレッドに戻ろうとして、デッドロックとなります。\nそのため、戻るスレッドがどこでもよい場合(おそらくほとんどの場合はそうなるようです。)は、 ConfigureAwait(false) をつけることで、戻るスレッドを親スレッドに限定しないことができるようです。 これを指定すると、デッドロックが回避できるようです。\npublic void callMethod() { methodAsync().Wait(); } public Task waitAsync() { return await Task.Delay(1000).ConfigureAwait(false); } ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/csharp/cs-async-await/","tags":null,"title":"C#におけるAysncとAwaitの動作に関して調べたときのメモ"},{"categories":null,"contents":"C#でTCP Clientを実際に利用したので、その際に作成したコードの雛形をメモしておきます。 本当は、色々と追加で必要な処理とかがあるのかもしれませんが、今回は下記のコードで十分でした。\n成果物 下記のコードでクライアントとしてサーバに接続し、文字列送信することが可能です。\n 注意点 実際には、接続失敗した場合の処理などが別途必要です。 また、このサンプルで利用では Connect 関数を利用していますが、 同期関数となるため接続が完了するまでスレッドが停止してしまいます。 停止させるのが問題になる場合は、 ConnectAsync 関数を利用するか、 Taskなどを利用して非同期に実行する必要があります。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/csharp/cs-tcp-client/","tags":null,"title":"C#においてTCPClientを利用したときのメモ"},{"categories":null,"contents":"jenkinsでpallalelしたときの挙動に関してです。 きちんと調べればわかるのかもしれませんが、動作させたときに起こった現象をまとめておきます。\n下記のようにnodeの下にparallelを記載した場合は、同一ノード中で処理が並列で実施されるようです。\npipeline {\ragent { node { label \u0026quot;slave\u0026quot; } }\rstages {\rstage ('hoge') {\rpallalel {\rstage ('p1') { step { hoge } }\rstage ('p2') { step { hoge } }\r}\r}\r}\r}\r一方で、下記のようにステージにノードが含まれている場合は、複数ノードで並列で実施されるようです。\npipeline {\ragent none\rstages {\rstage ('hoge') {\rpallalel {\rstage ('p1') {\ragent { node { label \u0026quot;slave\u0026quot; } }\rstep { hoge }\r}\rstage ('p2') {\ragent { node { label \u0026quot;slave\u0026quot; } }\rstep { hoge }\r}\r}\r}\r}\r}\r","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jenkins/jenkins-parallel/","tags":[],"title":"Jenkinsでのparallel処理"},{"categories":null,"contents":"結論 送信アドレスを直接設定できないのでGMailのアドレスに追加する。\n方法 GMailのページをPC環境で開き、設定から \u0026ldquo;アカウントとインポート\u0026rdquo; -\u0026gt; \u0026ldquo;名前\u0026rdquo; -\u0026gt; \u0026ldquo;他のメールアドレスを追加\u0026rdquo; で任意のアドレスを追加する。\n例 hoge@gmail.com の追加パターン hoge+geho@gmail.com を追加すると、送信アドレスに hoge+geho@gmail.com が追加される。\n注意 スマホとかだと設定画面へ行けませんでした。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/gmail-alias/","tags":[],"title":"Gmailで+付きのメールアドレスから送信する方法"},{"categories":null,"contents":"powershellスクリプトを書くときに、helpコメントやwhatifなどの標準機能を利用できるように調べたときのメモです。\n最終テンプレート  何ができるか 上記テンプレートに従って書いた場合に何ができるようになるかというと、下記の標準機能が利用できます。\nGet-Help ヘルプ表示をすることでスクリプトの処理内容をチェックすることができます。 また、引数などについても確認できるようになります。\n# Helpの取得 $ Get-Help hoge.ps1 # 使用例などを含めてHelpを取得 $ Get-Hellp hoge.ps1 -detailed # 全てのヘルプとピックを取得 $ Get-Help hoge.ps1 -full WhatIf 実行時にdryrunをするためには、powershellコマンドの場合はWhatIfが使われますが、 このWhatIfをスクリプト内に伝搬することが可能になります。 そのため、下記のようにスクリプトを実行すると、dryrunが実現できます。\n$ .\\hoge.ps1 -WhatIf その他のスクリプトを書くときの注意点 標準出力系 powershellの場合、出力に関しては下記のパターンが用意されているので、使った方がデバッグが楽に行えると思います。\n Write-Verbose Write-Host Write-Warning Write-Error Write-Debug  上記のうち、Host、Warnng、Errorは何もしなくても出力されます。 一方、VerboseとDebugは下記のようにスクリプトを実行すれば、実行時のみ出力することができます。 注意点として、Debugフラグをつけた場合はInquireになるため、メッセージの場所で続行するか否かの選択肢が毎回発生します。\n# output verbose message $ .\\hoge.ps1 -Verbose # output debug message(inquire) $ .\\hoge.ps1 -Debug 進捗バー 処理量が多い時などは、下記のように進捗バーを出すことが簡単にできます。\nfor ($I = 0; $I -le 100; ++$I) { Write-Progress -Activity \u0026quot;Hoge Process\u0026quot; -Status \u0026quot;Hoge $I\u0026quot; -PercentComplete $I } -PercentComplete は、100分率で記載すれば良いようです。\nまとめ テンプレートを使って、出力周りを気にしてあげると、それっぽいスクリプトを作って人に渡すことができます。 Readmeとかは、Get-Helpでコマンドみてねにしておけば、個別のスクリプトの修正は、そのファイルだけで済むので少し楽になります。\n参考資料  TechNet: about_Comment_Based_Help TechNet: スクリプトでコマンドレットを記述する Microsoft: 詳しいヘルプ情報の取得 Microsoft: Write-Progress  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/powershell/powershell-template/","tags":[],"title":"powershellスクリプトを書くときのテンプレート"},{"categories":null,"contents":"現象 日本語を含む行では、なぜか行末の位置を適切に表示できなくなり、編集などをすると表示とは別の位置に表示される。\n対処方法 コマンドプロンプトをutf-8にしていることが問題でした。 下記コマンドで、cp932に変更することで正常に動作することを確認しました。\n$ chcp 932 詳細 windows 7 + conemu + コマンドプロンプト + docker + vim で日本語表示した時に問題が発生していました。 他の環境での設定もあり、utf8にコマンドプロンプトの出力を変更していました。\n$ chcp 65001 utf-8ファイルのgit diff出力などは、こうしておかないと文字化けしていたのですが、 今回はこの設定がダメだったようです。\n他にもconemuで下記の設定にしています。\n フォント: MS ゴシック monospace は OFF  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/cmd-vim-strange-cursor/","tags":null,"title":"windowsのコマンドプロンプトでdokcer + vimを利用すると日本語を含む行で適切に表示されない"},{"categories":null,"contents":"Jenkinsを利用したCI環境の構築 privateリポジトリなど個人用にCIを行うためにdockerを用いてjenkins環境を構築したときのメモです。\nmaster環境の構築 dockerhubに用意されているimageを利用しました。\n最終形のpluginと設定 pluginリスト\n SSH Slaves plugin  slaveをssh接続で利用するために必要です。 これをいれないとノードの追加で\u0026quot;SSH経由でUnixマシンのスレーブエージェントを起動\u0026quot;という選択肢が出ませんでした。    dockerのjenkins設定\nmaster: image: jenkinsci/jenkins:latest environment: JAVA_OPTS: -Xmx1g JENKINS_OPTS: --prefix=/jenkins --httpPort=1313 volumes: - ./master:/var/jenkins_home:rw ports: - 1313:1313    slaveの設定画面         slave設定 今回は接続できることを確認するためなので、単にslaveを起動します。\nslave: image: jenkinsci/ssh-slave:latest expose: - 22 depends_on: - master 経過ログ プラグイン類は全てなしで初期設定を行いました。\nただ、それだとslaveへの接続で\u0026quot;SSH経由でUnixマシンのスレーブエージェントを起動\u0026quot;という選択肢が現れなかったので、sshが選択できそうなプラグインのSSH Slaves pluginを導入して見ました。 最小構成の方法かどうかは不明ですが、とりあえず選択肢が現れたのでOKとします。\nmasterからslaveへ接続できなくて詰まりました。 結局のところ、sshキーの認証をslave側で適切にできていなかったことが原因のようです。\n  masterでsshキーを作成(パスなどは設定せず)\n# master container $ ssh-keygen -t rsa   slave側に ~/.ssh フォルダを作成して公開鍵を保存し、認証鍵に追加\n# host machine $ docker cp master/id_rsa.pub slave:~/.ssh/ # slave container $ docker exec slave bash $ cd ~ $ cat .ssh/id_rsa.pub \u0026gt;\u0026gt; authorized_keys   試しにmaster側から接続できるか確認する。この時アクセス権限が違うと怒られたので修正しています。\n# master container $ chmod 700 ~/.ssh/id_rsa $ ssh -i ~/.ssh/id_rsa username@slave   ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jenkins/jenkins/","tags":null,"title":"DockerでJenkinsのmasterとslaveを用意"},{"categories":null,"contents":"概要 windowsを利用していてネットワークドライブにあるsymlinkのディレクトリの情報を powershellから取得する方法を調べました。 セキュリティとしては甘くなるようです。\n# 現在の設定を確認する $ fsutil behavior query symlinkevaluation # リモートでのシンボリックリンクを有効にする $ fsutil behavior set symlinkevaluation r2r:1 r2l:1 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/powershell/windows-symlink-from-remote/","tags":null,"title":"windowsでネットワークドライブからsymlinkを有効にする"},{"categories":null,"contents":"概要 dockerでfess環境を構築します。 ただ、どうやってローカルのファイル検索結果を開くようにするかが問題です。 単純にダウンロードなら動作させられますが、 直接開きたいのです。(セキュリティ上Web利用だとしにくいのはわかっているのですが。)\n手順   docker hubからcodelib/fessのイメージをpullします。\n  下記コマンドで実行します。\n$ docker run -p 8080:8080 -d codelib/fess:latest   変更 そのままでは、利用しにくいので設定を変更しています。\nnginxのreverse proxy用設定 イメージをそのまま利用すると、localhost:8080に展開されます。 私の環境では、nginxを用いてリバースプロキシを設定しており、 サブディレクトリで複数のアプリケーションを分けています。 そこで、/opt/fess/bin/fess.in.shを変更しています。 デフォルトの状態から変更している部分のみ記載します。\n# localhost:8888/fess/でアクセスできるように変更します FESS_JAVA_OPTS=\u0026#34;$FESS_JAVA_OPTS-Dfess.context.path=/fess/\u0026#34; FESS_JAVA_OPTS=\u0026#34;$FESS_JAVA_OPTS-Dfess.port=8888\u0026#34; ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/dockerfess/","tags":null,"title":"DockerでFessを動かします"},{"categories":null,"contents":"概要 Mac側でdockerを利用してhugoの実行環境を作成したのですが、 同じデータを共有しているwindows側でも ビルドとデプロイができるdocker環境を作成しました。 その際、windows側だと確認用のローカルhugoサーバを建てた時に、 接続IPの設定でハマったのでメモしておきます。\n結論 Docker toolboxの場合は、virtualboxを利用しているため、 virtualboxのIPも設定した上で、 hugoサーバのアドレス設定を適切にする必要がありました。 (Port番号は、どこがどこに繋がっているのか明確にするためにわざと変えています。 別に変える必要はないので、本当は全部1313(hugoのデフォルト)にしています。)\n  virtualboxの設定画面(docker-machineに利用している仮想マシン) からネットワーク設定を開き、IPとポートを設定します。\n 例えば、ホストとゲストを下記のように設定します  ホスト: IP = 127.0.0.1, Port = 1313 ゲスト: IP = 0.0.0.0 Port = 8888      dockerデーモンを起動する時に、下記に記載するようにポートフォワードしておきます\n$ docker run -d -p 8888:80 -v source_volume:mount_dir hugo_image   dokcerデーモン内では下記のようにhugoサーバーが起動するようにします。\n$ hugo server -p 80 --baseURL=127.0.0.1 --bind=0.0.0.0 -w   windows側からブラウザで127.0.0.1:1313にアクセスすると観れます。\n  構成状況 結論部分で記載したように構成を組むと下記のように設定がなされます。\n(hugo: IP = 0.0.0.0, port = 80, baseURL = 127.0.0.1) -\u0026gt; (docker: IP = 0.0.0.0, Port = 8888) -\u0026gt; (virtualbox: IP = 127.0.0.1, Port = 1313) -\u0026gt; (browser: IP = 127.0.0.1, Port = 1313) かなりの手数を踏みますが、Docker for Macだとvirtualboxがないので、 素直に繋げることができます。 一方、windowsの場合(Docker Toolboxを利用する場合)だと、 virtualboxの設定も必要で若干ハマりました。 (おそらくDocker for windowsはHyper-Vを利用するので違うと思います。)\nもう一つハマったこととして、 hugoのbaseURLを127.0.0.1にしてあげる必要があります。 (browser側からアクセスするIPに設定すれば好きなIPで問題ないです。) browser側からのアクセスが127.0.0.1になるため、 0.0.0.0でbaseURLにすると、127.0.0.1の下にはデータがないので、 リンク切れになります。 加えて、cssとか読み込まれずスタイルが何も適用されません。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/dockerwindows/","tags":["software"],"title":"WindowsでDocker+Hugoサーバを動作させる方法です"},{"categories":null,"contents":"Dockerとは何ができるのでしょうか? 色々調べましたが、Dockerの構成などは説明されているのですが、 何ができるようになるのかをわかりやすく書いている文献を見つけられませんでした。\n調べた範囲では、下記のようなことができるという感じでしょうか。 実運用でしているわけではないので本当のメリットは不明です。\n アプリケーションを実行する環境を構築できる 用意した実行環境が周りを汚さない(多分これは重要) 困ったら即消せる(まあ、環境構築してたら結構失敗するよね)  例えば、下記のようなサイトを参考にさせてもらいました。\n paiza開発日誌 いまさら聞けないDocker入門(1)   「Docker」とは、 Docker社（旧dotCloud）が開発するオープンソースの コンテナー管理ソフトウェアの1つです。\n ライセンスがオープンソースなのは使いやすいです。 githubのdocker/LICENSEによると、 Appache License2.0に従うようです。\n重要なこととして、 NVIDIA Dockerなるdockerイメージがあり、TensorFlowの環境構築に使えるそうです。 NVIDIA Docker\nsshによるdocker-machineのdefaultへのログイン 最初に作られたdocker-machineのdefaultへsshで入るときのIDとパスは下記になるそうです。 windowsの場合、 sshで入るにはgit-bashを利用するか(おそらくdockerインストール時に入っています。)、 Windows10であればBash on UBuntu on Windowsで入れます。 私の場合は、Bash on Windowsで入れることを確認しました。\nuser: docker pass: tcuser Dockerのインストールと起動 Dokcer Toolboxをインストールしてpowershellから起動しようとすると、 いくつかエラーが発生しました。\ndocker-machineでTLSエラー 下記のようなエラーが発生しました。\n Error checking TLS connection: Error checking and/or regenerating the certs: There was an error validating certificates for host \u0026ldquo;192.168.99.100:2376\u0026rdquo;: x509: certificate is valid for 192.168.99.101, not 192.168.99.100 You can attempt to regenerate them using \u0026lsquo;docker-machine regenerate-certs [name]'. Be advised that this will trigger a Docker daemon restart which will stop running containers.\n 対処法に書いてあるようにコマンドを実行します。\ndocker-machine regenerate-certs default ここでdefaultなのは、docker-machineでエラーはいている奴の名前です。\nshellの違い 利用しているシェルとの関係でエラーが発生していると思われます。\n C:/Program Files/Docker Toolbox/docker.exe: An error occurred trying to connect: Post http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/containers/create: open // ./pipe/docker_engine: The system cannot find the file specified.. See \u0026lsquo;C:/Program Files/Docker Toolbox/docker.exe run \u0026ndash;help\u0026rsquo;.\n 下記のコマンドを実行すると解消されました。\ndocker-machine env --shell powershell default | Invoke-Expression ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/docker_survey/","tags":["software"],"title":"今更ながらにDockerについて調べてみました"},{"categories":null,"contents":"目標 深層学習の勉強で実際に実行できる環境を整えようと思ったのですが、 以前から入っているpython環境とは別にしたいのでDockerで構築してみました。\npythonにインストールするライブラリは、 O'REILLY ゼロから作るDeep Learningが動作する環境です。 したがって、下記の環境になります。\n Python 3.x NumPy Matplotlib  結論 python環境を構築するdockerファイルは下記になりました。 もはやdockerfile必要なのかというレベルで何も書いていないです。(楽すぎます)\nFROMpython:3.5.2RUN pip install numpy matplotlib理由 python環境であればpyenvとか利用すれば、環境は分離できるのですが、 利用しているPCがMacとWindowsの両方あります(Macの方が性能が低いです)、 Macの方がプログラミングはしやすいのですが、 深層学習には軽い実験をするのにもマシンパワーが必要となるため、 実行だけはWindowsでやりたいわけです。 MacとWindowsで同じように動く環境を構築するのがめんどくさいという理由です。\n注意 Dokcerと深層学習のフレームワーク Tensorflowを利用するならばDockerに公式があります TensorflowのDockerイメージは、Docker Hubにあります。\nPUBLIC REPOSITORY:tensorflow/tensorflow\n上記イメージは、python2.7になります。 python3系のdockerイメージは公開されていないそうです。 python3系でTensorFlowを利用したい場合は、 公式からForkしてPython3対応を公開されている方がいらっしゃいましたので、 以下を利用すれば良いと思います。\n khm/tensorflow: branch/feature-py3 TensorFlow の Docker Image を Python3 で動かす  その他  Docker Habに公式イメージがあるフレームワーク  PUBLIC | AUTOMATED BUILD chainer/chainer   公式が見つからなかったフレームワーク  Caffe DeepDream    MacとWindowsではGPUの利用はできません 深層学習で遊ぶためにはGPGPUを利用した方が高速に処理できます。 (場合によってはCPUでは現実時間で終わりません。) ただし、MacかWindowsでDockerを利用する場合、GPUデバイスにアクセスできないため、 CPU実行しかできません。 必要に応じてLinux環境が純粋に入っているPCを用意する必要がありそうです。\n作業  Docker Hubから公式のpythonイメージを選びます pip installでnumpyとmatplotlibをインストールします  (注意1) matplotlibはグラフ描画しようとした時に、 ディスプレイ設定がおかしいと行ってエラーが発生します。 基本的には、import時に下記のようにすることで対処できるそうです。\nimport matplotlib matplotlib.use(\u0026#39;Agg\u0026#39;) import matplotlib.pyplot as plt (注意2) Dockerで起動しているので、xdisplayとかめんどくさいので、 画像出力して確認すればいいと思うので、下記のように実行します。\nimport matplotlib matplotlib.use(\u0026#39;SVG\u0026#39;) import matplotlib.pyplot as plt fig = plt.figure() ax = fig.gca() ax.plot([1, 2, 3]) fig.savefig(\u0026#39;hoge.svg\u0026#39;) WindowsでC:/User配下以外をマウントする方法 WindowsでC:/Users配下以外をマウントする場合は、 VirtulBox(Docker Toolboxを利用しています)でコンテナを起動するホストマシンの 共有フォルダを追加します。 例えば、C:/workフォルダを共有したい場合は、C:/workとc/workのように記載します。 (これはデフォルトで設定されているc:/usersに合わせて記載しています)\n次に下記のようにコマンドを実施し、ホストマシンにマウントします。\n$ docker-machine ssh dev \u0026#39;sudo mount -t vboxsf -o uid=0,gid=0 c/work /c/work\u0026#39; 失敗 Alpineでやろうとしたらnumpyインストールができず python3.5.2-alpineをベースとして、 numpyとmatplotlibをインストールしようとしたのですが、 numpyのインストールができず諦めました。 alpineをベースとして実現している方はいらっしゃるので、 きちんとやればできるのでしょうか、今回は時間かかりそうなのでやめました。 blasとlapackはインストールできたのですが、 numpyのインストールでエラーが発生していました。\nCommand \u0026#34;/usr/local/bin/python3.5 -u -c \u0026#34;import setuptools, tokenize;__file__=\u0026#39;/tmp/pip-build-tv7btsqy/numpy/setup.py\u0026#39;;f=getattr(tokenize, \u0026#39;open\u0026#39;, open)(__file__);code=f.read().replace(\u0026#39;\\r\\n\u0026#39;, \u0026#39;\\n\u0026#39;);f.close();exec(compile(code, __file__, \u0026#39;exec\u0026#39;))\u0026#34; install --record /tmp/pip-4d9kyt_m-record/install-record.txt --single-version-externally-managed --compile\u0026#34; failed with error code 1 in /tmp/pip-build-tv7btsqy/numpy/ ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/pythonenvwithdocker/","tags":["software"],"title":"Python開発環境をDockerで構築します"},{"categories":null,"contents":"概要 Windows環境下でTensorFlowをGPU利用で動作させたかったので、 最近追加されたWindows機能である Bash On Ubuntu On Windowsを利用できないか調査しました。 結論としては、現時点ではBash On Ubuntu On WindowsからGPUは使えないそうです。\nWindowsでビルドしてGPUで動作させたい場合は、 cmakeに記載の方法を利用するしかなさそうです。\nGPU利用できないソース OpenCL \u0026amp; CUDA GPU supportによると、 今のところは対応してくれなさそうです。 (コメントを見る限りTensorFlowで使いたいという人もいるようです。) MSさん頑張って対応してとしか言えないですね。\n It’s on the backlog, but not currently planned.\nWe know many of you would like to be able to accelerate your numerical analysis code via CUDA/OpenCL, etc.\nOne thing to explore in the meantime is to try running your code in Windows. Windows actually has very powerful GPU-acceleration capabilities and you may well find that much of your existing code may well work already or require trivial effort to port to Windows itself.\n ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/tensorflow/bashonubuntuonwindows/","tags":null,"title":"Bash On Ubuntu On WindowsのGPU利用は(現時点では)できないそうです"},{"categories":null,"contents":"利用できそうなLogger  Plog - portable and simple log for C++  ヘッダファイルのみで構成されているLoggerです。 License: Mozilla Public Lisense 2.0   log4cxx glog Boost.Log EasyLogging++ spdlog  License: MIT License    各Loggerのちょっとしたメモ Plog 2016/11/16現在でも更新されています。 ヘッダファイルだけで構成されているため、cloneしてパスを通せば利用できそうです。 利用方法については、Qiitaで記事が書かれていたので、こちらを参照してください。\nspdlog 2016/11/16現在も更新されています。 Plog同様にヘッダファイルのみで構成されているようです。 処理速度重視のようです。 利用方法については、ブログに記事がありましたので、こちらを参照してください。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/cpp/cpplogger/","tags":null,"title":"C++で利用できそうなLoggerを調べました"},{"categories":null,"contents":"Hugo + Tex 私の場合メモするときは、PC使えるならばmarkdown型式のテキストで保存します。 ただ、よく数式をメモしたいときに書けなかったので、かける方法を探したところ、 markdown+Texができるようでしたので導入しました。 (Tex記法には慣れていないと書きにくいかもしれません)\n現在は、サイトジェネレーターとしてHugoを利用しており、今回はmathjaxを導入します。 (別にHugoでなくてもjsを読み込めば使えるはずです。) 導入すると下記のようにインラインと一行分の挿入の両方ができるようになります。\n  インライン表示: $F(x) = \\sum_{n=1}^{N} \\frac{1}{N}$\nMarkdownでは、$を一つ利用して下記のように記述しています。\n$F(x) = \\sum_{n=1}^{N} \\frac{1}{N}$   一行表示 $$ F(x) = \\sum_{n=1}^{N} \\frac{1}{N} $$\nMarkdownでは、$を二つ利用して下記のように記述しています。\n$$F(x) = \\sum_{n=1}^{N} \\frac{1}{N}$$   加えて、Atomの場合は、パッケージを追加することでプレビューしながら編集できます。\n設定方法 Hugo編 設定方法については、下記の2つのページを参考にしています。\n HuGo に Mathjax を入れて数式を表示できるようにした MathJax の導入  違いとしては、header.htmlではなくfooter.htmlに記載しました。 前半のスクリプトでインライン表示ができるようになります。\n\u0026lt;!--tex --\u0026gt; \u0026lt;script type=\u0026#34;text/x-mathjax-config\u0026#34;\u0026gt; MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#34;\\\\(\u0026#34;,\u0026#34;\\\\)\u0026#34;]] } }); \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0026#34; /\u0026gt; \u0026lt;/script\u0026gt; Atom編 追加するパッケージは、markdown-preview-plusとmathjax-wrapperになります。 markdown-preview-plusがインストールできた段階で、 インストール済みのパッケージからmarkdown-previewをdiableにします。\nその他 $後の空白 インライン数式表示において、$ の後に空白を開けても htmlの方はきちんと数式になります。 ただし、Atomの方では $ の後ろに空白があると数式と認識してくれず、 プレビュー画面で表示されないです。\nKaTex 他の方法として、 Better TeX math typesetting in Hugoのような方法もありました。 こちらはshortcodeを利用していることや、 記事に数式がある時だけjsファイルの読み込みをするといったことができているようです。 ただ、今回の場合はAtomでのプレビューとHugoで 同じ表記で表示が同時にできなかったので採用しませんでした。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hugotex/","tags":["software"],"title":"Hugoで数式を導入します"},{"categories":null,"contents":"JekyllからHugoに環境を以降しました。 その時に行った作業のメモになります。 Macでの環境構築になりますが、 基本的にhugoをインストールしてthemeを設定しただけになります。 jekyllではread moreをプラグインで挿入しなければなりませんでしたが、 hugoでは標準で装備されていたりと設定が楽でした。\n(2016/11/20追記) Bash On Ubuntu On Windowsを利用して、Hugo環境を構築した時のメモを追記しました。 基本的にUbuntuでのインストール方法と同じになります。 (今回はバイナリを公式サイトからダウンロードしてインストールする方法を利用しました。)\n作業手順   Hugoをインストールします。\n$ brew file brew install hugo Ubuntuの場合は、.debファイルをダウンロードしてきてインストールします。 (環境に合わせて適切なファイルをダウンロードして下しさい。)\n$ sudo dpkg -i hugo_0.17-64bit.deb   Hugoを利用して新規サイトを作成します。 今回の例では、新しくhoge-siteを作成する例になります。\n$ hugo new site hoge-site   Hugoのテーマを設定します。 今回は、Hugo Theme Siteさんから BLACKBURNを選択しました。 理由は、シンプルな構成であることとcssのみで構成されており軽そうなことです。\n$ cd hoge-site $ mkdir themes $ cd themes $ git clone git@github.com:yoshiharuyamashita/blackburn.git blackburn   Themeが適用されてサイトが構築できるかサーバーを建てて確認します。 今回は、blackburnのthemeになりますが、 任意のthemeを利用した場合はblackburnの部分を設定したthemeに変えてください。\n$ cd .. $ hugo server -t blackburn   サイトの設定を記載します。\ntitle = \u0026#34;hoge\u0026#34; baseurl = \u0026#34;\u0026#34; languageCode = \u0026#34;ja-jp\u0026#34; theme = \u0026#34;blackburn\u0026#34; canonifyurls = true # 相対パスではなくbaseurlを基準とした絶対パスとする [params] description = \u0026#34;hoge\u0026#34; author = \u0026#34;hoge\u0026#34; [taxonomies] category = \u0026#34;categories\u0026#34; tag = \u0026#34;tags\u0026#34;   HugoのRead more Hugoではデフォルトで要約(Summary)と本文に分けてくれる機能があります。 おおよそ70単語らしいのですが、英語でないと分けてくれません…。 そこで強制的に要約部分と本文を分割するために、\n\u0026lt;!--more--\u0026gt; を挿入します。 ただし、余分にスペースを開けると認識してくれません。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hugosetup/","tags":["software"],"title":"Hugoの初期設定"},{"categories":null,"contents":"gitを利用していたら突然Could Not Execute Editorと言われたので解決方法です。 原因はよくわかっていないので、本当の対処方法があると思います。\n対処方法は、.gitフォルダにあるconfigファイルに以下を記載します。\n[core] editor = /usr/local/bin/vim ここで記載するvimへのパスは、以下のコマンドで確認できます。\n$ which vim ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/gitcouldnotexecuteeditor/","tags":["git"],"title":"gitでCould Not Execute Editorと言われた時の対処法"},{"categories":null,"contents":"Mac(El Capitan)へのElectron + coffee-script環境の導入手順。\n概要 MacにElectron + coffee-scriptでマルチプラットフォームのアプリ作成環境を構築する方法です。 Electronで作成するだけなら、JavaScriptでコードを記述すればOKですが、 どうせなら記述しやすいcoffee-scriptで記述できるように環境を若干いじっています。\n今回作成したソースコードのリポジトリは、ここです。\nElectronが動作する環境を作成する  node.jsをインストールします。  $ brew file brew cask install node  Electronをインストールします。  $ npm -g install electron-prebuilt ElectronでHello Worldを作成する プロジェクト用フォルダを新規に作成し、そこで作業を行うことを前提に説明します。 今回の説明では、関連するコードは全てフォルダ直下に展開する前提となります。 実際には、gitなど他の管理ファイルも置かれることになるため、 サブディレクトリを作成し、その中にソースコードを置く方が整理しやすいと思います。\n プロジェクトの作成  以下のように初期化を実行すると、 package.jsonが自動で生成されます。\n$ mkdir test $ cd test $ npm init -y  main.js の作成  \u0026#39;use strict\u0026#39;; // アプリケーションをコントロールするモジュール var app = require(\u0026#39;app\u0026#39;); // ウィンドウを作成するモジュール var BrowerWindow = require(\u0026#39;browser-window\u0026#39;); // メインウィンドウはGCされないようにグローバル宣言 var mainWindow = null; // すべてのウィンドウが閉じたら終了 app.on(\u0026#39;window-all-closed\u0026#39;, function() { if (process.platform != \u0026#39;drHarwin\u0026#39;) { app.quit(); } }); // Electronの初期化完了後の実行 app.on(\u0026#39;ready\u0026#39;, function() { // メイン画面の表示。  // ウィンドウ幅、高さを指定できる。  mainWindow = new BrowerWindow({width: 800, height: 600}); mainWindow.loadURL(\u0026#39;file://\u0026#39; + __dirname + \u0026#39;/index.html\u0026#39;); // ウィンドウが閉じられたらアプリも終了  mainWindow.on(\u0026#39;closed\u0026#39;, function() { mainWindow = null; }); });  index.htmlの作成  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Sample\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello World.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  アプリケーションの簡易実行  以下のコマンドを作業ディレクトリ(test)で実行することでアプリケーションが起動します。\n$ electron ./ アプリケーションを配布可能な状態にする アプリケーションを配布形式にするため、windowsならexe、maxならappにする方法を説明します。 Electronの環境を一緒に配布してあげることで環境構築していない人でも使えるようになります。\n electron-packagerのインストール  $ npm install -g electron-packager  アプリケーションの作成  以下のコマンドでMacとWindows用のアプリケーションが作成されます。\n$ electron-packager ./ sample --out=./bin/ --platform=darwin,win32 --arch=x64 --version=0.36.2 各引数の意味を簡単に説明しておきます。\n 第1引数: プロジェクトフォルダへのパス 第2引数: 生成するアプリケーション名 out: 出力フォルダの指定。指定しなければコマンド実行したフォルダに生成される。 paltform: Windows用やmac用などのどれを作成するか。  選択肢: darwin = Mac, win32 = Windows, linux, all   arch: アーキテクチャの選択(32bit or 64bit)  選択肢: ia32 = 32bit, x64 = 64bit, all   version: Electronのバージョン   2015/12/28現在で、0.36.2\n  調べ方は以下のコマンドを実行する。\n$ electron --version     coffee-scriptで記述できるようにする JavaScriptで全部書くのは大変なので、coffee-scriptを利用出来るようにする。\n package.jsonにdependenciesを追記  \u0026#34;dependencies\u0026#34;: { \u0026#34;electron-prebuilt\u0026#34;: \u0026#34;^0.36.2\u0026#34;, \u0026#34;coffee-script\u0026#34;: \u0026#34;^1.10.0\u0026#34; },  index.htmlを改変する。  改変部分の主なところは、まずヘッダ部分に以下のスクリプトを追加します。\n\u0026lt;script\u0026gt; window.onload = function() { require(\u0026#39;coffee-script\u0026#39;).register(); require(\u0026#39;./renderer.coffee\u0026#39;) } \u0026lt;/script\u0026gt; そして、coffee-scriptから記述する部分を決定するためdivタグにidを設定します。\n\u0026lt;p\u0026gt;\u0026lt;div id=\u0026#34;greetings\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/p\u0026gt;  renderer.coffeeにスクリプトを作成  greetings = document.getElementById \u0026#39;greetings\u0026#39; greetings.innerHTML = \u0026#34;hello, world.\u0026#34;  依存パッケージのインストール  coffee-scriptをローカルにインストールします。 グローバルインストールでも動作すると思ったんだけど、 なぜか動作しなかったのでローカルインストールに変更しました。\n$ npm install  実行  $ electron ./ 参考情報  [electron][electorn]  Quick Start   Qitta: 30分で出来る、JavaScript (Electron) でデスクトップアプリを作って配布するまで Qitta: Electron + CoffeeScript  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/electronenv/","tags":["electron","coffeescript"],"title":"Mac環境へのElectron導入方法"},{"categories":null,"contents":"HerokuのFreeプランでは1日6時間のSleep時間が設けられているが、それ以外の時間は起動し続けるように設定する方法。\n方法 基本的な考え方としては、hubot-heroku-keepaliveで18時間の間アクションを一定間隔で行い、時間いっぱい使ったらherokuが停止するので、6時間後にaddon:schedulerで起こすということをします。 そのため、以下の設定を行います。\n hubot-heroku-keepaliveの導入します。 addonのスケージュールを導入します。  hubot-heroku-keepaliveの導入方法 hubot-heroku-keepaliveを利用して、18時間の間、起きっぱなしになるように一定間隔でherokuにアクションを起こします。\n hubot-heroku-keepaliveの説明にあるように、以下のコマンドでhubotの環境にプラグインを導入します。  $ npm install hubot-heroku-keepalive --save  設定ファイル(external-scripts.json)にプラグインを追記します。  { \u0026#34;hubot-heroku-keepalive\u0026#34; }  環境変数の設定をします。  各環境変数は上から、起きる時間、寝る時間、設定した時間のリージョン、置きっぱなしにするアプリのURLになります。 起きる時間(HUBOT_HEROKU_WAKEUP_TIME)と寝る時間(HUBOT_HEROKU_SLEEP_TIME)の間が 6時間 以上空いている必要があります。 基本的には自分が寝ていると思う時間に設定しておけばいいと思います。\n$ heroku config:add HUBOT_HEROKU_WAKEUP_TIME=8:00 $ heroku config:add HUBOT_HEROKU_SLEEP_TIME=24:00 $ heroku config:add TZ=\u0026#39;Asia/Tokyo\u0026#39; $ heroku config:set HUBOT_HEROKU_KEEPALIVE_URL=$(heroku apps:info -s | grep web-url | cut -d= -f2) keepaliveのページでは、 grep web_url となっていましたが、 heroku apps:info -sで得られる値を見ると grep web-urlが正解のようです。\naddonのschedulerを導入する hubot-heroku-keepaliveは、起きている間は寝ないようにすることができます。 しかしながら、寝てしまうと起こすことはできないので別の機能を用います。 ここでは、addonのschedulerを利用します。\nスケジューラの導入は以下のコマンドでできます。\n$ heroku addons:create scheduler:standard ただし、クレジットカード情報を入力していないとaddonが使えないです。 そのためカード情報は、herokuのページから登録しておいてください。 このaddon自体は無料の範囲で利用するため料金が発生することはないはずです。 一度導入したらクレジット情報を消してしまってもいいかもしれません。\nスケジューラを導入したら、起こすタイミングを設定します。 以下のコマンドでherokuのaddon設定ページを開いて、WEBで設定します。\n$ heroku addons:open scheduler 入力するのは、以下のコマンドとherokuのdynoを起動する時間になります。 ここでの入力時間は、UTCのため日本時間より9時間マイナスになります。 今回のHUBOT_HEROKU_WAKEUP_TIMEだと8:00起動の予定なので、23:00と設定する必要があります。\n$ curl ${HUBOT_HEROKU_KEEPALIVE_URL}heroku/keepalive ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hubotkeepalive/","tags":["software"],"title":"HerokuのFreeプランでアプリを最大限起動しっぱなしにする方法(1日18時間まで)"},{"categories":null,"contents":"Hubotの動作用にHerokuのアカウントを登録したので、そのときやったことを覚書として残しておきます。\n概要 のアカウント作成方法。\nHerokuのアカウント  Herokuにアクセスして、Sign Upする。 名前とかメールアドレスを聞かれるので入力する。 メールアドレスに確認用メールが来るのでアクセスしてアカウントの有効化とパスワードを入力する。 Herokuを操作するためのToolbeltを導入する。 これを入れないとデプロイもできないので入れる必要がある。  $ brew cask install heroku-toolbelt 正しくHeroku toolbeltが導入されたかチェックする場合は、バージョン情報を確認します。\n$ heroku version  HerokuにSSHキーを登録する。 HerokuにコマンドラインからHerokuにログインするとメールアドレスとパスワードが聞かれるので入力する。 ここでSSHキーがローカルにないと作成するか聞かれるらしいので、そのときはYESとする。(私の場合は、すでにSSHキーがあったので何もせずにログイン成功。)  $ heroku login 参考情報 Mobage developers blog: 初心者でも15分で公開できるHerokuのはじめかた\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/herokusignup/","tags":["software"],"title":"Herokuアカウントの作成方法"},{"categories":null,"contents":"HubotをSlackと接続するところまでできたので、自分用にカスタマイズするためにスクリプトを作ろうと思う。 プログラムの練習をするのときの定番であるHello Worldを表示するまでの記録です。\n結論 hubotのディレクトリでscriptsフォルダの下にcoffeeスクリプトをおけばhubot起動時に自動で読み込まれます。 coffeeスクリプトが書ければ簡単に導入できる。\nHello World helloと名称指定してよびだしたら返事をするスクリプトは以下のようになります。\nmodule.exports = (robot) -\u0026gt; robot.respond /hello/i, (msg) -\u0026gt; msg.send \u0026#34;Hello, ${msg.message.user.name}\u0026#34; respond 相手を指定して呼び出された場合に反応します。 SlackだとDirect messageかメンション付きだと反応する。\n@bot: hello 対象を決めずに、どの発言でも対象とする場合は、 hear を利用する。\nmsgオブジェクト 発言に関する情報が含まれているオブジェクトになります。 msg.sned 関数を利用すると発言が来たチャネルに対して返信することができます。\nまた、 $(msg.message.user.name) とすると、発言者の名前を取得することができます。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/hubotscripttutorial/","tags":["hubot"],"title":"HubotのHello Worldスクリプトの作成方法"},{"categories":null,"contents":"SlackにHubotを導入してChatOpsをやってみようと思ったので、その実行環境を整えるための準備についての覚書です。\nHubot開発環境の導入 前提として、開発環境はMacです。 Hubotを自分の環境で動かせたほうが試行錯誤しやすいので、まずは自分のPCに開発環境を導入します。\n node.js npm: node.jsのモジュール管理ソフト yo: Hubotの生成用  導入用のコマンドは、homebrewを利用することを前提に以下のコマンドを実行する。\n$ brew cask install node $ brew cask install npm $ npm install -g yo generator-hubot Hubotをシェルで起動 まずはshellで起動する。 それから、適切に起動できているか確認するため、pingコマンドを実行してみる。 PONGと帰って来れば成功。\n$ bin/hubot -a shell -n XXX XXX\u0026gt; XXX ping XXX\u0026gt; PONG Slackアダプターの導入 Yeomenジェネレーターでhubotを導入している場合は、すでにSlackアダプターが導入されていました。 確認方法は、npmからアダプターのリストを取得してみる。\n$ npm list hubot-slack hubotcustom@0.0.0 /XXX/YYY/ZZZ └── hubot-slack@3.4.1 Herokuのアカウントと開発環境の導入  Herokuにアクセスして、サインアップします。 Heroku toolbeltを導入する。  $ brew cask install heroku-toolbelt Herokuへデプロイ  Hubotのディレクトリをgitリポジトリにする。 私の場合は、基本GitHubのリポジトリをリモートに設定するので、先にGitHubでリポジトリを作成してから、cloneする。  $ git clone \u0026lt;hoge repository\u0026gt;  コマンドでHerokuアプリを作成する。 アプリ名を入れないとHerokuが勝手に名前をつけるので、何のアプリわからなくなるので注意。  $ heroku create hogehoge  Herokuにpushする。 基本的に、masterブランチで作業することはないので、開発中のブランチからmasterブランチにpushした。  $ push heroku dev:master Herokuへのデプロイ元をGitHubに変更する コード管理をGitHubで行うとするとHerokuのgitでなくてもいいので、GitHubとの連携を行う。\n Herokuの連携からGitHubを指定する。  \n GitHubの連携を有効化する。 デプロイ元となるリポジトリとブランチを指定する。 自動でデプロイする項目をONにする。 デプロイ元のブランチをhogeRepo/deployとしたので、deployブランチにpushする。  $ push origin dev:deploy  連携が成功していればHerokuのアクティビティにdeploy履歴が表示される。  Herokuのフリープランだと30分くらいアクセスがないと停止するので、再起動が必要な場合がある。 その場合は、以下のコマンドで再起動する。\n$ heroku restart SlackとHubotを連携する  SlackのIntegrationsからHubotを選択する Hubotの名前を入れてConnetする TOKENが表示されるのでHerokuに設定を加える。  $ heroku config:set ¥ HUBOT_SLACK_TOKEN=xxx ¥ HUBOT_SLACK_TEAM=yyy ¥ HUBOT_SLACK_BOTNAME=zzz 注意 hubotとcoffee-scriptを利用してインストールという方法もあったが、私の環境ではエラーが発生しました。\n実行パターン:\n$ npm install -g coffee-script $ npm install -g hubot エラー:\n\u0026#39;hubot --create\u0026#39; is deprecated. Use the yeoman generator instead: npm install -g yo generator-hubot mkdir -p SampleBot cd SampleBot yo hubot See https://github.com/github/hubot/blob/master/docs/index.md for more details on getting started. yoとgenerator-hubotを利用すれば正常に動作するHubotが生成できました。\nログ hubotの生成時 $yo hubot _____________________________ / \\  //\\  | Extracting input for | ////\\  _____ | self-replication process | //////\\  /_____\\  \\  / ======= |[^_/\\_]| /---------------------------- | | _|___@@__|__ +===+/ /// \\_\\  | |_\\ /// HUBOT/\\\\ |___/\\// / \\\\ \\  / +---+ ? Description A simple helpful robot for your Company ? Bot adapter (campfire) slack ? Bot adapter slack create bin/hubot create bin/hubot.cmd create Procfile conflict README.md ? Overwrite README.md? overwrite force README.md create external-scripts.json create hubot-scripts.json conflict .gitignore ? Overwrite .gitignore? overwrite force .gitignore create package.json create scripts/example.coffee create .editorconfig _____________________________ _____ / \\  \\  \\  | Self-replication process | | | _____ | complete... | |__\\\\| /_____\\  \\  Good luck with that. / |//+ |[^_/\\_]| /---------------------------- | | _|___@@__|__ +===+/ /// \\_\\  | |_\\ /// HUBOT/\\\\ |___/\\// / \\\\ \\  / +---+ \\____/ | | | //| +===+ \\// |xx| - \u0026gt; ws@0.4.31 install /XXX/YYY/ZZZ/node_modules/hubot-slack/node_modules/slack-client/node_modules/ws \u0026gt; (node-gyp rebuild 2\u0026gt; builderror.log) || (exit 0) CXX(target) Release/obj.target/bufferutil/src/bufferutil.o hubot-maps@0.0.2 node_modules/hubot-maps hubot-help@0.1.2 node_modules/hubot-help hubot-google-images@0.2.3 node_modules/hubot-google-images hubot-shipit@0.2.0 node_modules/hubot-shipit hubot-heroku-keepalive@1.0.0 node_modules/hubot-heroku-keepalive hubot-diagnostics@0.0.1 node_modules/hubot-diagnostics hubot-rules@0.1.1 node_modules/hubot-rules hubot-pugme@0.1.0 node_modules/hubot-pugme hubot-google-translate@0.2.0 node_modules/hubot-google-translate hubot-redis-brain@0.0.3 node_modules/hubot-redis-brain └── redis@0.8.4 hubot-scripts@2.16.2 node_modules/hubot-scripts └── redis@0.8.4 hubot@2.16.0 node_modules/hubot ├── optparse@1.0.4 ├── cline@0.8.2 ├── async@0.9.2 ├── log@1.4.0 ├── scoped-http-client@0.11.0 ├── coffee-script@1.6.3 ├── chalk@1.1.1 (escape-string-regexp@1.0.3, ansi-styles@2.1.0, supports-color@2.0.0, strip-ansi@3.0.0, has-ansi@2.0.0) ├── connect-multiparty@1.2.5 (qs@2.2.5, on-finished@2.1.1, type-is@1.5.7, multiparty@3.3.2) └── express@3.18.1 (basic-auth@1.0.0, cookie@0.1.2, merge-descriptors@0.0.2, utils-merge@1.0.0, fresh@0.2.4, media-typer@0.3.0, content-disposition@0.5.0, range-parser@1.0.3, vary@1.0.1, escape-html@1.0.1, cookie-signature@1.0.5, parseurl@1.3.0, methods@1.1.0, depd@1.0.1, commander@1.3.2, debug@2.1.3, etag@1.5.1, send@0.10.1, proxy-addr@1.0.8, mkdirp@0.5.0, connect@2.27.1) hubot-slack@3.4.1 node_modules/hubot-slack └── slack-client@1.4.1 (log@1.4.0, coffee-script@1.9.3, ws@0.4.31) Hubot起動時 Hubotをとりあえず起動した時のログ。\n$bin/hubot -a shell -n XXX XXX\u0026gt; [Tue Nov 03 2015 11:02:11 GMT+0900 (JST)] ERROR hubot-heroku-alive included, but missing HUBOT_HEROKU_KEEPALIVE_URL. `heroku config:set HUBOT_HEROKU_KEEPALIVE_URL=$(heroku apps:info -s | grep web_url | cut -d= -f2)` [Tue Nov 03 2015 11:02:11 GMT+0900 (JST)] INFO hubot-redis-brain: Using default redis on localhost:6379 参考情報 Qiita: Hubot のインストール KayamaMemo: githubから自動でherokuにデプロイ\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/hubotinheroku/","tags":["software"],"title":"HubotをHerokuで動かすまで"},{"categories":null,"contents":"複数人でのソフトウェアの開発や在宅ワークなど働き方が多様化している中で、コミュニケーションツールとして旧来までのメールシステムに代わりチャットツールがある。 メールシステムにも良さはあるもののフロー型のツールとしてはチャットツールの方が優れている点も多い。 そこで、今回はチャットツールで最近(といっても結構経つが)ホットなSlackを導入し、Windows、Mac、Androidで共通の環境を利用できるまでの方法についてまとめる。\n目標 Windows、Mac、Androidの環境でSlackが利用できる。\n導入方法 Slackのアカウント作成編 まずは、Slackにチームアカウントを作成する必要がある。 チームアカウントを作るには、Slackにアクセスし、Sign inすれば良い。 ただし、ここでSlackは複数人での利用を想定している。 (当然のことながらチャットツールは相手がいて成り立つので1人で利用することはないということらしい。 ただし、別途記載するがBotを利用すれば個人での利用でも十分有用であると思う。 別に一人で利用するならば適当な名称を入力してアカウントを作成して一人で使えば良い。)\nこれさえ終われば、チームアカウントが作成され登録したメールアドレスにチームアカウント登録のメールが届く。 届いたメールから登録メールアドレスの個人アカウントのパスワード入力の設定画面へ飛べるので設定する。 ここが面白いところだが、全く新規に始めようとした場合、チームアカウントが作成された時点でパスワード入力なしにSlackのチームアカウントにアクセスした状態が表示される。 そのためいつの間にか設定が終わった気になるが、アカウントにパスワードが設定されていないので、この後別の端末からログインしようとした時に、チームにアカウントに個人アカウントが登録されていないと表示される。\n個人アカウントのパスワードまで設定できれば、Slackアカウントの作成が終わりである。 これ以降、Web版でのみ全ての端末からアクセスするならば以降の設定は必要ない。\nWindowsクライアントの導入編 非常に簡単で以下のクライアントソフトのダウンロードページからソフトをダウンロードしインストールするだけで利用できる。 利用では、Slackアカウントの作成編で作ったチームアカウントと個人用アカウントを入力すれば良い。\nAndroidクライアントの導入編 これもクライアントソフトをGoolge playよりダウンロードしソフトをインストールするだけ。 アカウントの設定も一緒。\nMacでのクライアント導入編 同様にクライアントソフトをインストールできる。 Homebrewを利用してインストールソフトを管理しているので、Caskroomが入っている前提で以下のコマンドでインストールできる。\n$ brew file brew cask install slack ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/platformforit/","tags":["slack"],"title":"Gmailにはない開発環境を求めて"},{"categories":null,"contents":"Minecraftのmod作成するためにMacに環境構築したので、その時のメモ。\n概要 今回は前提modとしてforgeを利用する。 forgeは多くのmodで前提modとなっているので、導入の障害にはなりにくいかと思う。 自分がmodで遊ぶ時は、まずforgeを導入してしまうので自分が使いたいmodを開発するのには何の問題もない。\nただし、forgeの対応がminecraftの最新バージョンには追いついていないので、開発できるバージョンはforgeに依存することになる。 2015/10/20現在において、minecraftは1.8.8までバージョンがアップデートされている。 が、forgeは1.8までしか対応していない。\n加えて、今回の開発環境はeclipseとかIDEAとか利用しない予定です。 参考にしたのは、ここです。感謝。\n forgeから開発したいバージョンのソースファイルをダウンロードする。 ダウンロードしたソースファイルのフォルダ内にて、以下のコマンドを実行する。  $ cd forge $ ./gradlew setupDecompWorkspace  以下のコマンドでminecraftを実行し、開発環境が構築されたか確認する。  $ ./gradlew runClient 詳細 forgeのダウンロード modを導入して遊ぶ場合は、forgeからinstallerをダウンロードする。 けれども今回の場合、開発環境が必要なためinstallerではなくsrcをダウンロードする。\ngitリポジトリへの登録 プログラムを開発する時は、ソースコードの管理はバージョン管理システムに任せたほうが楽だし、簡単なので、gitリポジトリへの登録用.gitignoreを作成します。\n管理が必要なのは、gradle関連と開発したソースコード(ここ重要でminecraftのソースコードは自分で変更しない限り管理しない)なので、それ以外を除外リストに追加。\n今回作成した.gitignoreファイルはここ。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/minecraft/envforminecraftmodcreator/","tags":["minecraft"],"title":"Minecraftのmod作成環境を構築した時のメモ(Mac編)"},{"categories":null,"contents":"Minecraftのバージョンが1.8(1.8.xではなく1.8)のときのmod構成\n導入mod  Forge Lite Loader  Forge系  cutall, digall, mineall: 一括破壊系 Death Chest: 死んだ場所にチェストでアイテムを保存する Spawn Checker: スポーン場所の可視化 Strage Drawers: 多機能ストレージ  Chameleon: Strage Drawersの前提mod(1.8版のみ)   Little Maid Mob: 言わずと知れたメイド追加mod  EBLib: Little Maid Mobの前提mod。作者のページにて公開されている。   竹mod: 和風建築用mod Inventory Tweaks: インベントリのソート用  Lite Loader系  Voxel map: 地図mod  リソースパック  Faded Dreams Resource Pack: リソースパック(巨大建築向けらしい)  なぜか.rar形式で配布されていたのでいったん解凍してzipで圧縮しなおしたら認識した。   LB Photo Realism: 高精細な写実的な雰囲気らしい Misa's Realistic Resource: これもリアル系らしい   シェーダー  shaders mod: 影modの本体 SEUS: 基本中の基本 Sildure's shaders: ちょっと太陽光のフレアとかが抑え気味 LAGLESS SHADERS:  暗さとかはちょうどいい感じ。だけどトーチが手に持った状態で明るくならない。 Spawn checkerの表示が消えてしまう…。   MrMeepz\u0026rsquo; shaders: ちょっと赤みが強いかな。でも夜は光源なしで何も見えなくはならない。  導入してないmods  Optifine: なぜか文字化けしてしまったのでとりあえず入れない。 Not Enough Items: レシピ確認など(色々できるけど基本はレシピ確認)  Code Chicken Core: Not Enough Itemsの前提mod   Waila: ゲーム中でItemのIDを知るためのmod(cutallなどのIDを追加するときに使う)  1.8からIDじゃなくて名称に変わった?名称ならばWaliaでなくてもいいので、今回は除外   Inventory Sorter: インベントリのソート用  MCPatcherを使わないと入らないっぽいので代わりにInventory Tweaksを使うことにした。   MO\u0026rsquo; BENDS: プレイヤーとモンスターのアニメーション追加  イベントリのキャラクターが挙動不審になったので(プルプル震え続ける)、導入停止。    前提modの導入方法 ForgeとLite Loaderは共存できるので、共存させる。 ただし、Lite Loaderは1.8への対応が開発版らしいので問題が発生しても対応できない。\nまずは、Forgeをダウンロードし、インストーラからインストールする。 その後、lite loaderの1.8対応バージョンをダウンロードし、jarファイルを起動する。 ここで、インストールを選択せずに、Extract jar fileを選択し、jarファイルを抽出する。 抽出したjarファイルをmodsフォルダに配置することでlite loaderのmodを利用できるようになる。\nminecraftを起動し、右中央ちょっと上に鶏のタブが出せるようになっていればOK。 lite loaderのmodは、modsフォルダの下のバージョン名フォルダに入れる。 例えば今回の場合は、versions/1.8-forge/mods/1.8のフォルダに.litemodファイルを置く必要がある。\nエラー発生 Not Enough Itemsを利用すると地下(y=10)くらいでクラッシュした。 たぶん他の何かと干渉しているんだと思うけど原因不明(他のmodは除いてもクラッシュが治らなかった)ので、 今回はNEIを使わないことにした。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/minecraft/minecraftmods1_8/","tags":["minecraft"],"title":"Minecraft 1.8のmod構成メモ"},{"categories":null,"contents":"Windows環境でvirtualenv環境を構築したときのメモ。\n概要 目標はmacと同じ環境を作成し動作すること。 私が持っているMacのスペックは非常に低いので、計算が重くなると実行速度に難がでる。 そこで、スペックが高いWindowsマシンでMacで作成したプログラムが動作することが目標。\n注意点として、pythonはchocolateyでインストールしているので、プログラムの位置関係は適時合わせてください。\nvirtualenvの導入 まずは、chocolateyでpython3.4がインストールされている前提。 この状態だと、pythonはpowershellから起動するが、pipなどにパスが通っていない。 以下のコマンドで環境変数を追加する。 ただし、固定してないので、powershellをクローズすれば、この設定は消える。\n$ $Env:Path += \u0026#34;;C:/tools/python3/Scripts\u0026#34; そうすればpipが利用できるので、以下のコマンドでvirtualenvを導入する。\n$ pip install virtualenv virtualenvの環境作成は、以下のコマンドでできる。 hogeの部分をパスで指定すれば、そこにフォルダが作成されファイルが管理される。\n$ python -m virtualenv hoge 作成した環境を利用するには、hoge/Scriptsフォルダのactivateを実行する。 cmdだとdeactivate.batもあるんだけど、ps1はactivate.ps1しかないのはなぜだろう。 まあ、環境を早々変えることはないので、変えたくなったら別のpowershell開くかすればいいか。\nで、macのほうで書き出したpackages.txtファイルを利用してpipで一括インストール。\n$ pip install -r ./packages.txt これで一筋縄でいかんのだよねぇ。 numpyとmatplotlibでインストールエラー発生。\nnumpyとmatplotlibのインストール インストールされないのでなぜかなと調べてみると、32bit版しかwindows用はないと…。 しょうがないので、以下の素晴らしきサイトからnumpyとmatplotlibの64bit版用wheelファイルをダウンロード。\n Unofficial Windows Binaries for Python Extension Packages  そして、以下のコマンドでインストール。 \u0026lt;numpy.whlの部分はダウンロードしてきたファイルをパスで指定する。\n$ pip install \u0026lt;numpy.whl\u0026gt; matplotlibの描画エラー 以下のようなスクリプトを実行しようとしたら、エラーが発生し描画できなかった。\nimport numpy as np import matplotlib.pyplot as plt x = np.arange(-3, 3, 0.1) y = np.sin(x) plt.plot(x, y) plt.show() 原因は、フォルダ内のパスが適切に探索できなかったよう。 本来は、設定ファイルとかに記載するんだろうけど、書き方が不明だったので、シンボリックリンクで対応。\n$ mklink /D c:/tools/hoge/lib/tcl8.6 c:/tools/python3/tcl/tcl8.6 $ mklink /D c:/tools/hoge/lib/tk8.6 c:/tools/python3/tcl/tk8.6 1行目がtclの時で、2行目がtkの時に発生していたエラーは以下の通り。\nCan't find a usable init.tcl in the following directories: Can't find a usable tk.tcl in the following directories: 上記設定で無事に表示されることを確認。 今後もエラーが発生したらとりあえずpython3フォルダ内を探索して適当にパスを通せばOK?\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/python/pythonwindows/","tags":["python"],"title":"virtualenvを利用したpython環境の構築(Windows編)"},{"categories":null,"contents":"Homebrewでパッケージをインストールしたが、途中でNot writableと言われたので解消方法。\n結論 以下のコマンドを実行する。 今回は/usr/local/binに書き込み権限がなかったので、書き込み権限を付加。\n$ sudo chown -R `whoami`:admin /usr/local/bin ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/homebrewpermission/","tags":["software"],"title":"Homebrewでnot writableがでた時の対処方法"},{"categories":null,"contents":"Mac(Yosemite)のvirtualenv環境でmatplotlibを導入したら、導入できたのに表示できなかったので対処法メモ。\n結論 描画対象が適切に設定されていないので、描画する対象を設定する。 設定ファイルは、matplotlibrcというファイルで、以下の項目を書き換える。\n- backend : macosx + backend : tkAgg ファイルの場所は、pythonを起動して以下のコマンドを実行することで表示できる。\nimport matplotlib matplotlib.matplotlib_fname() ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/python/matplotlib/","tags":["python","matplotlib"],"title":"python3.4でmatplotlibを導入したらグラフ表示できない問題の対処法"},{"categories":null,"contents":"Windowsのパッケージ管理にchocolateyを利用することにしてみたので、導入メモ。\n導入方法 コマンドプロンプトを管理者権限で起動し、以下のコマンドを実行する。\n$ @powershell -NoProfile -ExecutionPolicy unrestricted -Command \u0026quot;iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))\u0026quot; \u0026amp;\u0026amp; SET PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin 実行してインストールできたけど、エラーが出ていた。 Windowsの再起動後に確認したら、インストールパスがC:/ProgramData/Chocolateyになっていたので、 環境変数に無効なディレクトリを追加しようとしたことが原因っぽい。 まあ、きちんと環境変数も記載されていたので気にしないことにする。\nGUIの導入 Windowsの場合、コマンドが貧弱で使いにくいので、なるべくGUIにしたい。 そこで、ChocolateyのGUIも導入する。 GUIは、Chocolateyからインストールできて、以下のコマンドを実行する。\n$ cinst chocolateygui Powershellの4.0とかインストールするか聞かれるけど、とりあえず全部YesにしとけばOK。\nパッケージをdotfileで管理する homebrew見たいにパッケージ管理用のファイルは自動で出力できないみたいだけど、 chocolateyGUIのエクスポートはできるようなので、たまにやっておくといいかも。 configファイルはXML形式で以下のような感じ。 実際のconfigファイルは、ここ。\n﻿\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;packages\u0026gt; \u0026lt;package id=\u0026#34;chocolatey\u0026#34; version=\u0026#34;0.9.9.9\u0026#34; /\u0026gt; \u0026lt;package id=\u0026#34;ChocolateyGUI\u0026#34; version=\u0026#34;0.13.1\u0026#34; /\u0026gt; \u0026lt;package id=\u0026#34;PowerShell\u0026#34; version=\u0026#34;4.0.20141001\u0026#34; /\u0026gt; \u0026lt;/packages\u0026gt; 何かあって一括でインストールが必要な時は、以下のコマンドを実行する。\n$ cinst packages.config ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/chocolatey/","tags":["chocolatey"],"title":"Windowsのパッケージ管理にchocolateyを導入したときのメモ"},{"categories":null,"contents":"Atomの設定をvimの.vimrcとかbundlesとかのように共有する方法を調べた時のメモ。\n概要 Atomを新しく使い始めたので、vimとかと同じように設定を共有化したい。 色々方法があるみたいだけど、今回はGitHubを利用して自分で対象ファイルを管理し、シンボリックリンクで行う方法を利用する。\nWindowsの共有 今回はすでにWindowsのほうが設定されていたので、 まずはWindowsの設定をGitHubにアップロードするところから開始した。 まずは、GitHubに適当なリポジトリを用意する。 私の場合は、vimrcなどの設定ファイルを保存するdotfilesというリポジトリがすでにあるので、 その中にatomフォルダを作成した。\nその後、Atomの設定ファイルを全てリポジトリのatomフォルダにコピーする。 (移動でもいいけど、何かあった時の保険として成功するまで、もとのデータは残しておく。) Windowsの場合、C:\\Users\\hogeに.atomフォルダがあり、その中に設定データがある。 .atomフォルダには、.gitignoreファイルがデフォルトであることから、 このフォルダをGitHubで共有することを想定している気がする。\nただし、デフォルトの.gitignoreでは、 packageフォルダなどを共有してしまうので、 いくつかの項目を追加する。 今回追加した設定は以下の通り。 全設定は、こっち。\npackages .apm GitHubのリポジトリをそのまま、C:\\Users\\hogeの下に.atomフォルダという名称でcloneしてもいいし、 Windowsでシンボリックリンクを作成してもいい。 シンボリックリンクは、コマンドラインのみから作成できる。\n$ cd C:/Users/hoge $ mklink /D .atom \u0026lt;GitHubのatomフォルダ\u0026gt; 後は、GitHubにpushすればよい。 この方法だと、パッケージやテーマが共有されないので、その方法は別途設定する。\nMacの共有 Windowsで共有した設定ファイルをMacでも利用するために、以下のように設定する。 ここでは、MacのAtomは初期状態を想定しているので、Macの設定ファイルは全て削除している。\n$ cd $ rm -rf .atom $ ln -s \u0026lt;GitHubのatomフォルダへのパス\u0026gt; .atom パッケージリストを作成してパッケージの管理 Atom.ioのStarで管理する方法もあるようだが、 複数個所に設定を分散すると、後で何がどこにあったかわからなくなるので、 今回は一括でGitHubで管理する。 パッケージ情報の出力は、コマンドラインから行う。 Atomがインストールされた時点で、Atomのbinフォルダにパスが通っているはずなので、 以下のコマンドが実行できるはず。\n$ atom -v [10016:1002/203548:INFO:CONSOLE(0)] 1.0.19 $ apm -v apm 1.0.5 npm 2.13.3 node 0.10.40 python 2.7.9 git 1.9.4.msysgit.2 visual studio 2013 これができれば、以下のコマンドでパッケージとテーマのリストを作成する。 cmd.exeの代わりにpowershellを利用しているので、cmd.exeの場合はコマンドが違うかもしれない。\n$ apm list --installed --bare | Set-Content \u0026lt;GitHubのatomフォルダへのパス\u0026gt;/packages.txt あとは、パッケージをインストールしたいマシンで、以下のコマンドを実行する。 これで自動でインストールされる。\n$ apm install --packages-file \u0026lt;GitHubのatomフォルダへのパス\u0026gt;/packages.txt 注意点として、パッケージのインストール、アンインストール時に自動で更新されたり、 他のPCで自動実行もされないので、全て手動でやる必要がある。\n参考情報  Mae's Blog: Atomの便利なパッケージ管理方法 – GitHubやスターを利用して他の開発環境でも使えるようにしておく ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/shareatomsettings/","tags":["software"],"title":"Atomの設定をGitHubを利用して共有する方法"},{"categories":null,"contents":"homebrewでインストールしたら自動でbrewfileを更新してほしいので、どうすればできるか調べた時のメモ。\n結論 インストールコマンドを利用する時に以下のように行う。\n$ brew file brew install \u0026lt;package\u0026gt; もし、brew-caskを利用するならば以下のようにする。\nbrew file brew cask install \u0026lt;package\u0026gt; ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/homebrew_update_brewfile/","tags":["software"],"title":"homebrewでインストールした時に自動でbrewfileを更新する方法"},{"categories":null,"contents":"Windows環境ではVimが思ったよりも使いにくいので変更しようと思ってAtomを試験的に導入したのでその時のメモ\n所感 元々vimをエディタとして使っていたのだけど、 macを購入したらwindowsのvimがmacのterminalで実行するvimに比べてあまりにも使いにくい。 windowsはwindowsの環境を構築するべきだと思ったので、 windowsに合わせたeditor含めた環境の再構築を目指して進める第１弾。\n今までvimでプログラム(言語としては、c/c++/java/javascript/python/rubyなど)は全て書いていた。 その他markdownを利用したメモ(これもそう)を取っているのでそれもできることが基準となる。\n atomの使い方としては、フォルダごと登録して使うのがいいのかな。 基本ファイル検索が使いやすいから、ctrl + tでファイル検索するのが、ファイルを開くときの基本動作になりそう。  導入したプラグイン エディタなので当然だが、利用しながら必要なプラグインは追加していく予定なので暫定設定。\n vim-mode: normal modeとinsert modeを使えるようにする(これがないと始まらない) ex-mode: ex mode使えるようにする。(ただし、:ではなくshift + :) file-icons: ファイルのアイコンをいい感じにしてくれる japanese-wrap: 日本語を利用するなら入れたほうがいいらしい。(折り返しなどが日本語に対して適用される)  設定の変更  Settings -\u0026gt; Settings -\u0026gt; Soft WrapをON Settings -\u0026gt; Settings -\u0026gt; Soft Wrap At Preferred Line LengthをON Settings -\u0026gt; Settings -\u0026gt; Preferred Line Lengthを120にする  備考  Markdown Previewをするためには、ctrl + Mでプレビューが開く  できてほしいこと  vim-modeのinsert modeでctrl + jで改行とか、ctrl + hでバックスペースとかできてほしい。  ctrl + hはキーバインドにctrl-hを定義することでbackspaceの操作ができた。 ctrl + jでの改行のみデフォルトのキーバインドとかぶって対処方法がわからない。   vim-modeでwでの移動時に日本語だけだと文末まで飛ぶのを、せめて漢字と平仮名とかの変更点で止めてほしい ex-modeのshift + :は使いにくいから、:だけでできないかなぁ  Macだと:のみでex-modeが起動する。Windowsも設定でできるのかな?   設定ファイルを保存しておいて、他の環境と共有できる方法がほしい。vimの.vimrcみたいな感じ。  若干手動が入るが、できる方法があった。設定の共有方法   スニペットの設定とオートコンプリート機能 言語ごとの設定 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/atomeditor/","tags":["software"],"title":"Windows環境のエディタをAtomに乗り換えようかと思ったのでメモ"},{"categories":null,"contents":"久しぶりにminecraftにmodを導入しようと思ったので、メモ。 (IDが衝突しているみたいで適切な動作になっていないので注意。)\n概要 とりあえず大量にmodを入れて、どのコンテンツを楽しむかは後から決めるスタイルで行きたい。 なので、modを導入して起動すればOKとする。\n豆腐modで豆腐世界に行ったときにemptyの敵が現れて倒せなくなっていたので、どこかでIDが衝突している?\n導入mod 導入したmod群。上から順に導入した。 基本的にForge以外は、jarファイルをmodフォルダに追加する。 zipファイルは解凍して、中のjarファイルのみmodフォルダに追加。\n Forge: 前提mod インストーラ版から導入 Optifile: 軽量化mod(jar版) Shaders mod (updated by karyonix): 影modの本体 Slider's shaders: 影modのshader  バニラの雲はOFF バニラの雲の影をOFF: Options -\u0026gt; shaders -\u0026gt; CloudShadow   MineAll, CutAll, DigAll: 一括破壊系 竹mod もみじmod Code Chicken Core: Not enough itemsの前提mod  Not enough items: アイテムレシピの確認 WAIIA: ブロック名の表示 ChickenChunks: チャンクローダー   MO\u0026rsquo; BENDS: アニメーションの追加 Dynamic Lights: 光源を持った状態やドロップした状態でも光源とする。 SpawnChecker: スポーン場所を示す Armor Status HUD: 武器、防具の耐久値を表示 Status Effect HUD: ステータス変化を表示する Rei's minimap: ミニマップ Player API: Smart movingに必要  Smart moving: 上り下りなどの動作を追加する   Infernal mod: 強化されたユニークmobの追加 Zombie Awareness: mobに聴覚、嗅覚の概念を与える Tofu Craft: 豆腐mod Apple \u0026amp; Milk \u0026amp; Tea! ver 2: りんごを使ったレシピなどの追加。 Sonic the Hedgehog Mod: ゲーム「ソニック・ザ・ヘッジホッグ」に登場したブロック、アイテム、mobを追加 Gilded Games Util: Aether IIの前提  Aethre II: 天界mod(Dimensionの追加)   Caveworld: 地下世界の追加(Dimensionの追加) Galacticraft3: 月や枷を始めとする太陽系のブロック、アイテム、モブの追加(Dimensionの追加) Frozen land: 雪と氷の極寒世界の追加(Dimensionの追加) The Twilight Forest: 黄昏世界の追加(Dimensionの追加) Tropicraft: 南国のアイテムなど追加(Dimensionの追加) 抜刀剣mod: 多くの刀剣が追加 MoreInventoryMod: アイテム管理に便利なブロック、アイテムの追加  一度クリエイティブモードにしたらコンテナの挙動がおかしくなりアイテムが取り出せなくなった。 直し方がわからない。   MOre Furnaces: かまどの追加 Garden staff: 花壇やフェンスなどの装飾用インテリアアイテムの追加 Millenaire: 村追加mod Mo\u0026rsquo; Creatures: Mob追加 Hostile Mobs and Girls: mob追加 Better dungeons: ダンジョンの追加 Dungeon Pack: ダンジョンの追加 C-TETRA: 16x16のリソースパック Inventory Tweaks: アイテム整理  見送ったmod  ThebombzenAPI: AutoSwitchの前提  Auto Switch: 自動で採掘、mob攻撃で手持ちの最適ツールに変更する 動作しなかった。   AoA(Divine RPG): mob、アイテム、ブロックの追加(Dimensionの追加)  何かと競合した。   Glacia: 雪原世界の追加(Dimensionの追加)  おそらく何か他のDimension追加系のmodと競合している   Eternal Frost: 極寒世界の追加(Dimensionの追加)  おそらく何か他のDimension追加系のmodと競合している   Little Blocks Mod: 一辺の長さが1/8のリトルブロックを作成可能になる。  ダウンロードできなかった。   Ore Spawn: mob追加  競合した。   LotsOMobs: mobの追加  起動したけど、twilight forestと競合した。   Battle Towers: バトルタワーの生成  ワールド生成ができなくなった。   Slime Dungeons: ダンジョンの追加  ワールド生成ができなくなった。   Sphax PureBDcraft: 64x64タイプ。リソースパック  気分じゃなかったので変更   Zelads word skills: ゼルダの動作やmod、ダンジョンの追加  進めないと壊せないブロックが結構追加されて建築の邪魔なので、これだけやるのでなければ入れないほうがやりやすい。   Spuer Mario Mod: スーパーマリオのブロック、アイテム、mobを追加  ジュゲムがでてきて湧き潰しが利かないので建築に邪魔。   More mobs mod: mobの追加  重くなりすぎたので削除    その他の設定 modを大量に入れたからか、かなり重くなったので、javaのメモリ割当を適当に多くする。 EditProfileからJVM Argumentsで以下のパラメータを変更\n- -Xmx1G + -Xmx4G ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/minecraft/minecraftmods/","tags":["minecraft"],"title":"Minecracft 1.7.10にmodを導入"},{"categories":null,"contents":"ふと近未来動画を集めた時のメモ書き。\n概要 近未来動画って非常に面白いと思う。 コンセプトだし、そうなるわけじゃないかもしれないけど色々興味が湧く、 こうなったらいいなが入っていてワクワクするのがいい。\nたまに、おいおいって言いたくなるのもなんか笑って許せるところが、またコンセプト動画の良さでもあると思う。\n近未来動画 公開年代順に並べてみる。これはこれで、少しずつ変わっていそうで一気に流せたら時間の流れがわかりそう。 公開年代は、動画のアップロード日だったり、わかれば実際に作った年とか結構アバウトだけど。\n  Microsoft\nMicrosoftは、カード型の端末がずっとメインに続いてる。 大きさが違ったり(タブレット見たいなサイズ)、新聞のようなものも出てくるけど、 基本、みんなが持ってるのはカード型のスマホが薄くなったような端末。\n 2015/03/10 Microsoft: Productivity Feature Vision 2013/07/14 Microsoft's Concept - Future vision 2010 2011/10/24 Productivity Future Vision (2009)    NTT\n 2013/05/16 data for smart society(NTT DATA future vision) 2013/06/12 2025 the future of ICT    その他\nみんな、タブレットとスマホが大好きって感じ。 それ以外の面白デバイスは少ないなぁ。\n  2015/05/10 Top 5 future Technology inventions: 2015 - 2050\n幾つかの動画からテクノロジーを集めてきた感じかな。\n  2013/03/04 TOYOTA Introducing TOYOTA i-ROAD personal Mobility Vechicle\n  2012/02/03 Corning A day made of Glass 2: Same day. Expanded Corning vision(2012)\n  2012/??/?? Openarch / Film\nなんか最初のシーンで目覚ましが写っている横に普通のアナログ時計がかけてあって笑ってしまった。 そこは、プロジェクタで写すんじゃないのか(笑)\n  2011/06/05 仏エアバス The future by Airbus - concept plane cabin\n    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/others/futurevisionmovie/","tags":["others"],"title":"近未来動画の寄せ集め"},{"categories":null,"contents":"Macでpandocを利用してpdfに変換しようとしたら文字化けして変換できなかったので、 変換できるように設定した時のメモ。\n概要 macのutf-8が特殊みたいで、一回変換をかませてあげる必要があるみたい。 コマンドとしては、以下のようにしてあげると変換できる。 長いので.bashrcとかにaliasか関数定義する方が早いかもしれない。\n$ iconv -c -f UTF-8-MAC -t UTF-8 hoge.md | pandoc -o hoge.pdf -f markdown -V documentclass=ltjarticle --latex-engine=lualatex 必要パッケージの導入 homebrewを利用して以下のパッケージを導入する。\n pandoc  今回の変換のためには、pandocが必要なので導入する。 pandoc自体は結構いろんな形式に変換できる。   mactex  pandocでpdfに変換するためには、 一旦texに変換して、それをpdfに変換する必要がある。    コマンドとしては以下でインストールされるはず。\n$ brew install pandoc $ brew cask install mactex pdf変換コマンドの説明 文字エンコードの変更(UTF-8-MAC to UTF-8) texへ変換する前に、macのutf-8を普通のutf-8に変換する。 ただし、以下のコマンドを実行するだけでは、単にコマンドラインにutf-8の文字列が出力されるだけ。 長い文章のファイルに対して行うと結構ずらっとでるので注意。\nたまに変換エラーがでるので、変換できなくても無視して続けるようにするために、-cオプションを追加しておく。\n$ iconv -c -f UTF-8-MAC -t UTF-8 hoge.md texからpdfへ ファイル形式がmarkdownのファイルを、texを利用してpdfに変換する。\n$ pandoc -o hoge.pdf -f markdown, -V documentclass=ltjarticle --latex-engine=lualatex  -f markdown  マークダウンファイルを変換   -V documentclass=ltjarticle --latex-engine=lualatex  lualatexを利用して変換する    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/macpandocpdf/","tags":["pandoc"],"title":"macでpandocを利用してpdfに変換しようとした時のトラブルメモ"},{"categories":null,"contents":"macにjava環境を構築した時のメモ。 まだ成功していない。\n概要 MacにJAVA環境を構築した時に行った作業一覧。 Eclipseを利用すれば早いし、環境としても良いのはしっているが、 Eclipseは重いという問題があるので、基本vimだけで動くことを目標として環境構築。\nインストールパッケージ   java\n$ brew cask install java   eclipse\n$ brew cask install eclipse-java インストールしたらとりあえず、一回は起動しておく。\n  ant\nこの後のNeoBundleでEclimをビルドするのに必要なので導入。 javaを利用したビルドツール(要はmakeツール)\n$ brew cask intall ant   vimパッケージ NeoBundle .vimrcに記述してNeoBundleで管理するパッケージ。\n ervandew/eclim   以下のコマンドを.vimrcに記載する。\nNeoBundleLazy 'ervandew/eclim', { \\ 'build': \\ {'mac': 'ant -Declipse.home=/opt/homebrew-cask/Caskroom/eclipse-java/4.5/Eclipse.app/Contents/Eclipse -Dvim.files='.escape(expand('~/.vim/bundle/eclim'), '')}, \\ } Declipse.home=の指す先は、brew cask install eclipseでインストールされたEclipseの場所。 -Dvim.files=の指す先は、vimのbundleを管理しているフォルダ。\n結局よくわからないので、自分でビルドしに行った。\n$ ant -Delipse.home=/opt/homebrew-cask/Caskroom/eclipse-java/4.5/Eclipse.app/Contents/Eclipse -Dvim.files=~/.vim/bundle/eclim 上記がエラーの原因だった。 ビルド時の出力みたらeclimフォルダの中にDvim.filesのパスが作成されていた。 この辺の挙動が不明で適当に書き換えているからエラーする。 とりあえず以下のように強引にeclimフォルダに出力されるようにビルドした。\n$ ant -Delipse.home=/opt/homebrew-cask/Caskroom/eclipse-java/4.5/Eclipse.app/Contents/Eclipse -Dvim.files=./   Eclimdの起動。\n$ /opt/homebrew-cask/Caskroom/eclipse-java/4.5/Eclipse.app/Contents/Eclipse/eclimd 以下のようにEclipse上でも起動できる。 Window -\u0026gt; Show View -\u0026gt; Ohter -\u0026gt; Eclim -\u0026gt; eclimd\n  vim上で以下のコマンドを利用して動作確認。(これが動作しない)\n:PingEclim エラーは以下の文。\nE492: Not an Editor Command: PingEclim vimのパスが通っているところにビルドしたらきちんとコマンドが存在した。\n    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/java/javaenvironment/","tags":["java","vim"],"title":"macにjava環境を構築した時のメモ"},{"categories":null,"contents":"何をするのに一般的に利用されているか、まとめてみる。\n概要 用途によって利用する言語は変えれば良いと思うが、 いくつか比較してみると、とりあえず使えるようになっておけば良い言語は以下の感じかな。\n C / C++: 現時点で一番利用しているから放置 Java: Androidアプリ開発で利用する Objective-C (Swift): iPhone/macアプリ開発で利用する Python: 学術系では強い Ruby: ???  比較対象言語  julia go lang javascript java python c++ swift ruby or ruby on rails haskel c#  TOIBE TOIBEは以下のような感じ。 そこから主観的に抜き出しておく。\n C / C++ Java Objective-C C# Python Javascript Ruby  TOIBEランキング  C Java Objective-C C++ C# Basic PHP Python Perl Transact-SQL Delphi/Object Pascal Javascript VB .NET Visual Basic R Ruby Dart F# Swift Pacal  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/progrmlanguage/","tags":["software"],"title":"今後学ぼうと考えているプログラム言語をまとめてみる"},{"categories":null,"contents":"MacでPython環境を構築した時のメモ。\n概要 MacでPython環境を構築した時のメモ。\npyenv-virtualenvの導入 homebrew導入済みと仮定して、以下のコマンドでpyenv-virtualenvを導入する。\n$ homebrew update $ homebrew install pyenv-virtualenv ついでに、.bash_profileに以下を記述して、パスを通す。\nexport PYENV_ROOT=\u0026quot;${HOME}/.pyenv\u0026quot; if [ -d \u0026quot;${PYENV_ROOT}\u0026quot; ]; then export PATH=${PYENV_ROOT}/bin:$PATH eval \u0026quot;$(pyenv init -)\u0026quot; fi pythonのインストールは、バージョン確認して好きなのを選択すれば良い。\n$ pyenv install 3.4.3 以下のエラーがでた時はXCodeを導入すれば良いので、追加でXCodeのインストールコマンドも行う。\n ERROR: The Python ssl extension was not compiled. Missing the OpenSSL lib?\n $ xcode-select --install 利用するバージョンを変更するために以下のコマンドを実行する。\n$ pyenv global 3.4.3 $ pyenv rehash virtualenvの利用方法 virutalenvは、pythonの環境を構築できる。 pyenvがバージョンの管理とすると、virtualenvはライブラリなどの環境管理が可能。 pyenvの3.4.3に対して、インストールするライブラリを変更して用意することができる。\n環境を新しく作る方法は、以下のコマンドを利用する。\n$ pyenv virtualenv 3.4.3 3.4.3-develop 環境の切り替えは、pyenvでそのままできる。\npyenv-virtualenvの確認用コマンドメモ   python\n バージョン確認(大文字のVでないとダメみたい)  $ python -V   pyenv\n インストール可能なバージョン確認  $ pyenv install -l  今インストールしているバージョンの確認  $ pyenv versions  今選択しているバージョンの確認  $ pyenv version  利用するバージョンを変更する  $ pyenv global 3.4.3  環境の削除  $pyenv uninstall 3.4.3-develop   virtualenv\n 新規環境の作成  $ pyenv virtualenv 3.4.3 3.4.3-develop   pip\n パッケージをインストールする  $ pyenv exec pip install hoge   パッケージ状態を保存して、別の環境で一括追加 \u0008* 環境の保存\n$ pyenv exec pip freeze \u0026gt; requirements.txt  環境の一括構築  $ pyenv exec pip install -r requirements.txt --use-wheel   vim + python用プラグイン NeoBundleでインストールしているプラグイン  kana/vim-smartinput: 対応カッコの自動挿入 scrooloose/syntastic: 構文チェック スニペット  Shougo/neocomplcache Shougo/neosnippet Shougo/neosnippet-snippets   davidhalter/jedi-vim: オムニ補完  jedi-vimをNeoBundleで導入した後、 jedi-vimのフォルダ内でgit submodule update --initでサブモジュールを取得する必要がある。   andviro/flake8-vim: スタイルチェック  jedi-vimと同様にサブモジュールのアップデートが必要。   hynek/vim-python-pep8-indent: インデントを適切に導入する  ftpluginの設定  以下のファイルをvimruntimepathのパスが通っているところのafter/ftpluginに置く。  python.vim    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/python/pythonenvironment/","tags":["python"],"title":"Macでpython環境の構築"},{"categories":null,"contents":"jekyllがMac環境でうまく動作しなくなったので、そのときに見直したRuby環境のメモ。\n概要 結論は、ここに乗ってたけど、以下は関係なくて、 _config.ymlにrougeを記載してgemパッケージでrougeを入れれば動く。\n$ rbenv exec gem install rouge _config.ymlに以下の記述を追加。\nhighlighter: rouge rbenv 基本的にrubyの複数バージョン管理を行うためのパッケージ。 pythonのpyenvと同じ感じ。\n以下のコマンドで、全体の環境を変更できる。\n$ rbenv global 2.2.3 個別に環境を変更するときは、以下のコマンド。\n$ rbenv local 2.2.3 bundler gemパッケージのバージョン管理。 pythonのvirtualenvと違って、環境ごと管理できるわけではない? 使い方がよくわからなかったので、結局gemで直jekyllをインストールした。\nrbenv exec gem install jekyll bundler自体は、インストールするためには以下のコマンドを実行すると、 すべてのbundlerがインストールされる。\nrbenv exec gem install bundler 参考文献 Liquid Exception: No header received back - Mac OS X #2604\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/ruby/rubyenvironment/","tags":["ruby"],"title":"ruby環境"},{"categories":null,"contents":"macbookの設定をメモ。 初のmacbookなので設定がおかしいかもしれないが、おかしいのに気付いた時に直す。\n概要 macbookの設定で行ったことのまとめ。 ソフトウェアとか、設定の変更とか。\nソフトウェア とりあえずApple Storeでインストールできるソフトは、AppStoreでインストールするが、 それ以外のソフトはHomebrewで管理することにした。\nデフォルト 初期から入っていたソフト\n Safari メール カレンダー 連絡先 リマインダー メモ マップ メッセージ FaceTime Photo Boose iMovie 写真 Game Center iTunes iBooks App Store Pages Numbers KeyNote プレビュー  App Storeでインストールしたソフト  XCode  Homebrewでインストールしたソフト Brewfileで管理しているので、Brewfileが最新版になっているはず。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/macsettings/","tags":["mac"],"title":"Macbook 12インチ(1.1GHz)の設定"},{"categories":null,"contents":"クロスプラットフォームでメモ環境を構築しようとした時のメモ書き。\n概要 論文とかもmarkdown記法でテキストで書いてしまえる気がする。 長文も短文も全て書きだしをスムーズにしたいから、メモして行く方法を確立できないだろうか。\nメモ とりあえず、書き始めを基本はgoogle keepにする。 そして、そこから長くなってきたら後悔しても問題ない範囲ならgithubにしてしまえばどこからでも確認できる。 後悔したくないデータは、Dropboxに入れる。\n 書き始め: google keep ⇒ markdown記法 公開可能: github ⇒ markdown記法(テキストファイル) ⇒ html 非公開: Dropbox ⇒ markdown記法(テキストファイル) ⇒ PDF  Google keep Windows、Android、Mac(おそらくiOsも)で使えるクロスプラットフォームなメモ。 簡易メモとして非常に軽量で起動とメモの開始までが早いという特徴がある。\nただし、macでsafariを使った時は、文字入力がかなり遅れるという問題があった。 chromeをインストールして、keepを利用したら速度が上がった。 基本は純正ソフトから使えということか?\n現在のところmarkdownで書いておけば、この後はコピペで適切な形式に変換できる。\nGitHub markdown記法で書いてjekyllでhtmlに変換しておけば、 どこからでもアクセスできる個人データベースの完成。 自分のページにgoogleの検索窓さえつけとけばgoogleの優秀な検索機能が利用できるので、非常に楽に検索機能が利用できる。\nDropbox 一応プライベートな(ネットに繋がっている時点でプライベートか疑問だが)ファイルを保存できるので、 公開したくないメモはこちらに書いて、保存しておく。 ここもmarkdownで書いておけば、もし公開しても良い気がしたらGitHubに移動すればいいし、 最後までダメならそのまま置いておけばいい。\nただ、書き終わったらテキストファイルも残しておくがPDFにしてしまえば見やすくなる。 PDFへの変換は、pandocを利用してしまえば、一発で変換される。\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/memoenvironment/","tags":null,"title":"メモ環境"},{"categories":null,"contents":"外部バックアップをするのにHDDを内臓HDD+スタンド or 外付けHDDのどちらが良いか調べたの時のメモ。\n概要 バックアップを行うのに数TB程度のバックアップ環境を構築したくなったので、どうするか検討した。\n結論としては外付けHDDを購入したほうが安いということが分かった。 内臓HDDのみなら若干安いのだが、スタンドの費用がかさみ単価は外付けHDDのほうが安くなった。\n外付けHDD BUFFALO USB3.0 外付けハードディスク PC/家電対応 3TB HD-LC3.0U3/N [フラストレーションフリーパッケージ(FFP)] 2TB: \\8,890-(\\4,445-/1TB) 3TB: \\10,880-(\\3,627-/1TB) 4TB: \\15,980-(\\3,995-/1TB)\n6TB(2個): \\21,760-(\\3,627-/1TB)\namazon\n内臓HDD利用 1TB: \\11,292- 2TB: \\12,768-(\\6,384-/1TB) 3TB: \\15,102-(\\5,034-/1TB)\n6TB(3TB x 2枚): \\26,244-(\\4,374-/1TB)\n玄人志向 HDDスタンド USB3.0接続 KURO-DACHI/CLONE/U3 パソコンなしでHDDのまるごとコピー機能付き \\3,960-\namazon\nWD 内蔵HDD Green 3TB 3.5inch SATA3.0（SATA 6 Gb/s） 64MB Inteilipower 2年保証 1TB: \\7,332- 2TB: \\8,808-(\\4,404-/1TB) 3TB: \\11,142-(\\3,714-/1TB)\namazon\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/hddbackup/","tags":["hardware"],"title":"外部バックアップ用HDDの比較"},{"categories":null,"contents":"母艦となるWindowsマシン以外にも移動用PCがほしくなったのでその時のメモ。\n概要 メインとなるWindowsデスクトップPCを持っているが、 移動したときや自宅以外で作業することが可能なPCがなく不便な時があるので持ち運び用のPCがほしくなった。\n Windows PCのスペック  CPU: Intel Core i7-4770 3.40GHz(8 CPUs), 3.4GHz メモリ: 16GB GPU: NVIDIA GeForce GTX 770    選択基準としては、以下に示すようなこと。\n メインはWindowsPCであり、あくまでもサブ機。 持ち運びに便利である。(既にあるA4サイズまでしか入らないバッグに入ること) プログラミング(3D関連の重い作業はメインで行うのでそれ以外)、動画鑑賞ができること。 サブ機なので、比較的安価であること。  これらを踏まえて、いくつかのPCを比較した結論は、 買うならMacBook Air 11インチ(early 2015)になると思う。\n⇒ 結局誘惑に勝てなかったので、macbook 12インチ(1.1GHz)を購入した。\n候補  New MacBook  用途としては十分性能が満たしていると思うが、さすがに1.1GHzはないので、1.3GHzのほうにしたい。 1.3GHzの場合は、\\178,800-となり高すぎる。\n⇒ と思ったが、用途的に1.1GHzでも十分かもしれない。 たぶん利用する目的の一番重い処理が、動画閲覧になると思うから。 それなら、1.1GHzで\\148,800-で差額が1万円なら許容範囲か? Retinaディスプレイは良い。 サイズは一番小さい。 最も軽い(920g)。 プログラミングは、動かさなければ一通りできる気がする。コンパイルが少し遅いか? スペック1  CPU: 1.3GHzデュアルコアIntel Core M メモリ: 8GB GPU: Intel HD Graphics 5300 解像度: 2304x1440 pix(16:10)   スペック2  CPU: 1.1GHzデュアルコアIntel Core M メモリ: 8GB GPU: Intel HD Graphics 5300 解像度: 2304x1440 pix(16:10)     MacBook 11インチ  メモリ4GBでは心もとないので、8GBにアップグレードすると\\138,800-で、まだ安いかな。 サイズは、MacBookよりちょっと大きいかなぐらい。 まだ軽いと思う(1080g)。 一通りの作業はできると思う。3D関連はさすがに無理だと思うけど。 スペック  CPU: 1.6GHzデュアルコアIntel Core i5 メモリ: 8GB GPU: Intel HD Graphics 6000 解像度: 1366x768 pix(16:9)     MacBook 13インチ  大きすぎるので選択対象外。   Windowsラップトップ  いまだに1台もMacがないのであってもいいかなと思うので、今回は対象外。   タブレットPC  surfaceとか店頭で触ってきたが、 重いし、最後はキーボードつけっぱになってただのラップトップになりそうなので却下。    ラップトップとメインの使い分けは? 何をラップトップで行って、何をメインのPCで行うかを考えてスペックとか決まると思うので、 以下に列挙して、想定しているPC毎に分ける。 ラップトップにあるものは、今はメインPCでやっていたり、やってみたいことだったりいろいろ。 もちろん重複もあって、その時の気分とかでも変わっていくと思う。 あと、紙のノートも好きだし、頭の中の整理には使いやすいと思っているので、ついでにあげておく。 ついでにスマホも書いておく、移動用としては常に携帯しているし。\n メイン  PCゲーム(SkyrimとかMinecraftとか) 動画鑑賞 Webサーフィン プログラミング 画像処理とか機械学習とか UnityとかBlenderとか 写真管理 メモの整理(evernote, google keep, github) メール(google inbox)   ラップトップ  動画鑑賞 漫画鑑賞 Webサーフィン プログラミング メモをとることと整理すること(evernote, google keep, github) メール(google inbox)   スマホ  メール(google inbox, キャリアメール) feedly メモ(google keep) 地図、乗り換え 電子マネー   紙のノート  マインドマップ 紙ベースの旅行で手に入れたものを張り付ける 旅行でのスタンプを押す 文章以外のものを書くとき。(たとえば、数式とか図とか絵とか。) メモをとる\n⇒ 文章ならPCでとる。 どうしても、図とか数式とかが入ると思考よりも遅くなって、思いついたことが書ききれないので、 用途によっては紙のノートになる。    性能 性能面の話は何を比較するとか色々あるけど、わかりやすくCPUで比較する。 たぶん、今回の性能だけを見るとどれでも使用に耐えられると思う。 なんせ昔使っていたPCから見れば非常に性能が良い。 そして、無茶なことはしないのでサブ機だしね。\n MacBook (Intel Core M-5Y31 @0.9GHz): マルチ 2484 シングル 1145 MacBook (Intel Core M-5Y71 @1.2GHz): マルチ 3049 シングル 1301 MacBook Air (Intel Core i5-5250U @1.6GHz): マルチ 3703 シングル 1507 MacBook Air (2011) (Intel Core i5-2467M @1.6GHz): マルチ 2332 シングル 953 Sony VPCX13AKJ(Intel Atom Z550 @2.00GHz): マルチ 381 シングル 0  2010年ころに購入したラップトップ。使い心地がわかっていて比較になるので。    数値の参照元\nその他  メインとのデータ共有方法  外付けHDD(exFAT)にしておけばmacとwindowsで同じHDDを利用できる。    ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/comparison-macbook/","tags":["mac"],"title":"MacBookとMacBook Airの比較"},{"categories":null,"contents":"何かしていて気になった言葉。\n今日は死ぬのにもってこいの日だ 師の跡を求めず、師の求めたるところを求めよ Yahoo! 知恵袋: 師の跡を求めず、師の求めたるところを求めよ\nサヨナラだけが人生だ だいせんじがけだらなよさ 立ち上がってたたみなさい、君の悲嘆の地図を 参考資料  Yahoo! 知恵袋: 師の跡を求めず、師の求めたるところを求めよ  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/others/wiseremarks/","tags":["others"],"title":"気になった言葉"},{"categories":null,"contents":"Occulus Riftの入力デバイスを調べた時のメモ。 ただし、Occulus RiftというよりVRとかARとかまで派生して、面白入力デバイスという感じ。\n体の一部型 Myo 腕につけて、指の動作を取得するらしい。既にAmazon.comでは販売してるっぽい。 目的はジェスチャコントロール。\n関連記事:\n Google Glass info: 驚異の筋電位コントローラー「MYO」がグーグルグラスに対応　Glass at Work参加企業との提携を発表 ギャップロ: 番外編・ Myoを使ってユニティちゃんを撫でてみる！ あの技術の名前を僕たちはまだ知らない: MyoをハックしてAndroidで筋電位データを取得し、ポーズ検出できるようにしてみた。  Wired: This Adorable Thumbnail Trackpad Could Actually Be Useful 爪の先でトラックパッド。\nRing by LogbarRing by Logbar 指輪型のデバイス。\n全身型 Vritual Omni 腰のあたりを固定して、FPSとかの動きをそのまま全身でやって、それが反映されるようにするらしい。\nSTEM System Wiiのリモコンを両手足につけて頭にVRつけるような感じみたい。\nその他 人型入力デバイス『QUMARION』 公式サイト 人型の入力デバイスで、フィギュアみたいのを動かして、それがそのまま反映されるタイプ。 コンテンツ作成の時向け。\n参考資料  Myo  Google Glass info: 驚異の筋電位コントローラー「MYO」がグーグルグラスに対応　Glass at Work参加企業との提携を発表 ギャップロ: 番外編・ Myoを使ってユニティちゃんを撫でてみる！ あの技術の名前を僕たちはまだ知らない: MyoをハックしてAndroidで筋電位データを取得し、ポーズ検出できるようにしてみた。   Wired: This Adorable Thumbnail Trackpad Could Actually Be Useful Ring by LogbarRing by Logbar Vritual Omni STEM System 人型入力デバイス『QUMARION』 公式サイト ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/vrinputdevice/","tags":["hardware"],"title":"Occulus Riftの入力デバイスを調べた時のメモ"},{"categories":null,"contents":"Oculus rift dk2を利用して試したコンテンツ。\nコンテンツ とりあえず、個人的な感想で☆5つまでで評価。\n SightLine: The Chair ☆☆☆☆☆  綺麗だし、酔いにくいから面白い。 1回目より2回目のほうが、いろいろ動かせることがわかって面白い。\n Mona Lisa Room ☆☆☆  美術館の1部屋分を再現した感じなのかな?モナリザを見に行ったことがないから、わからない。\n上を見ようとしてマウスを動かしてしまう…(笑)Occulus利用している場合は、 見上げればいいだけなんだが、慣れとは恐ろしい。\n移動するときのペースが速いので結構酔いそうになる。 自分で動かせるから止まればいいけどちょっと気になる。\nこれは、本当に高解像度で実現できるようになったら綺麗だろうと思う。\n Lollihop ☆☆☆☆  ステージクリア型(?)のアクションゲーム。 ただしゲームオーバーはないし、たぶん最後に終わりだよって書いてあるけど、 ゲームの中で終わる方法がよくわからなかった。\n今までのゲームを作るとこうなるのかってのがよくわかった。 没入感はあるし面白いと思う。けど、勝手にカメラを前後に動かされると酔う…。 ごく一部だし、すぐに抜けたから問題なかったけどね。\n Star Conflict Oculus Demo Dreadnought Battle  Oculus Modeで利用できなかった…。理由はわからない。\n Vox Machine  スムーズに動かせるロボットもの。コックピットからみるとこんな感じになるのか!!って感じで面白い。 ただ、めっちゃ酔う…。\n Virtual Desktop  参考資料  Oculus VR share SightLine: The Chair Mona Lisa Room Lollihop Star Conflict Oculus Demo Dreadnought Battle Virtual Desktop Vox Machine  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/oculusriftshare/","tags":["hardware"],"title":"Oculus Rift DK2 で試したコンテンツ"},{"categories":null,"contents":"Oculus Rift DK2のセットアップをした時の導入手順メモ。\nHeadsetの設定 説明書が入っているので、それに沿ってコネクタ類を接続する。\nPCの設定 Qiita: Oculus Rift DK2をセットアップする手順を参考に順に設定を進める。\nOculus VRでのアカウント作成 最初に公式サイトでアカウント作成を行う。\nRuntimeとSDKのダウンロードとインストール 開発なども行うことを考えてRuntimeとSDKをダウンロードする。 SDKのみでよいかと思ったらRuntimeも必要だった…。 SDKがやたら軽いと思ったらSDKのReadmeに書かれてた。\n Oculus Runtime for Windows(現時点では0.5.0.1-beta) Oculus SDK for Windows(現時点では0.5.0.1-beta)  Runtimeのインストールでは、以下2つのインストールを聞かれるが両方ともYesとした。\n Oculus VR, Incディスプレイアダプター Oculus VR  最後に再起動を聞かれるので、再起動する。\nOculusの設定 タスクバーのOculusアイコンをダブルクリックし、Oculus Configuration Utilityを起動する。\nOculus Configuration UtilityでTools -\u0026gt; Display ModeをExtend Desktop to the HMDにすると、 拡張デスクトップで画面が表示できる。\nこの時、縦横が逆になっていて表示がおかしい。 Windowsのデスクトップから解像度の設定を行いOculus Riftの画面設定で方向を正しく設定する。 また、解像度を1920x1080にする。\n動作確認 Oculus VR shareで何かをダウンロードして動作を確認する。\n動作させるまでは非常に簡単。 ただ3D酔いが結構あるなぁ。一本確認したら酔ってしまった。\n参考資料  Oculus VR Oculus VR share Qiita: Oculus Rift DK2をセットアップする手順  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/oculusriftdk2setup/","tags":["hardware"],"title":"Oculus Rift DK2のセットアップ"},{"categories":null,"contents":"Blenderで流体シミュレーションを試した時のメモ。\n概要 いろはメモ -Blender-: グラスに水を注いでみる 〈流体シミュレーション〉のページを参考に 流体シミュレーションの実験。\n泥水ぶちまけてる感じだが、きちんとマテリアルとかテクスチャとか勉強してないから。 レンダリングについては後回し。 シミュレーションできることが分かったので良い。\n\nBlender: GitHub: fluidSimulation\n流体シミュレーションの準備 とりあえず液体を注ぐものを作成する。\n法線方向を確認するためには、Edit modeでNキーで表示されるPropertiesから Mesh display -\u0026gt; Normals -\u0026gt; Display face normals as linesをONにする。\n\n流体の注ぎ口を作成 UV球を作成する。(これが水の発生源になる。) 作成したUV球に物理演算から流体を設定する。\n\n設定としては、以下の感じ。\n タイプ: 流入口 ボリュームの初期化: 両方 流入速度: 適当に注ぎたい方向へ向ける  いろはメモ -Blender-: グラスに水を注いでみる 〈流体シミュレーション〉によると、 各項目の説明は以下。\n 【流体のタイプ】 コントロール(Control) ： 流体の形状を変形させるようコントロール。 パーティクル(Particle) ： 飛沫。しずく・浮かぶ泡・トレーサー（霧みたいなもの）の3タイプがある。 流入口(Inflow) ： 液体が出てくる。給水栓。 流出口(Outflow) ： 液体が吸収されてなくなる。排水口。流入口とセットで使うとよいみたい。 障害物(Obstacle) ： 障害物。表面の滑り方（粘つき）を、滑る・滑らない・部分的に滑るの3タイプから選ぶ。 液体(Fluid) ： そこにあるだけの液体。流入口のように生成はされない。 ドメイン(Domain) ： 液体シミュレーションの領域。必ず必要。\n【ボリュームの初期化】 ボリューム：オブジェクトの内部を液体にする。閉じたメッシュのみ有効。 外殻：メッシュの表面が薄い液体。開いたメッシュでも有効。 両方：オブジェクト＋外殻。よくわからないときは、とりあえずこれで。\n【流入速度】 水が発生する方向と速度。単位はメートル/秒。 数値が高いほど勢いよく放水される。 Z方向を＋の数値にすると上空に噴射する。下に落としたいときは－で。\n グラスの設定 グラスを障害物に設定することで、水がそこにとどまるようになる。 注ぎ口と同様にグラスに流体を設定し、タイプは障害物とする。\nドメインの指定 流体シミュレーションが行われる範囲を指定する。 ドメインは常に立方体で扱われるため、作成には\u0026quot;立方体\u0026quot;を使えばよい。 今回は、流入口とグラスの両方が含まれる範囲を指定する。\n作成した立方体に対して、流体を設定し、タイプをドメインとする。\nシミュレーションの実行 ドメインのベイクからシミュレーションが開始される。 シミュレーション終了後は、アニメーションの開始からシミュレーション結果を確認できる。\n色々 シミュレーションを実行したら、水がグラスの外側に。 とりあえずシミュレーションしてみたらグラスから水は漏れないが、 外側に盛りだすという現象が発生した。\n\n⇒今のところ修正方法が不明。\nプレビューだと飛沫が確認できない 飛沫の設定をしてみたが、プレビュー状態だと確認できなかった。 レンダリングするときちんと描画されている。\n流体のマテリアル設定 流体のマテリアル設定は、流入口のほうではなく、ドメインに行う。\n参考資料  いろはメモ -Blender-: グラスに水を注いでみる 〈流体シミュレーション〉 Blender Cycles memo: オブジェクトの法線方向の確認方法  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/blenderfluidsimulation/","tags":["software"],"title":"Blenderで流体シミュレーション"},{"categories":null,"contents":"Jekyllでサイト内検索を作成するために、Googleカスタム検索を利用したのでメモ。 今のところ成功しておらず検索できない…。\n⇒ Googleウェブマスターツールで処理してから、 一日程度ほったらかしにしといたら、きちんと全体のページから検索できるようになった。\nたぶん結論 Googleカスタム検索を設定して、 Googleのウェブマスターツールでサイトマップを登録してあげると、たぶん検索できるようになる。 (検索できるようになるまでには、若干(1~数日程度)必要っぽい。\nウェブマスターツールのサイトマップも、登録後は勝手に更新されてる。\nGoogleカスタム検索を作成する Googleカスタム検索のページで、適当に検索したい検索クエリを作成する。\n作成した検索クエリの\u0026quot;コードを取得\u0026quot;からHTMLに貼り付けるスクリプトを取得し、 default.htmlに記載しておく(別にここである必要はない)。\n検索できるか試してみたができず…。\nサイトマップを作成する とりあえず関連してそうなサイトマップなるものを作成する。 サイトマップは、検索エンジンに検索させるために必要らしい。 GitHub: Jekyll Plugin: Sitemap.sml Generatorを利用する。\nconfig.ymlに以下を記述する。\nurl: https://iimuz.github.io\rsitemap:\rfile: \u0026quot;/sitemap.xml\u0026quot;\rinclude_posts:\r- \u0026quot;/index.html\u0026quot;\rchange_frequency_name: \u0026quot;change_frequency\u0026quot;\rpriority_name: \u0026quot;priority\u0026quot;\rやっぱり検索できない…。\nGoogleウェブマスターツールを利用する。 Google ウェブマスターツールのページからアクセスできるか確認したが、 データがありませんと表示される。 HELPには、しばらく待ってくださいとあったので、とりあえず放置してみる。\nサイトマップを送信 とりあえずやってみた。\n一部検索できるようになった! TOPページのみ検索可能になった。意味ないけどちょっと進歩。 なぜ下位のページが検索されないのか、こっちが本題なのに。\n検索式を変更 検索式を正規表現っぽくiimuz.github.io/*に変更してみた。\n参考資料  takemikami's note: blog用にjekyllを設定したメモ Googleカスタム検索 GitHub: Jekyll Plugin: Sitemap.sml Generator Google ウェブマスターツール  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jekyll/jekyllsearch/","tags":["jekyll"],"title":"Jekyllでサイト内検索(Googleカスタム検索)を入れる"},{"categories":null,"contents":"静岡Developers勉強会の「UnityとBlenderハンズオン第3章」の資料公開 に沿って進めてみる。\nパックマンもどきの作成 noobtuts: Unity 2D Pac-Man Tutorialに沿って、パックマンもどきを作成する。\nパックマンもどき: GitHub: pacmanClone\nMaze Physics Add ComponentsからPhysics 2DでBox Collider 2Dを追加する。 形状は、Edit Colliderを押して壁に合わせる。\nここは、かなりめんどくさい…。 より複雑な形状を作ろうとするなら、 ブロック(衝突判定付)のPrefub作って、それを配置したほうが、まだ早そう。 スクリプトで生成する方法もあるだろうけど、 実際に作ること考えたら画面上で動かしたほうが、やり易いだろうし。\nAdding Pack-Man 画像をUnity内で分割して利用する場合は、Import設定で、Sprite ModeをMultiplyにする。 それから、Sprite Editorを押すと分割処理ができる。 これを実行すると、Projectの該当画像の下階層に分割した画像が生成される。\nアニメーションは、アニメーションに利用する画像を一括選択し、SceneにD\u0026amp;Dすることで生成される。 そのとき適当にアニメーション名を設定して保存すればよい。\nアニメーションの再生は、無限ループになるらしい。\n Note: Unity will play the right animation over and over again while in right state. It will use Transitions to know when to switch to another state. Unity does all of that automatically, all we have to do is notify it about Pac-Man's movement direction from within a Script later on.\n アニメーションのメカニズムについては、 controllerファイル(pacman_0)を開いて、right(既にある)、left、up、downを全てD\u0026amp;Dで放り込む。\nアニメーションタブのParametersで追加(プラスボタン)を選択後、 FloatでDirXとDirYを作成する。これでスクリプトから以下のことができるらしい。\nGetComponent\u0026lt;Animator\u0026gt;().SetFloat(\u0026#34;DirX\u0026#34;, 0);\rGetComponent\u0026lt;Animator\u0026gt;().SetFloat(\u0026#34;DirY\u0026#34;, 0);\rAnyStateから右クリックで遷移線を引いて、\u0026ldquo;Can Transision To Self\u0026quot;のチェックを外す。 これは、毎回毎回繰り返しアニメーションが最初から開始されないようにするためらしい。 Conditionsの大小比較は、GreaterとLesserを選択する。\n Note: this avoids weird situations where an animation would be restarted all the time while holding down a movement key.\n アニメーションの変更はPackmanのFixedUpdate関数のスクリプト部分で、 以下のように記述して値を変更することで実現する。\nVector2 dir = dest - (Vector2)transform.position;\rGetComponent\u0026lt;Animator\u0026gt;().SetFloat(\u0026#34;DirX\u0026#34;, dir.x);\rGetComponent\u0026lt;Animator\u0026gt;().SetFloat(\u0026#34;DirY\u0026#34;, dir.y);\rPacmanを常に全面に表示するためには、Sprite Renderer -\u0026gt; Order Layerを1にする。 これは、OrderLayerが小さい順にUnityが描画するから。\n Note: Unity draws objects sorted by their order. It starts with the lowest order and continues with higher orders. So if Pac-Man has the order 1 then he's always drawn after the maze and the food and anything else with order 0. And because he's drawn after everything else, he's automatically in front of everything else.\n また、表示順の制御は、2通りあり(Sprite Render's Sorting layer or Order in Layer)、 今回は簡単な後者のOrder in Layerを利用しているが、 複雑な場合はSprite Render's Sorting layerのほうがよいらしい。\n There are two ways to do this. We could either change the Sprite Renderer's Sorting Layer property or we could change the Order in Layer property. The Sorting Layer is important for bigger games with far more objects. For us it's enough to simply change the Order in Layer to 1:\n ちなみにSprite Render's Sorting Layerを利用する方は、 第2章のほうで行ったnoobtuts: Unity 2D Arkanoid Tutorialの方で行っている。\nThe Pac-Dots Pac-Dotsのように衝突判定がほしいだけの時は、Box Collider 2Dのis TriggerをONにする。 おそらくその名の通りトリガがほしいだけの物体につけるフラグと思われる。\n Note: a Collider with IsTrigger enabled only receives collision information, it does not physically collide with other things.\n Pac-Dotsもかなりの量があって作るのが大変。 今回は、一行分を作って、それをPrefubにして、コピーの繰り返し。 いらない場所を消すことでPrefubではなくなるけど別に問題ないはず。\nThe Gosts Waypoint(Empty Object)で作成し、その位置を順に巡回するように設定する。\nvoid FixedUpdate() {\rif (transform.position != waypoints[cur].position) {\r// Waypoint is not reached yet? then move closer\r Vector2 p = Vector2.MoveTowards(transform.position,\rwaypoints[cur].position,\rspeed);\rGetComponent\u0026lt;Rigidbody2D\u0026gt;().MovePosition(p);\r} else {\r// Waypoint reached. select next one;\r cur = (cur + 1) % waypoints.Length;\r}\r最後に、Pinky、Inky、Clydeの追加があるが、同じ作業の繰り返しのため省略する。\nBlender: 人のモデルを作る 静岡Developers勉強会の「UnityとBlenderハンズオン第3章」の資料公開の p.81からの説明に沿って人のモデルを作成する。\n一通り知っていることだったので、そのまま作って終わり。\n本章までの人モデルの作成データ: GitHub: Human\n参考資料  静岡Developers勉強会の「UnityとBlenderハンズオン第3章」の資料公開 noobtuts: Unity 2D Pac-Man Tutorial noobtuts: Unity 2D Arkanoid Tutorial ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/shizuokadevunityandblender03/","tags":["software"],"title":"UnityとBlenderハンズオンの第3章を進めてみる"},{"categories":null,"contents":"自転車のサイクルコンピュータが壊れたので買い替える時のメモ。\n条件 現在探しているのは、以下のような条件。\n 一般的な速度などが測れれば良い。\nケイデンスとかまではいらない。 スマホ連携がほしい。\nデータを取り出して、その記録をどっかに残すことが簡易にできればそれでいい。 プラスアルファとしてGPSでコースを記録しておいてくれると尚よい。  比較 高すぎて手が出せないパターンは除外している。\n (外部センサーと表示部) CATEYE: マイクロワイヤレス = \\4,377 (外部センサーとスマホのみ) センサー CATEYE ICS-12 + スマホホルダー SPA-HB10 = 6,048 + 3,770 = \\9,818 (外部センサーとスマホのみ) センサー Wahoo Fitness + スマホホルダー SPA-HB10 = 7,091 + 3,770 = \\10,861 (外部センサーとサイコンとスマホ) センサー CATEYE ICS-12 + SMART STRADA + スマホホルダー SPA-HB10 = 6,048 + 6,690 + 3,770 = \\16,508 (上のパターンをCAT EYEで一括パッケージ買いの場合) = 12,092 + 3,770 = \\15,862 (外部センサーとサイコンとスマホ) センサー Wahoo Fitness + SMART STRADA + スマホホルダー SPA-HB10 = 7,091 + 6,048 + 3,770 = \\16,639 (外部センサーとサイコンとスマホ) センサー Wahoo Fitness + Wahoo RFLKT + スマホホルダー SPA-HB10 = 7,091 + 14,000 + 3,770 = \\24,861  結論 センサー CATEYE ICS-12 + スマホホルダー SPA-HB10\nそのうち、センサー CATEYE ICS-12 + SMART STRADA + スマホホルダー SPA-HB10になるかも。\n理由 まずは、サイコン代わりにスマホを使うパターンで利用する。 サイコンが欲しくなったら、その時に買い足す。 買い足すことを考えると、SMART STRADAがWahooより安い。 一括買いより700円位高くなるが、そこはあきらめる。\n調べている最中に気になった機種 表記は、機種(サイト: 調べた時点での価格)\nCATEYE: STRADA SMART(Amazon: \\6,690-) 2014年9月頃発売。 スマホに走行距離結果を出力可能。 加えて、ミラーモードでGPSによるコース記録も可能。\n ケータイWatch: スマホと強力に連携するサイコン「ストラーダスマート」 CAT EYE: CC-RD500B(ストラーダスマート) Amazon: キャットアイ(CAT EYE) ストラーダ スマート CC-RD500B STRADA SMART Bluetooth SMART対応  これは、アプリ(無料)だけでGPSのみで動作するサイコンになるのか? CAT EYEのオンラインマニュアルを見るとそんな感じに見えるんだが…。\n⇒アプリをダウンロードしてみたができそう。 その辺のサイクリング程度ならこのぐらいでも十分かもしれない。 CATEYE Atlasでログ管理ができるみたい。\n⇒STRADA SMARTは、別途センサーまわりを買う必要がありそう。 たぶん、これ( Amazon: キャットアイ(CAT EYE) ISC-12 Bluetooth SMART スピード\u0026amp;ケイデンスセンサー )だと思う。(現時点で、\\6,048-)\n⇒同じパッケージ版を見つけた。(\\12,092-) Amazon: キャットアイ(CAT EYE) ストラーダ スマート CC-RD500B STRADA SMART スピード+ケイデンスキット Bluetooth SMART対応\nCATEYE: マイクロワイヤレス(Amazon: \\4,377-) ロードバイク初心者ナビ: サイクルコンピューターによると、 もっとも標準的な感じらしい。\n ロードバイク初心者ナビ: サイクルコンピューター Amazon: キャットアイ(CAT EYE) マイクロワイヤレス CC-MC200W ブラック  POLAR(ポラール) サイクリング向け CS500(Amazon: \\26,948-) 色々とPCでもデータを管理できるようだけど、とりあえず高い。 一式そろえると\\40,000-近いのはなかなか手がでない。\n 家電批評モノマニア: 比較2015’ サイクルコンピューター最新15種類の性能・価格とおすすめ Amazon: POLAR(ポラール) サイクリング向け ハートレートモニター CS500cad  GARMIN EDGE 810J(Amazon: \\58,900-) サイクル用ナビという感じで地図までくっついてるのは非常に良い。 今ほしい機能は全て満たしている。ただ、高い…。\n 家電批評モノマニア: 比較2015’ サイクルコンピューター最新15種類の性能・価格とおすすめ  Wahoo Fitness スピード・ケイデンスセンサー(Amazon: \\7,091-) 表示部を全てiPhoneに任せたタイプ。 コンセプトは好きだし、非常によさそう。Androidにも対応しているらしい。\n 家電批評モノマニア: 比較2015’ サイクルコンピューター最新15種類の性能・価格とおすすめ すりゴマ・ドットコム Amazon: Wahoo Fitness  STRADA SMARTのようにするためには、サイコンも売っている。\n Amazon: 日本正規代理店品・保証付Wahoo Fitness サイクルコンピュータ RFLKT for iPhone (Bluetooth SMART/Bluetooth 4.0対応) WAF-PH-000011  スマホの固定 SPA-HB10(Amazon: \\3,770-) スマホの固定としてはよさそう。\n すりゴマ・ドットコム: スマホのロードバイク用ハンドルバーマウントは「絶対に落ちない」SONY SPA-HB10がファイナルアンサー！ Sony AV関連製品・アクセサリー: SPA-HB10の対応スマートフォン一覧 Amazon: SONY スマートフォン用 幅 71mm ハンドルバーマウント SPA-HB10  参考資料  ケータイWatch: スマホと強力に連携するサイコン「ストラーダスマート」 CAT EYE: CC-RD500B(ストラーダスマート) Amazon: キャットアイ(CAT EYE) ストラーダ スマート CC-RD500B STRADA SMART Bluetooth SMART対応 CATEYE Atlas ロードバイク初心者ナビ: サイクルコンピューター Amazon: キャットアイ(CAT EYE) マイクロワイヤレス CC-MC200W ブラック 家電批評モノマニア: 比較2015’ サイクルコンピューター最新15種類の性能・価格とおすすめ Amazon: POLAR(ポラール) サイクリング向け ハートレートモニター CS500cad runtastic Amazon: Wahoo Fitness Sony AV関連製品・アクセサリー: SPA-HB10の対応スマートフォン一覧 Amazon: SONY スマートフォン用 幅 71mm ハンドルバーマウント SPA-HB10 すりゴマ・ドットコム: スマホのロードバイク用ハンドルバーマウントは「絶対に落ちない」SONY SPA-HB10がファイナルアンサー！ すりゴマ・ドットコム: 色々比較したけど、サイクルコンピューターはwahooがおすすめ。Androidにも対応。アプリもいいよ！ すりゴマ・ドットコム: おすすめサイクルコンピュータアプリ Wahoo fitnessがようやくAndroidに正式対応！(4.3以上) Amazon: キャットアイ(CAT EYE) ISC-12 Bluetooth SMART スピード\u0026amp;ケイデンスセンサー Amazon: キャットアイ(CAT EYE) ストラーダ スマート CC-RD500B STRADA SMART スピード+ケイデンスキット Bluetooth SMART対応 Amazon: 日本正規代理店品・保証付Wahoo Fitness サイクルコンピュータ RFLKT for iPhone (Bluetooth SMART/Bluetooth 4.0対応) WAF-PH-000011  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/cyclocomputer/","tags":["bicycle"],"title":"サイクルコンピュータの買い替え"},{"categories":null,"contents":"Minecraft1.7.10で侵略mod環境を構築する。\n導入mod  Forge Optifine Shaders mod(updated by karyonix) Sonic Ether's Unbelievable Shaders v10.1 Invasion Mod - So you think your base is tough? NotEnoughItems Waila 1.5.7 for 1.7.10 / 1.6.0 for 1.8.1 Rei’s Minimap Mod 1.7.10, 1.7.2, 1.6.4 and 1.5.2 一括破壊系MOD＋α FLAN'S MOD  Modern Weapons Pack World War Two Pack   LittleMaidMob Ver0.0.8 \u0026amp; 座布団 3/17更新 Millenaire THE CHOCOLATE QUEST WIKI SpawnChecker (Mobが湧くかをチェックするMOD) 1.7.2~1.8ネザースターが作れるようになったりするMODなど  導入手順 前準備 Minecraft 1.7.10を起動し、初期状態を用意する。\nForgeの導入   Forgeよりインストーラ版をダウンロードする。\nRecommendバージョンでないと、Optifineのところでエラーした。\n  forgeでインストールされたMinecraftのプロファイルを編集し、 Game Directoryをforgeのインストーラで作成されたディレクトリに変更する。\n  Invasion mod用にディレクトリを分割  forgeのプロファイルからNew Profileしてコピープロファイルを作成する。  Profile Name: 1.7.10_invasion Game dir: 1.7.10_invasion Use version: release 1.7.10-Forge 10.13.2.1291    Optifineの導入   OptifineからForge対応版をダウンロードする。\n今回は、Standerd版のB1を選択した。\n  optifineのjarファイルを1.7.10_invasion/modsにコピーする。\n  影modの導入  Shaders mod(updated by karyonix)からダウンロードする。 1.7.10_invasion/modsにコピーする。  シェーダパックの導入   Sonic Ether's Unbelievable Shaders v10.1からダウンロードする。\n今回は、スタンダードパックにした。\n  1.7.10_invasion/shaderspacksにコピーする。\n  minecraftを起動して、Optionsのshaderから選択する。\n  その他に、以下の設定をする。\n minecraftの通常の雲をoffにする。    Invasion modの導入 Invasion Mod - So you think your base is tough?からダウンロードする。 1.7.10_invasion/modsにコピーする。\nその他modの導入   Chicken Bones Modsから、以下の2つをダウンロードして導入する。\n CodeChickenCore NotEnoughItems  アイテムの一覧とかレシピが見れる。\n  Waila 1.5.7 for 1.7.10 / 1.6.0 for 1.8.1を導入する。\n  画面上で、視点の先に何があるかが表示される。 NotEnoughItemsとの関係で、1.6版をダウンロードしてインストールする。\n加えて、デフォルトではONになっていないので、Numpad0からメニューを開いてvisibleにする。\n  Rei’s Minimap Mod 1.7.10, 1.7.2, 1.6.4 and 1.5.2: ミニマップ\n  一括破壊系MOD＋α\n  定番のCutAll、DigAll、MineAllの導入。 パラメータは適当に変更する。特にキーはかぶっているので変更する必要あり。\n  FLAN'S MOD\n Contens: Modern Weapons Pack World War Two Pack: 固定砲台用    LittleMaidMob Ver0.0.8 \u0026amp; 座布団 3/17更新: 補助味方ユニット追加\n  Millenaire\n  導入するためには、ダウンロードしてきて解凍してから、中身をmodsフォルダにコピーする。\n  THE CHOCOLATE QUEST WIKI: ダンジョン追加\n  Inventory Tweaks 1.59 (March 31): アイテム整理\n  SpawnChecker (Mobが湧くかをチェックするMOD): わきつぶし用\n  1.7.2~1.8ネザースターが作れるようになったりするMODなど: 火薬作成用\n  結局入れていないmod 固定砲台 エネルギー系を扱う必要がありそうだったのでやめた。\n OpenModularTurrets Thermal Foundation CoFHCore  参考資料  Forge Optifine Shaders mod(updated by karyonix) Sonic Ether's Unbelievable Shaders v10.1 Invasion Mod - So you think your base is tough? Chicken Bones Mods Waila 1.5.7 for 1.7.10 / 1.6.0 for 1.8.1 Rei’s Minimap Mod 1.7.10, 1.7.2, 1.6.4 and 1.5.2 一括破壊系MOD＋α FLAN'S MOD LittleMaidMob Ver0.0.8 \u0026amp; 座布団 3/17更新 Millenaire THE CHOCOLATE QUEST WIKI Inventory Tweaks 1.59 (March 31) SpawnChecker (Mobが湧くかをチェックするMOD) OpenModularTurrets Thermal Foundation CoFHCore 1.7.2~1.8ネザースターが作れるようになったりするMODなど  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/minecraft/minecraftinvasionmod/","tags":["minecraft"],"title":"Minecraftで侵略mod"},{"categories":null,"contents":"Oculus Rift DK2を注文したので、その経過をメモ。\n⇒到着済み(2015.05.09)\n現状ステータス  2015/5/9: 受け取り完了。 2015/5/7: 一度配達されていることを確認。 2015/5/6: 日本に到着(FedExのログで確認)。  注文の流れ(2015/5/2) Oculus VRのページが日本語に対応しているので非常に簡単。 購入のページから一通り流されるままに記入して、支払うだけ。 以下のページの左上の購入から進む。\n Oculus VR  全部半角英数字での入力が必要となる。 英語表記だと県とか市とかどう表現するのが適切知らないので、全部日本語表記(Tokyotoなど)する。 ContryのみJapanとしておけば、日本にたどり着いてからは日本語が読める人が対応するはずだし、 そうすればローマ字表記は読めるはず。\n注文が成功すれば、入力したメールアドレスに\u0026quot;注文ありがとう\u0026quot;といったメールが来る。\n Oculus VR: ご注文ありがとうございます / ご注文番号 [xxxxxxxx]\nThanks for your pre-order!\n 確認と発送(2015/5/4) 発送が開始されてカードで請求できたら、以下のメールが来た。\n Oculus VR: Payment received for your pre-order\nYou're receiving this email because your Oculus Order xxxxx is about to ship, and we've charged the remaining balance to the credit card on file.\n このメールには、現在のステータスが書かれているページへのアクセスURLが記載されている。 Oculus Order Managerというらしいが、ここのページにアクセスすると登録したアドレスが要求されるので、 入力するとOculusr Order Managerへのアクセス方法が書かれたメールが送信される。\nOculus Order Manager Oculus Order Managerにメールアドレスを入力すると、 Order InformationへのアクセスURLがメールで送られてくる。\n Oculus VR, LLC. Order Info\nYou can use the following link to access your order information:\n このURLへアクセスすると、現在の状態と送先住所、支払い状況が確認できる。\n発送中(2015/5/6) 発送はFedExというのが利用されるらしい。 FedExの状態を確認するためのメールが送られてきて、ここでは時間(分単位)でどこにあるのかわかる。\n Oculus VR Order xxxxxx Shipping Notification\nYour order xxxxxxx has been shipped.\nPlease click the following link(s) to access the tracking information:\n 受け取り完了(2015/5/9) 中身はOculusRiftDK2と説明書。 なぜか関税は払うことなく終わってしまった???\n参考資料  Oculus VR  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/hardware/oculusriftdk2/","tags":["hardware"],"title":"Oculus Rift DK2を注文した"},{"categories":null,"contents":"静岡Developers勉強会の「UnityとBlenderハンズオン第2章」の資料公開 に沿って進めてみる。\nブロック崩しもどきを作成 noobtuts: Unity 2D Arkanoid Tutorial に沿ってブロック崩しもどきを作成する。\nブロック崩しもどき: GitHub: arkanoidClone2d\nThe Hexagon Background Pattern 背景画像のFilter ModeをPointにすることで、 画像をぼやけさせずにドットを強調させることができる。\n表示順を制御するために、layer設定を行う。 背景画像のSorting LayerからAdd Sorting Layer\u0026hellip;を選択し、 Sorting LayerにLayerを追加する(ここではBackground)。 そして、Backgroundを一番上に持ってくる。これで背景が背景として一番下に表示される。\n Note: Unity draws the layers from top to bottom, hence whatever should be in the background will be at the top of the list.\n Adding the Borders 2Dのオブジェクトに四角形の衝突判定を持たせるときは、 Box Collider 2Dを利用する。\nThe Racket 2Dのオブジェクトに物理法則を適用するには、Rigidbody 2Dを利用する。 ただし、今回の場合、バーに重力の影響を考慮する必要がないため、Gravity Scaleの値を0にする。\nスクリプトで毎回更新する関数はUpdate()だが、 物理法則を適用したオブジェクトの更新はFixedUpdate()のほうがよいみたい。 理由は、Unityが物理計算を同じタイミングでするかららしい。\n There is yet another type of Update function, it's called FixedUpdate. It's also called over and over again, but in a fixed time interval. Unity's Physics are calculated in the exact same time interval, so it's always a good idea to use FixedUpdate when doing Physics stuff (our racket has a RigidBody and a Collider, which makes it Physics stuff).\n 方向毎の動きについては、キーの入力を毎回判定してもよいが、 Unityの横方向の動きを取れば、キーやパッドの操作も受け取れるみたい。\nfloat h = Input.GetAxisRaw(\u0026#34;Horizontal\u0026#34;);\r右方向のベクトルは以下のように取得できるらしい。\nGetComponent\u0026lt;Rigidbody2D\u0026gt;.velocity = Vector2.right * h * speed;\rThe ball なぜかballに対する衝突判定は、Box Collider 2Dを利用するらしい。 Circle Collider 2Dが自然な気がするんだが…。後で理由がわかるか?\n反発とかをスクリプトで組んでもよいらしいが、 基本的な法則ぐらいならPhysics2D Materialを利用すれば、 FrictionとかBouncinessは対応できるみたい。\nボールの物理特性は、Massが0.0001でバーを動かさないようにする。 重力は無効らしい。 (重力で落とすのではなく、基本的にVelocityが一定で反発することで動作させる予定なのか?)\n衝突したときに呼ばれる関数は、OnCollisionEnter2Dとなる。\n衝突した物体の情報を取得するには、関数を以下のように定義する。\nvoid OnCollisionEnter2D(Collision2D col) {\r}\r衝突物体をキャストして、元の型に戻すことで、サイズを取得している。\nfloat x = hitFactor(transform.position, col.transform.position,\r((BoxCollider2D)col.collider).size.x);\r2Dベクトルの正規化は、以下のようにすることで一発らしい。(正規化しないと速度が変わってしまう)\nVector2 dir = new Vector2(x, 1).normalized;\rAdding Blocks Destroy()を呼ぶときにクラス内でDestory(this)は、スクリプトを消すだけらしい。 物体ごと消す場合は、Destroy(gameObject)とする必要がある。\nやってる途中で気付いたが、 blockにColliderとScriptを貼り付けてPrefubにしてから設置したほうが早くないか? あと、一気にStart()とかで機械的に貼り付けたほうが、この配置は早いんじゃ…。\n静岡Developers勉強会の資料には、きちんと一括作成方法が乗っていました。 ずっとnoobtutsのページのみ見て作成してて後から、 スライドを流し身したら載ってた…。\nスコア作成 ここから、静岡Developers勉強会の「UnityとBlenderハンズオン第2章」の資料公開 の資料に沿ってスコアを作成する。\nHierachyのCreateからUI -\u0026gt; Textを作成すると、EventSystemが自動で作成されるが、 これは画面のボタンイベントなどで利用するらしいので今回は削除する。\nUnity: Shooting Game 第12回 Waveを5個にする、スコアの実装 に記載されているScore.csをコピーする。\nUnityのUI関連が更新されているようで、 そのままGUITextとしてもscoreテキストをInspectorから設定できない。 Unity5(いつからなのか知らない)だと以下のようにする必要があるみたい。\n- public GUIText scoreGUIText;\r+ public UnityEngine.UI.Text scoreGUIText;\rUnityでのデバッグ方法は、 Monoからスタートボタン(三角印)を押して、Attach to ProcessでUnity Editore(Unity)でAttachしてから Unityでスタートすればよい。\nサイコロの作成 サイコロ: Github: dice\nべベルの追加 べベルとは、辺や角をなめららにする効果のこと。 プロパティエディタのスパナアイコンから追加でべベルを選択する。 適用を押さないと反映されないので注意。\nループカットは、面を分割する。Ctrl+Rキーでできる。 ピンク色の線を出してから数字を押すと勝手に等間隔でその数の線を引く。 つまり、2を押せば、2本の線で3分割する。\n目の箇所を凹ますために、 まず、押し出しで各面ごとを選択し、即右クリックで確定する。 ここで、マウスを動かすと押し出しの量が変更される。 2回目の押し出しは、適当に押し出し量を変更する。\n細分割局面を利用して、目の部分を局面にする。細分化のビューを1から3に変更する。 ここでは、適用ボタンを押さない。\n目の中心部分を選択しCtrl++(プラス)で選択した面のまわりへ選択を広げる。\nテーブルを作成する サイコロ: Github: 木目テーブル\nオブジェクトモードから編集モードに変更して物体を追加すると同じグループになる。\n対称形の物体は、ミラーで作成すると早い。\n参考資料  静岡Developers勉強会の「UnityとBlenderハンズオン第2章」の資料公開 noobtuts: Unity 2D Arkanoid Tutorial Unity: Shooting Game 第12回 Waveを5個にする、スコアの実装 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/shizuokadevunityandblender02/","tags":["software"],"title":"UnityとBlenderハンズオンの第2章を進めてみる"},{"categories":null,"contents":"静岡Developers勉強会: UnityとBlenderハンズオン 第1章 でUnityとBlenderの使い方を勉強する。\nUnityでテトリスもどきを作成 noobtuts: Unity 2D Tetris Tutorialを参考に、 テトリスもどきを作成するようなので読みながら作ってみる。\nテトリスの著作権については、ここを参照。\nテトリスもどき: GitHub: likeTetris2d\nProject Setup 当然のことながら2Dプロジェクト\nCreating the Game Art そのままの画像では面白くないので、BEIZ Graphicsから画像をダウンロード。\nプロジェクトのAssetsフォルダに画像を直接追加するとUnityのGUI上で反映される。\nゲーム中のサイズはPixels to unit(Unity5だとPixels per unit?)になるらしい。\n Note: the Pixels to Units property specifies the size in game.\n Creating the Groups ブロックの集合は、Prefubで作成する。\nThe Spawner スポナーは、空オブジェクトで作成する。\nQuanternion.indentityは、回転方向をデフォルトにする。\n Note: transform.position is the Spawner's position, Quaternion.identity is the default rotation.\n The Grid Script Math関数を利用するので、Systemを追加する。\nMath.Roundがdoubleを返すようなので、floatにキャストする。\nThe Group Script 途中でlastFall変数が出てくるが、これはfloatでメンバ変数に定義する必要がある。\nUpdate()の中が同じコードの繰り返しのため、適当にメンバ関数に切り分けて記述したほうが見やすい気がする。\n他のオブジェクトの関数を呼び出す場合には以下のように書く。\nFindObjectOfType\u0026lt;Spawner\u0026gt;().spawnNext(); // Spawn next grouup.\rBlender編 サイコロを作成する。\nサイコロ: GitHub: chapter01\n設定情報の変更 FPSを29.97に設定する。\nインターフェースを日本語化する。\n User Preferences -\u0026gt; System -\u0026gt; International Fonts を Japanese にする。  TranslateのInterfaceとTooltipsをONにする。    選択を中心に回転およびPythonツールチップを表示\n User Preferences -\u0026gt; Interface  選択を中心に回転をON Pythonツールチップを表示をOFF    3Dビュー Dynamic Spacebar Menu\n User Preferences -\u0026gt; アドオン -\u0026gt; 3Dビュー Dynamic Space bar Menu をON  履歴操作  元に戻す(Ctrl + Z) やり直す(Shift Ctrl + Z)  サイコロ作成(UVマッピング) 動画(Youtube: Blender入門講座｜実践編｜UVマッピング)を参考にサイコロを作成する。 画像は、GitHub: yaju/ShizuokaDev_UnityAndBlenderからコピーしてくる。\n表示モードは、UVマッピング用のUV Edittingを選択する。\nオブジェクトのエディットモードで、 線選択で展開するときに切るところを選択し、 左側のシェーディング/UVタブからシームを付ける(Mark Seem)を選択する。\n全選択で、シェーディング/UVタブから展開(Unwrap)を選択する。\n貼り付ける画像(dice.png)を下側の画像-\u0026gt;画像を開くから選択する。\n3Dビューのシェーディングでテクスチャを選択すると、 画面上にテクスチャが張り付いて表示される。\n頂点選択してpボタンで、頂点のピン止めを行うことで、移動しない点を作ることができる。\n直方体のテクスチャで画像を設定する。 マッピングの座標をUVに設定する。 ただし、プレビューは正しく表示されないが、F12でレンダリングすればきちんと表示される。\n適当に光源を移動して、表示している面が見えるようにする。\nUnity用の修正 UnityやWebGLでは四角形のポリゴンを表示できないため、三角形ポリゴンに分割が必要らしい。\nCubeを全選択後に、Ctrl+Fから三角形に分割を選択する。\nJason形式にエクスポート GitHub: mrdoob/three.jsからリポジトリをダウンロードして、zipファイルを解凍する。 解凍したフォルダ内にあるio_threeをBlenderのaddonにコピーする。\ncp three.js-master/three.js-master/utils/exporters/blender/addons/io_three blender/version/scripts/addons/\rBlenderで有効にするために、 User Preferences -\u0026gt; アドオン -\u0026gt; カテゴリ -\u0026gt; インポート/エクスポートから、 Three.js Formatを探してONにする。 表示されていなければ、更新ボタンを押せば出てくるはず。\nファイル -\u0026gt; エクスポート -\u0026gt; Three(json)でエクスポートする。\nサイコロを作成? Youtube: blender初心者モデリング\nなぜ先ほどと違うサイコロを作成するのか、よくわからないので今は飛ばす。 後で必要になったら作る。\n⇒本当にBlenderの使い方を勉強するためだけだったみたい。 後で必要な知識は調べればいいので、今はいらない。\n参考資料  静岡Developers勉強会: UnityとBlenderハンズオン 第1章 noobtuts: Unity 2D Tetris Tutorial BEIZ Graphics HOTNEWS: テトリスの著作権について【自作テトリスを公開したら違法？】 Youtube: Blender入門講座｜実践編｜UVマッピング GitHub: yaju/ShizuokaDev_UnityAndBlender GitHub: mrdoob/three.js Youtube: blender初心者モデリング ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/shizuokadevunityandblender01/","tags":["software"],"title":"UnityとBlenderハンズオンの第1章を進めてみる"},{"categories":null,"contents":"素材集など、何度も繰り返し利用するようなリンク集。\n画像素材  いらすとや: いわずと知れたサイト pixabay: CDN があるのでダウンロードしなくても使えそうです。 BEIZ Graphics  音素材  mobile backend: ゲーム開発に使える音源配布サイトまとめ(効果音編)  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/others/materialslink/","tags":["blog"],"title":"色々なリンク(素材集など)"},{"categories":null,"contents":"Unityの環境を構築するまで。\n最初に 最初の思い付きは、 機械学習を利用していると何をしているかよくわからないので、 計算過程や結果の可視化を行うために利用できないかということ。 最終的には以下の環境が必要?\n グラフィック = Unity  C#も利用する   モデル作成 = Blender 学習アルゴリズム = C++、OpenCV、Python、C#  なので、見た目動くと楽しいので、Unityを構築して遊んでみる。\n環境構築  インストーラをダウンロードしてインストールする。 ついでにExampleProjectもインストールしておいた。 Activate your licenseは、Unity 5 Personal Edition。 Create Accountからアカウントを作成。 作ったアカウントですぐにアクティベート。 questionがあるので適当に回答する。 Country = Japan what capacity = Hobbyist Categorize = Programmer Unity skills = Absolute beginner team sizse = 1 Platform interest = windows type of content = Research projects  ドットインストールで入門 ドットインストール: Unity入門にて、最初から順に進める。 説明されているのはUnity4系だけど、 利用しているのはUnit5なので若干違いがあるのかもしれないが、 大まかな利用方法がわかればいいので、細かいところは気にしない。\n作成したもの: GitHub: dotinstall\nmyFirstUnity  #01 Unityとはなにか? #01 Projectを作ってみよう #03 画面の見方を覚えよう  画面の配置をTallにする。 SceneとGameタブを上下に配置する。 構成は、以下のような感じ。\n= Scene\n== GameObject\n=== Component\n= Assets: 共通部品   #04 視点を操作してみよう  File-\u0026gt;Scene保存でAssetsに追加される。 Hierachyでオブジェクト名をダブルクリックするとScene画面でオブジェクトを中心に表示できる。 Scene画面の左上のカメラ移動とかは左からQWERにショートカットキーが割り当てられている。 視点移動は、Altキーを同時に押すと角度が変更できる。 視点移動は、Ctrlキーを同時に押すと拡大/縮小が変更できる。\n⇒できなかった。中央のホイールの動作でできたので、それで十分。   #05 GameObjectの操作をしてみよう  移動(Wキー)、回転(Eキー)、拡大/縮小(Rキー)に対応。 各軸をドラッグすると、その軸方法の動きをする。 中央をドラッグすると自由移動。 右上の視点下にある部分をクリックして三本線(三)だと遠近法なし、\u0026lt;の中に線がある感じだと遠近法あり。 Shiftを押しながら、視点の真ん中の□をクリックすると、見下ろし視点。   #06 Transformを使ってみよう  現在のScene画面とカメラを一致させるには、Hierachyからカメラオブジェクトを選択し、 GameObject-\u0026gt;AlignWithViewを選択する。   #07 Materialを使ってみよう  Materialの管理は、Assets。 作ったMaterialをHierachyのオブジェクトにドラッグ\u0026amp;ドロップで適用できる。 テクスチャをマッピングする方法が、動画のようにできなかった。  Assetsで右クリックからImport New Assets\u0026hellip;を選択する。(ここは一緒) テクスチャをAssetsのMaterialにあるAlbedoの左側にD\u0026amp;Dする。(ここが違う。あってるかも不明だが適用された。) テクスチャの繰り返しは、Tilingの数値を変更すれば適用される。     #08 Regidbodyを使ってみよう  Regidbodyは物理特性を追加する。 HierachyからObjectを選択し、Add ComponentsからPhysics-\u0026gt;Regidbodyを選択する。 Massが重さで、Use GravityのチェックボックスをONにする。 アニメーションを見るには、右上の再生ボタンを押す。 反発は、AssetsにPhysics Materialを追加し、Bauncinessの値を大きくする。 あとは、普通のMaterialと同様にオブジェクトにD\u0026amp;DでくっつければOK。   #09 Directional Lightを追加しよう  なぜか最初からDirectional Lightがついていたので、視聴しただけ。 再生中のオブジェクトの変更は、再生をやめると全て破棄される。 再生中の画面の色変更は、Edit-\u0026gt;Preferences-\u0026gt;Colors-\u0026gt;General-\u0026gt;Playmode tintで変更できる。   #10 GameObjectを階層化してみよう  オブジェクトの階層化は、子オブジェクトを親オブジェクトにD\u0026amp;Dする。 親子関係を作ると、親のPhysics Materialが子にも適用されていた。 単純にグループ化する場合は、GameObjectで空のオブジェクトを作って、空オブジェクトの子に入れればよい。   #11 Prefabを使ってみよう  prefabは、オブジェクトのアセット化。変更を一括でできる。 HierachyのオブジェクトをAssetsにD\u0026amp;DでOK。 Assetsの方で変更を加えると、一気に変更できる。    mySecondUnity   #12 Scriptを追加してみよう\n Scriptはオブジェクトに適用する。AssetsからオブジェクトにD\u0026amp;Dする。  エラーが発生して、オブジェクトにつけられなかった。\nCan't add script component \u0026lsquo;playerScript\u0026rsquo; because the scirpt class cannot be found. Make sure that there are no compile errors and that the file name and class name match. 理由はエラー文の通り。 C#の自動で作成されるスクリプトのファイル名を後から変えたので、 クラス定義とファイル名があっていなかったから。 きちんとplayerScriptにクラス名を変更したらエラー発生しなかった。   Scriptは、Assetsから追加する。  C#とJavaScriptが選べる。   今回は、C#を選択したので動画と違う。 編集は、ScriptのOpenからできるがMonoDevelopはいろいろめんどいので、 自分のエディタに変更する。  Edit-\u0026gt;Preferences-\u0026gt;External Tools-\u0026gt;External Script Editorでexeを選択する。   Openで毎回エディタが開かれるのもめんどくさいので、以下に保存されることがわかっているので、 そっちから編集する。\nProject/Assets/hoge.cs    #13 はじめてのScript\n ScriptはJavaScriptではなく、C#を利用するので、 Qiita: UnityをC#で超入門してみる #1 Unity入門の章 のスクリプトを参照する。(まあ、ほぼ一緒) Scriptの最新の一行は、一番下に表示されるが、 見にくいのでWindow-\u0026gt;Consoleで表示して、タブはどっかにマージする。 デバッグ用出力は以下のコード。  void Start () {\rint x = 5;\rDebug.Log(\u0026#34;hello world. val = \u0026#34; + x);\r}\r 以下のようにすれば変数をUnityのGUIから変更できる。  public int x = 5;\r// Use this for initialization\rvoid Start () {\rDebug.Log(\u0026#34;hello world. val = \u0026#34; + x);\r}\r  #14 GameObjectを移動させてみよう\n コガネブログ: 【Unity】Transform型の位置や回転角、サイズの設定を楽にするによると、 C#で変数に値を入れるためには、一度変数に入れるかnewが必要。 あと、Translate関数の使い方は、Documentatin: Transform.Translateを読む。  transform.position.x = 1; // エラー\r\r// OK\rVector3 pos = transform.position;\rpos.z += 0.1f;\rtransform.position = pos;\r// OK\rtransform.position = new Vector3(\rtransform.position.x,\rtransform.position.y,\rtransform.position.z + 0.1f);\r// OK\rtransform.Translate(0, 0, 0.1f);\r  #15 ユーザー入力を受け付けよう\n  キー入力への反応はInput.GetButtonUpでKeyを渡す。\n スペースは、KeyがJump。  if (Input.GetButtonUp(\u0026#34;Jump\u0026#34;)) {\rDebug.Log(\u0026#34;jumped!\u0026#34;);\r}\r Inputの割り当ては、Edit-\u0026gt;Project Settings-\u0026gt;Inputで確認できる。    左右キーの入力受付。\n  transform.Translate(Input.GetAxis(\u0026#34;Horizontal\u0026#34;) * 0.2f, 0, 0);\r  #16 衝突判定をしてみよう\n RegidbodyのConstraintsで、Freeze Rotationにチェックを入れると、回転しなくなる。 以下のようにすると、衝突した物体を判定し、条件分岐ができる。  void OnCollisionEnter(Collision obj) {\rif (obj.gameObject.name == \u0026#34;RightWall\u0026#34;) {\rDebug.Log(\u0026#34;Hit! R.\u0026#34;);\r}\r}\r  #17 動的にGameObjectを生成しよう\n Prefubから作成する。 以下のようなコードを書いて、ballにPrefubをD\u0026amp;Dで指定する。  public Transform ball;\rvoid Update()\r{\rif (Input.GetButtonUp(\u0026#34;Jump\u0026#34;)) {\rInstantiate(ball, transform.position, transform.rotation);\r}\r}\r  #18 OnGUIを使ってみよう\n GUIStyleをpublicで宣言してCameraにつけることで、Inspectorから操作できる。  public GUIStyle style;\rvoid OnGUI() {\rGUI.Label(new Rect(10, 10, 200, 50), \u0026#34;Game Over\u0026#34;, style);\r}\r Cameraのstyleからフォントサイズを変更する。    #19 別のSceneを呼び出してみよう\n Scene呼び出しは以下のように行う。  Application.LoadLevel(\u0026#34;GameOver\u0026#34;);\r 複数のSceneを利用するときは、File-\u0026gt;Build Settingsから利用するSceneを登録する。    #20 ゲームを書き出してみよう\n File-\u0026gt;Build SettingsのSceneの順は、最初に実行するmainが上。 File-\u0026gt;Build SettingsでPlatformを変更したらSwitch Platformを押すこと。 設定したらFile-\u0026gt;Build SettingsからBuildを押す。    ballGame あとは、既に説明してあることをやるだけ。 ここからは動画見ながら同時に同じ作業ができるので、動画+ちょっとの時間で一通り終わる。\n  #21 ボールゲームを作ってみよう\n  #22 Playerを動かしてみよう\n  #23 Enemyの設定をしていこう\n todo: 以下のコードは挙動が違う。Translateとpositionへの追加は違うらしい。  - transform.Translate(0, 0, -0.1f); // 今回の想定とは違う動き。\r+ transform.position += new Vector3(0, 0, -0.1f); // 今回想定している動き。\r Time.frameCountでフレーム数が得られる。    #24 衝突時にEnemyを消してみよう\n ScriptでOnCollisionEnter()内でDestroy(gameObject)をすると指定したオブジェクトを削除。    #25 Playerを小さくしていこう\n transform.localScaleでオブジェクトのサイズを変更できる。    #26 GameOver処理を作りこもう\n  プロジェクトのgit管理 とりあえずgitでプロジェクトを管理するので、.gitignoreは必須。 Qiita: Unity向け .gitignoreの設定についてのignoreリストをコピペ。\nゲーム書き出しで余分そうなデータが出たので、以下も追加。(いいのかは知らない)\n *_Data/ *.exe  参考資料  Unity  Download Documentatin: Transform.Translate   Qiita: UnityをC#で超入門してみる #1 Unity入門の章 Qiita: Unity向け .gitignoreの設定について ドットインストール: Unity入門  #01 Unityとはなにか? #02 Projectを作ってみよう #03 画面の見方を覚えよう #04 視点を操作してみよう #05 GameObjectの操作をしてみよう #06 Transformを使ってみよう #07 Materialを使ってみよう #08 Regidbodyを使ってみよう #09 Directional Lightを追加しよう #10 GameObjectを階層化してみよう #11 Prefabを使ってみよう #12 Scriptを追加してみよう #13 はじめてのScript #14 GameObjectを移動させてみよう #15 ユーザー入力を受け付けよう #16 衝突判定をしてみよう #17 動的にGameObjectを生成しよう #18 OnGUIを使ってみよう #19 別のSceneを呼び出してみよう #20 ゲームを書き出してみよう #21 ボールゲームを作ってみよう #22 Playerを動かしてみよう #23 Enemyの設定をしていこう #24 衝突時にEnemyを消してみよう #25 Playerを小さくしていこう #26 GameOver処理を作りこもう   BEIZ Graphics コガネブログ: 【Unity】Transform型の位置や回転角、サイズの設定を楽にする GitHub: ドットインストールをみて作成したもの  GitHub: myFirstUnity GitHub: mySecondUnity GitHub: ballGame   ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/unitytutorial/","tags":["unity"],"title":"Unity導入"},{"categories":null,"contents":"bash コマンドの備忘録。\n 再帰 ls: find -type f ディレクトリ以下の再帰で指定したファイルを削除する: rm $(find -type f | grep hoge); ntp を使わず http で時刻合わせ: sudo date --set @\u0026quot;$(wget -q https://ntp-a1.nict.go.jp/cgi-bin/jst -O - | sed -n 4p | cut -d. -f1)\u0026quot;  参考資料  俺的備忘録 ~なんかいろいろ~: ls コマンドで覚えておきたい使い方 16 個(+2 個) ntp を使わずに時刻を合わせるワンライナー（Proxy 環境下でも安心）  ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/bash/bashcommand/","tags":["bash"],"title":"bashコマンド"},{"categories":null,"contents":"BlenderでPythonを利用する。 ついでに、Blenderの物理シミュレーションをpythonで作成する。 作ったデータ: github: iimuz/blenderTutorials/cubePhysicsEngine\n起動したBlenderからPythonスクリプトを利用する 情報処理I: 第15回を参考に以下のようにする。\n\n物理シミュレーションをpythonで作成 株式会社CFlatの明後日スタイルのブログ: Blenderの物理シミュレーションをpythonスクリプトで作成 のスクリプトをいくつか変更して実行。\n ループすると余計なオブジェクトが削除できなないので、ループして全部削除する。  - bpy.ops.object.delete()\r+ for data in bpy.data.objects:\r+ data.select = True\r+ bpy.ops.object.delete()\r 光源をスクリプトで追加すると、名称が変わっていたので、光源の呼び出しで利用する名称を変更す。  #照明\r- bpy.data.objects[\u0026#34;Lamp\u0026#34;].location = (0, 0, N+10)\r- bpy.data.lamps[\u0026#34;Lamp\u0026#34;].type = \u0026#39;SUN\u0026#39;\r+ bpy.ops.object.lamp_add();\r+ bpy.data.objects[\u0026#34;Point\u0026#34;].location = (0, 0, N+10)\r+ bpy.data.lamps[\u0026#34;Point\u0026#34;].type = \u0026#39;SUN\u0026#39;\r cameraをスクリプトで追加すると、sceneのcameraに設定されないので設定されるように変更。\nBlender beta: un blender Still rendering from command line with external Python script  # 動画作成\r bpy.context.scene.camera = bpy.data.objects[\u0026#34;Camera\u0026#34;]\rbpy.context.scene.render.resolution_x = 400\rbpy.context.scene.render.resolution_y = 300\rbpy.context.scene.render.resolution_percentage = 100\rbpy.context.scene.render.image_settings.file_format = \u0026#39;AVI_JPEG\u0026#39;\r ファイルの保存場所をblenderのファイルと同じ場所に変更。  - bpy.data.scenes[\u0026#34;Scene\u0026#34;].render.filepath = \u0026#34;test.avi\u0026#34;\r+ bpy.data.scenes[\u0026#34;Scene\u0026#34;].render.filepath = \u0026#34;//test.avi\u0026#34;\r参考資料  株式会社CFlatの明後日スタイルのブログ: Blenderの物理シミュレーションをpythonスクリプトで作成 情報処理I: 第15回 Blender beta: un blender Still rendering from command line with external Python script ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/blenderpythonscript/","tags":["software"],"title":"BlenderでPythonスクリプトを利用する"},{"categories":null,"contents":"Blenderでのコマンド備忘録\n設定 余分なイメージや素材を保存しない blender 2.6: ミスからの回復によると、 User preferenceのSave Preview ImagesがONの場合、、 .blendファイルサイズが大きくなるのでOFFにする。\n参考資料  blender 2.6: ミスからの回復 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/blendersetting/","tags":["software"],"title":"Blenderコマンドの備忘録"},{"categories":null,"contents":"GitHubのアクセスに毎回パスワードを利用してpushするのがめんどくさいので、 sshキーを利用してアクセスする方法。\n手順 公開鍵の作成 もし、.sshフォルダに既に公開鍵id_ras.pubがあれば既に作成済みのため、 この手順は必要なし。\nssh-keygen -t rsa -C \u0026#34;hoge@example.com\u0026#34;\rhoge@example.comは自分のメールアドレスを記述する。 以下の3つの入力を求められるが全てEnterでよい。\n 鍵ファイルを保存するフォルダ パスフレーズ パスフレーズ(確認用)  パスフレーズについては、 本当は怖い情報科学: SSH秘密鍵のパスフレーズは（つけるなら）11文字以上にしましょうねという話 を読む。\n公開鍵をGitHubに登録する 以下のコマンドで表示される内容をそのまま、コピーしてGitHubのssh keyから登録する。\ncat ~/.ssh/id_rsa.pub\r試に接続する ssh -T git@github.com\r以下が表示されたら成功。\n You've successfully authenticated, but GitHub does not provide shell access.\n 参考情報  mon_sat at Co-Edo: SSHの公開鍵を作成しGithubに登録する手順 本当は怖い情報科学: SSH秘密鍵のパスフレーズは（つけるなら）11文字以上にしましょうねという話 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/githubssh/","tags":["git"],"title":"GitHubにSSHを利用して接続する"},{"categories":null,"contents":"Google Photosの画像をJekyllで貼り付ける際に、 画像サイズが勝手にリサイズされて小さくなっていたので、 原画像サイズで取得して貼り付ける方法。\n原画像での貼り付け 画像リンクのw500-h500とかs50とかの部分をs0にする。 以下に例を示す。\n- https://lh5.googleusercontent.com/-Sg_L4Jgkqb0/VTuO0HwGL_I/AAAAAAAAN6Y/muVxSUfMtGE/w500-h250-no/2015-05-25-settingPythonConsoleOnBlender.jpg\r+ https://lh5.googleusercontent.com/-Sg_L4Jgkqb0/VTuO0HwGL_I/AAAAAAAAN6Y/muVxSUfMtGE/s0/2015-05-25-settingPythonConsoleOnBlender.jpg\r元のリンクの貼り方だと、以下のような画像になる。\n\nそれが、リンクを修正すると以下のようになる。\n\n参考資料  クリボウのプログラミングひとりごと: Google+ でオリジナルサイズの画像を保存する方法 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/others/googlephotslink/","tags":null,"title":"Google Photosの画像URLを原画像サイズで取得する方法"},{"categories":null,"contents":"JekyllのTips。\nfor文の要素数を制限 {% raw %}\n- {% for post in site.posts %}\r+ {% for post in site.posts limit:5 %}\r{% endraw %}\nliquidの文法をエスケープ 下記のタグで囲む。 {と%の間にスペースを入れているので注意。\n{ % raw % }\rhoge hoge\r{ % endraw % }\r参考資料  Jekyll Tips1 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jekyll/jekylltips/","tags":["jekyll"],"title":"Jekyll Tips"},{"categories":null,"contents":"vimがun~ファイルを作成するようになったので、 un~ファイルを一か所にまとめる方法。\n特定フォルダに出力する :set undodir=C:/hoge/vim/undo\rその他の対処法 香り屋さんのページを参照。\n香り屋: Vimが変なファイルを作るようになった\n参考資料  香り屋: Vimが変なファイルを作るようになった ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/vim/vimunfile/","tags":["vim"],"title":"vimがun~ファイルを作るようになった"},{"categories":null,"contents":"最初のページに続きを読む機能を導入する方法。 要は、↓のような機能。\n方法   postmore.rbを_pluginsフォルダに導入する。\n  以下のように折り畳み機能を導入するコンテンツ表示部分を書き換える。\nメインページに導入するならindex.mdかindex.htmlあたり。\n  - {{ post.content }}\r+ {{ post.content | postmorefilter: page.url, \u0026quot;Read the rest of this entry\u0026quot; }}\r 各記事の折り畳みを行うところで以下のコードを記述しておく。  \u0026lt;!--more --\u0026gt;\r参考資料  Jacques Fortier GitHub Gist: ravasthi / postmore.rb ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jekyll/jekyllmorepost/","tags":["jekyll"],"title":"Jekyllで'続きを読む'機能を導入"},{"categories":null,"contents":"Jekyllのページネーション機能を有効にする方法。\n方法  以下のコードを_config.ymlに記述する。  paginate: 5\r index.htmlに以下を書き換える。\nここで、index.mdではダメで、index.htmlにする必要がある。  {% raw %}\n---\rlayout: default\r---\r\u0026lt;h2\u0026gt;Pages\u0026lt;/h2\u0026gt;\r{% for post in paginator.posts %}\r\u0026lt;h3\u0026gt;\u0026lt;a class=\u0026quot;post-title\u0026quot; href=\u0026quot;{{ post.url | prepend: site.baseurl }}\u0026quot;\u0026gt;\r{ { post.title } }\r\u0026lt;/a\u0026gt;\u0026lt;/h3\u0026gt;\r\u0026lt;p class=\u0026quot;post-excerpt\u0026quot;\u0026gt;\r{ { post.excerpt } }\r\u0026lt;/p\u0026gt;\r{% endfor %}\r{% if paginator.total_pages \u0026gt; 1 %}\r\u0026lt;div class=\u0026quot;pagenation\u0026quot;\u0026gt;\r{% if paginator.previous_page %}\r\u0026lt;a href=\u0026quot;{{ paginator.previous_page_path | prepend: site.baseurl | replace: '//', '/' }}\u0026quot;\u0026gt;\u0026amp;laquo; Prev\u0026lt;/a\u0026gt;\r{% else %}\r\u0026lt;span\u0026gt;\u0026amp;laquo; Prev\u0026lt;/span\u0026gt;\r{% endif %}\r{% for page in (1..paginator.total_pages) %}\r{% if page == paginator.page %}\r\u0026lt;em\u0026gt;{{ page }}\u0026lt;/em\u0026gt;\r{% elsif page == 1 %}\r\u0026lt;a href=\u0026quot;{{ '/index.html' | prepend: site.baseurl | replace: '//', '/' }}\u0026quot;\u0026gt;{{ page }}\u0026lt;/a\u0026gt;\r{% else %}\r\u0026lt;a href=\u0026quot;{{ site.paginate_path | prepend: site.baseurl | replace: '//', '/' | replace: ':num', page }}\u0026quot;\u0026gt;{{ page }}\u0026lt;/a\u0026gt;\r{% endif %}\r{% endfor %}\r{% if paginator.next_page %}\r\u0026lt;a href=\u0026quot;{{ paginator.next_page_path | prepend: site.baseurl | replace: '//', '/' }}\u0026quot;\u0026gt;Next \u0026amp;raquo;\u0026lt;/a\u0026gt;\r{% else %}\r\u0026lt;span\u0026gt;Next \u0026amp;raquo;\u0026lt;/span\u0026gt;\r{% endif %}\r\u0026lt;/div\u0026gt;\r{% endif %}\r{% endraw %}\n","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jekyll/jekyllpaginate/","tags":["jekyll"],"title":"Jekyllのページネーション"},{"categories":null,"contents":"gitのコマンドをよく忘れるので、利用するときに調べたらここに記載する。\nコマンド cloneする git: 2.1 Gitの基本 - Gitリポジトリの取得を参考にすると、 カレントディレクトリにフォルダを自動で作成してcloneする場合は、以下の方法。\ngit clone \u0026lt;url\u0026gt;;\rもし、cloneするディレクトリを指定する場合は、以下の方法でhogeフォルダに作成できる。\ngit clone \u0026lt;url\u0026gt; ./hoge;\rさらにブランチも指定したいならば、 Qiita: リモートから特定のブランチを指定してcloneする を参考にすると、以下の方法で可能。\ngit clone -b \u0026lt;ブランチ名\u0026gt; \u0026lt;url\u0026gt;;\rurlは、githubなら、対象リポジトリまで行って、 右のサイドバーにあるHTTPS clone URLというところをポチッすれば URLがクリップボードにコピーされる。\nbranchを作成する サルでもわかるGit入門: 1. ブランチを作成するを参考に。\ngit branch \u0026lt;ブランチ名\u0026gt;;\rpushする 初回のみ以下の方法で紐付が必要。\ngit push -u origin \u0026lt;ブランチ名\u0026gt;;\r2回目以降は、以下でできる。\ngit push;\rmergeする git merge \u0026lt;ブランチ名\u0026gt;;\rステージにaddしたデータの削除 hogehoge foobar Blog Style5: git addでステージングしたファイルをアンステージング(キャンセル)する を参考に、キャッシュのみ削除する場合は以下。\ngit rm --cache ./hoge.txt\rファイルごと削除する場合は以下。\ngit rm ./hoge.txt\rサブモジュールの追加 サブモジュールとして取り込む。\ngit submodule https://github.com/hoge hoge\rリモートのアドレスを調べる git remote -v\r参考資料  git: 2.1 Gitの基本 - Gitリポジトリの取得 Qiita: リモートから特定のブランチを指定してcloneする サルでもわかるGit入門: 1. ブランチを作成する hogehoge foobar Blog Style5: git addでステージングしたファイルをアンステージング(キャンセル)する ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/gitcommand/","tags":["git"],"title":"Gitのコマンド備忘録"},{"categories":null,"contents":"MinecraftでDQM4 modを導入したときにやったこと。 DQM4 modとは、Minecraft DQM IVのこと。 重要そうなページは、以下の4つ。\n Minecraft DQM IV マインクラフト 非公式日本ユーザーフォーラム: DQM IV Minecraft ドラクエMOD DQM4mod 攻略wiki Minecraft MOD DQM4 wiki  導入した全MOD  minecraft forge DQM4 前提 resourceフォルダへ導入  DQM4 音楽   modsフォルダへの導入  DQM4 本体 1.5.2 DamageIndicators v2.7.0.1 InventoryTweaks-1.54 BiblioCraft[v1.3.3] ZansMinimap1.5.2 Waila_1.3.10_1.5.2 %5B1.5.2%5DCutAll_v2.4.1 %5B1.5.2%5DDigAll_v2.2.1 %5B1.5.2%5DMineAll_v2.5.1   coremodsフォルダへの導入  CodeChickenCore 0.8.7.3-fix1 ChickenChunks 1.3.2.14 NotEnoughItems 1.5.2.28    入れられなかったMOD   chicken関連\nなぜか干渉して入れれなかった。core+chunksは、起動しなくなる。 core+notEnoughItemsは、起動するけど表示されない。\n  導入手順 基本は、全てMinecraft DQM IVの導入方法及び動画に従う。 以前導入したDQM3Nextとかと干渉して失敗する部分があったようなので、.minecraftを全削除してから実行した。\n  以下のファイルを全てダウンロードする。\n minecraftforge-universal-1.5.2-7.8.1.738 forge 1.5.2 libファイル 1.5.2DQMIV Ver8.75 前提・本体 1.5.2DQMIV Ver.4.20 音声・BGM    1.5.2のプロファイルを作成し、DQM用にコピーする。\n  jsonとjarをDQM4用に書き換える。\n  Forgeの導入。\nなぜかwinrarで解凍すると一部のclassファイルが解凍できなかったので、 説明書通りに7-zipを利用して行った。\nあと、この部分は一度エラーすることが前提となっている。 エラーになった時点で色々調べてしまって、 最後には戻ってくるという無駄なことをしてしまう可能性があるので注意。\n  DQM4 modを導入する。\n  その他のmodを導入する。\n  config/DQMIV.cfgで以下を変更して、普通のインベントリ表示にする。 DQMIV専用のインベントリと何が違うかわかって、 DQMIVインベントリの表示方法のほうがよかったら元に戻す。 戻すとNotEnoughItemsが使えなくなる??\n- I:\u0026#34;プレイヤーインベントリGUIを バニラ改Ver(アクセ装備可)=2 DQMⅣVer8.0=1,DQMⅣVer9.0=0(マルチの場合、サーバーと合わせること)\u0026#34;=0\r+ I:\u0026#34;プレイヤーインベントリGUIを バニラ改Ver(アクセ装備可)=2 DQMⅣVer8.0=1,DQMⅣVer9.0=0(マルチの場合、サーバーと合わせること)\u0026#34;=2\r  modのWailaは、そのままだとONにならないので、 キーコンフィグから対応キーを探してONにする。 加えて、キーがかぶっているので、別の値にする。\n  modの一括破壊系は、以下の設定に変更した。 キー設定はすべて47として、Vに設定。 digとmineの場合は、以下のパターン。\nStartMode=false\rAutoCollect=true\rLimiter=3\rDestroyUnder=false\rKey=47\rcutは以下の設定。\nStartMode=false\rLimiter=0\rDestroyUnder=true\rDropGather=true\rKey=47\r  参考資料  Minecraft DQM IV マインクラフト 非公式日本ユーザーフォーラム: DQM IV Minecraft ドラクエMOD DQM4mod 攻略wiki Minecraft MOD DQM4 wiki ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/minecraft/minecraftdqm4/","tags":["minecraft"],"title":"Minecraft DQM IVの導入"},{"categories":null,"contents":"Jekyllでタグクラウドを作成し、一覧を表示するために調べたことのまとめ。\nやったこと  GitHub: pattex/jekyll-taggingのページを参考に、 プラグインを導入しようとしたが、Gemfileの設定がよくわからず、 以下のエラーが出て対処できなかったのであきらめた。  /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/plugin_manager.rb:29:in `require': cannot load such file -- jekyll-tagging (LoadError)\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/plugin_manager.rb:29:in `block in require_gems'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/plugin_manager.rb:26:in `each'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/plugin_manager.rb:26:in `require_gems'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/plugin_manager.rb:19:in `conscientious_require'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/site.rb:79:in `setup'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/site.rb:41:in `initialize'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/commands/build.rb:29:in `new'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/commands/build.rb:29:in `process'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/lib/jekyll/commands/build.rb:18:in `block (2 levels) in init_with_program'\rfrom /var/lib/gems/1.9.1/gems/mercenary-0.3.5/lib/mercenary/command.rb:220:in `call'\rfrom /var/lib/gems/1.9.1/gems/mercenary-0.3.5/lib/mercenary/command.rb:220:in `block in execute'\rfrom /var/lib/gems/1.9.1/gems/mercenary-0.3.5/lib/mercenary/command.rb:220:in `each'\rfrom /var/lib/gems/1.9.1/gems/mercenary-0.3.5/lib/mercenary/command.rb:220:in `execute'\rfrom /var/lib/gems/1.9.1/gems/mercenary-0.3.5/lib/mercenary/program.rb:42:in `go'\rfrom /var/lib/gems/1.9.1/gems/mercenary-0.3.5/lib/mercenary.rb:19:in `program'\rfrom /var/lib/gems/1.9.1/gems/jekyll-2.5.3/bin/jekyll:20:in `\u0026lt;top (required)\u0026gt;'\rfrom /usr/local/bin/jekyll:23:in `load'\rfrom /usr/local/bin/jekyll:23:in `\u0026lt;main\u0026gt;'\rrubyについては、まったくわからないので、 bundleの使い方は、All About: Bundlerの使い方・Gemfileの書き方を参考にしたが、 よくわからず。\n catrio: Jekyllのタグクラウドプラグインを開発するを参考にして、 タグクラウドプラグインを作って導入。  以下の3ファイル分のコードをコピーして作成\n1. tagcloud.rb\r1. tagpage.rb\r1. tag.html\r ただ、このままだとサイドバーに表示したときに、タグが単純に横に並んでしまったので、 tagcloud.rbを以下のように変更して利用している。\n- tagcloud = \u0026#34;\u0026#34;\r- tag_array.each do |tag|\r- tagcloud \u0026lt;\u0026lt; \u0026#34;\u0026lt;span\u0026gt;\u0026lt;a href=\u0026#39;#{site.baseurl}/tags/#{tag}/index.html\u0026#39;\u0026gt;#{tag}\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt;\u0026#34;\r- end\r+ tagcloud = \u0026#34;\u0026lt;ul\u0026gt;\u0026#34;\r+ tag_array.each do |tag|\r+ tagcloud \u0026lt;\u0026lt; \u0026#34;\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#39;#{site.baseurl}/tags/#{tag}/index.html\u0026#39;\u0026gt;#{tag}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\u0026#34;\r+ end\r+ tagcloud \u0026lt;\u0026lt; \u0026#34;\u0026lt;/ul\u0026gt;\u0026#34;\rあと、タグページはタイトルと日付がほしかったので、tag.htmlも以下のように変更した。\n- \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{ post.url }}\u0026#34;\u0026gt;{{ post.title }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r+ \u0026lt;li\u0026gt;{{ post.date | date:\u0026#34;%Y-%m-%d\u0026#34; }}: \u0026lt;a href=\u0026#34;{{ post.url }}\u0026#34;\u0026gt;{{ post.title }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r参考資料  catrio: Jekyllのタグクラウドプラグインを開発する GitHub: pattex/jekyll-tagging All About: Bundlerの使い方・Gemfileの書き方 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jekyll/jekylltagcloud/","tags":["jekyll"],"title":"Jekyllにタグクラウドをつける"},{"categories":null,"contents":"Jekyllで作成したデータをGitHub Pagesにpushする方法が自動化できたので、 プラグインをいくつか導入する。\nプラグインの導入方法 jekyll: プラグインによると、以下の2つの方法でインストールできるらしい。\n  _pluginsディレクトリを作成し、その下にプラグインを配置する。\n  _config.ymlファイルにgemsをキーとして、記述する。例は以下のような感じ。\n  gems: [jekyll-test-plugin, jekyll-jsonify, jekyll-assets]\rJekyllでのタグとカテゴリの書き方 てっく煮ブログ: Jekyll のカテゴリーとタグの指定方法 3 パターンさんによると、 以下の4パターンで書けるらしい。\n 単数形  category: Foo\rtag: Hoge\r  複数形(1)\n 文字列指定  categories: Foo FooFoo\rtags: Hoge HogeHoge\r 複数形配列(1)  categories:\r- Foo\r- Foo Foo\rtags:\r- Hoge\r- Hoge Hoge\r 複数形配列(2)  categories: [Foo, Foo Foo]\rtags: [Hoge, Hoge Hoge]\r  参考資料  jekyll: プラグイン てっく煮ブログ: Jekyll のカテゴリーとタグの指定方法 3 パターン ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/jekyll/jekyllplugins/","tags":["jekyll"],"title":"Jekyllにプラグンインを導入する"},{"categories":null,"contents":"Markdownで書く上で調べたことのまとめ。\ndiffを表示する Ginpen.com: Markdownでdiffを表示する。さんを参考にすると、 code defenceの先頭にdiffを書いて、各行の-と+を先頭に記述するとのこと。\n```diff\rcontinues line\r-removed line\r+added line\r参考情報  Ginpen.com: Markdownでdiffを表示する。 さかなチキンぱん。: Markdown記法チートシート(redcarpet) ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/programming/markdown/markdown/","tags":["markdown"],"title":"Markdown記法について"},{"categories":null,"contents":"GitHub PagesにそのままpushしてJekyllの変換を利用していると plugin系が使えないらしいので、 ローカルのJekyllでファイルを作成してGitHub Pagesにpushするまでのメモ。\nやったこと  masterブランチからdevelopブランチを作成  git branch -u develop;  masterブランチの中をいったんすべて削除  git rm -rf .;  developブランチでhtmlの作成  jekyll b;  masterブランチに移動して、_siteの中身を全て取り出す  この辺で、なぜか_site内以外がcheckoutされなくなって好都合だったので、そのまま進めた。 なぜそうなったのか不明。 ⇒ たぶん、_siteをignoreリストに追加したから。\ngit checkout master; cp -r _site/* ./; rm -r _site;  masterブランチをコミットしてpush  git commit -m \u0026#34;作成\u0026#34;; git push -u origin master;  ついでにdevelopブランチもGitHubにpush  git checkout develop; git commit -m \u0026#34;ソースコード\u0026#34;; git -u push origin master;  最後に毎回同じことをやるのがめんどくさいので、以下のスクリプトを作って実行  以下は、最初に作ってみたが、GitHub: akkunchoi/akkunchoi.github.comを見ると、 直下にクローンして削除したほうが早そう。\n#!/bin/bash  # developブランチでjekyllによる生成 git checkout develop; jekyll b; # 余分なファイルや必要なファイルを_site以下にコピー rm _site/createGitHubPages.sh; cp .gitignore _site/; touch _site/_nojekyll # developブランチをコミットしてプッシュする git add --all .; echo -n \u0026#34;develop branch comment: \u0026#34;; read comment; git commit -m $comment; git push origin develop -u; # masterブランチへ移動し、jekyllで生成したデータである_site以下を全て一番上にあげる git checkout master; ls | grep -v -E \u0026#39;^_site\u0026#39; | xargs rm -r; mv ./_site/* ./; mv ./_site/.* ./; rm -rf ./_site; # masterブランチ以下の変更を全て反映して、プッシュする git add --all .; echo -n \u0026#34;master branch comment: \u0026#34;; read comment; git commit -m $comment; git push origin master -u; # 最後にdevelopブランチに戻る git checkout develop; ついでにやったこと  jekyllで利用するパーサをkramdownからredcarpetに変更  参考ページ: ひげろぐ: Rubyで使えるMarkdownパーサー\n gvimで改行コードをunixに変更  このページを書いている環境がWindows7+VirtualBox+Ubuntuのため、 テキスト編集は全てgvimの改行コードがWindows系になっていたのでunix系に変更。\n参考ページ:\nサイト更新停滞ちうっ: vimエディタで「文字コード、改行コードを変更して保存する。」\nQitta: シェルスクリプトを書くときに気をつける9箇条\n参考資料  ひげろぐ: Rubyで使えるMarkdownパーサー サイト更新停滞ちうっ: vimエディタで「文字コード、改行コードを変更して保存する。」 Qitta: シェルスクリプトを書くときに気をつける9箇条 GitHub: akkunchoi/akkunchoi.github.com ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/gitpagesandjekyll/","tags":["git","github"],"title":"Jekyllでファイルを生成してGitHub Pagesにpush"},{"categories":null,"contents":"目標 とりあえず一週間位(実質初版完成まで2、3日)で、 結婚式の余興のためにアニメーションを作成する必要がある。 前回は、Adobe After Effects(?)で作成したが体験版の期間が終わったので、 利用できなくなった。 そこで、今回はBlenderのみでアニメーション作成したい。 作りたいイメージは、以下のような感じ。\n Motion graphics line performance in Japan 映画風オープニングムービー・動画制作・動画素材・タイトル動画 0019 『SMAP LIVE Opening』1991'97'98'99'00'01'02'03'05'06'08'10'12'ver  作成手順 まずはBlenderの練習 とりあえず練習のために、 日本vtr実験室さんのBlender基礎でアニメーションを作成する勉強。\n③マテリアル・テクスチャの設定より  SpecularのシェーダーはPhongだと柔らか目になる。 テクスチャマッピングの方法はPROJECT-6Bさんを参照してね。 直接色を塗る方法は、Blender操作備忘録さんを参照した。 テクスチャのサンプルは、CG Texturesさんを利用できる。\nただし、登録は必要。  途中で時間が足りないので挫折。 Blenderの大まかな雰囲気はつかめたので、 作り始めてわからないところだけGoolge先生に尋ねることにした。\nとりあえず作成 以下をつなげたような状態にしたい。\n Blenderで舞う花びらの表現 Blenderで波紋で表現するロゴ Blenderでライトバーストするロゴ２  途中で調べたことは、以下のような感じ。\n 文字の背景を透過する方法は、三流作家の雑記帳さんを参考に。 文字の押し出し方法は、code snipettsさんを参考に。 コンポジットノードの使い方は、Totto Worldさんを参考に。 背景を設定する方法は、CG PLANGETさんを参考に。  映像と音の合成  blender.jp 音声合成の方法を利用。  参考資料 HP  Blenderユーザマニュアル tomo@web\n近日中に実現したい目標 日本vtr実験室\n初心者のための!作って学ぶBlenderの基礎: ③マテリアル・テクスチャを設定する PROJECT-6B Blender操作備忘録 CG Textures blender.jp 音声合成 三流作家の雑記帳 code snipetts Totto World CG PLANGET  動画  Motion graphics line performance in Japan 映画風オープニングムービー・動画制作・動画素材・タイトル動画 0019 『SMAP LIVE Opening』1991'97'98'99'00'01'02'03'05'06'08'10'12'ver ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/software/blender_practice/","tags":["software"],"title":"Blenderの練習 000"},{"categories":null,"contents":"You are not human GistBoxに登録して色々してたら、突然Gitに人間ではありませんと言われてしまった。 原因は、GitsBoxから何度も消したり書いたりしたせいかもしれない。\nで、とりあえず解決策をGoogle先生に尋ねたところ、 やっぱりいろんな人が同じ状態になったことがあったようです。 とりあえず、最初に見つけたサイトに文章があったので、 それをコピペしてコンタクトしてみたら、半日後に解除されてました。\n以下は、最初に見つけたTOTEKANさんのサイトからコピーした内容。\n Please reinstate my profile.\nMy profile has been deactived.\nI have the following message:\nOne of our mostly harmless robots seems to think you are not a human. Because of that, it’s hidden your profile from the public. If you really are human, please contact support to have your profile reinstated. We promise we won’t require DNA proof of your humanity.\nPlease reinstate my profile.\n 適当に訳すと、\n アカウントが無効化されたから直してほしいです。\n表示されたメッセージは、以下です。\n という感じでしょうか?\n参考資料  TOTEKAN ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/git/","tags":["git"],"title":"Gitでyou are not humanと言われたら"},{"categories":null,"contents":"後で調べる  簡単な検索できない?  Googleカスタム検索?\n⇒TOPのindex.htmlのみは検索に成功。それ以外ができない…。   ページの作成日だけでなく、更新日を自動でつけられない? postした別のメモへのリンクは貼れないの?\n⇒サイトの構成さえ知っていれば付けれなくはないが、どっかで置換したほうが確実な気がする。 タグのところに記事の件数を追加できない? 引用の文字が巨大すぎるんだけど直せないか? 文章書くなら字下げがないと体裁が変な気がする。  調べ終わった  タグ付で管理できない? ⇒ できた! ページネーションの追加 コードのシンタックスハイライトは? ⇒一応できてるっぽいので終わり。若干気に入らないがそれは、全体のテーマもだから後回し。  参考資料  WYSAWYG\nレイアウト(default.htmlとpost.html)を参考にしました。 Jekyllいつやるの？ジキやルの？今でしょ！\n全般に参考になります。 まだ後半の部分が理解できてないので、あとで読む予定です。 akkunchoi.github.com\n一番最初の構築で利用しました。 unity-yb/unity-yb.github.com\nディレクトリ構成などの参考に利用しました。 ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/softwaretool/git/gitpages/","tags":["git"],"title":"Git Pagesを使ってMarkdownでメモする環境構築"},{"categories":null,"contents":"","date":"0001-01-01T00:00:00Z","href":"https://iimuz.github.io/scrapbook/_footer/","tags":null,"title":""},{"categories":null,"contents":"          ","date":"2020-01-02T14:39:52Z","href":"https://iimuz.github.io/scrapbook/search/","tags":null,"title":"search"}]