<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Books on しさく</title><link>https://iimuz.github.io/scrapbook/book/</link><description>Recent content in Books on しさく</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sun, 16 Aug 2020 16:27:05 +0000</lastBuildDate><atom:link href="https://iimuz.github.io/scrapbook/book/index.xml" rel="self" type="application/rss+xml"/><item><title>Pythonによるベイズ統計学入門</title><link>https://iimuz.github.io/scrapbook/book/python_for_bayes/</link><pubDate>Sun, 16 Aug 2020 16:27:05 +0000</pubDate><guid>https://iimuz.github.io/scrapbook/book/python_for_bayes/</guid><description>朝倉書店 著者: 中妻照雄 初版の発行年月日: 2019.4.20 公式 GitHub nakatsuma/python_for_bayes Memo PyMC を利用してベイズ統計の基本的なモデルの実装などを紹介しています。 残念ながら、PyMC のバージョンが 3 系?のようなので、少々現在の状況だと使いにくく見えます。 PyMC4 になると tensorflow probability がバックエンドになるようです。
数式の展開に関して、補足資料がしっかりしているので、比較的数式展開が追いやすいように思います。</description></item><item><title>仕事で始める機械学習</title><link>https://iimuz.github.io/scrapbook/book/machine_learning_at_work/</link><pubDate>Sun, 16 Aug 2020 15:27:48 +0000</pubDate><guid>https://iimuz.github.io/scrapbook/book/machine_learning_at_work/</guid><description>O&amp;rsquo;REILLY 著者: 有賀 康顕 , 中山 心太,西林 孝、 出版: オライリージャパン 公式のノートブック メモ 1 章から 5 章までの間は、機械学習の基本的な事柄がまとめられているように思います。 機械学習プロジェクトを動かすためには、下記の人材が必要であるという風に書かれています。 このような人材をきちんと集められることは非常に幸運なことだと思います。
プロダクトに関するドメイン知識を持った人 統計や機械学習に明るい人 データ分析基盤を作れるエンジニアリング能力のある人 失敗してもかまわないとリスクをとってくれる責任者 6 章からは一部でコードの紹介も含めて書かれており、実際にどう作っていくかが分かって面白いです。 効果検証などマーケティング系では必要なのだろうと思うことが書かれています。 この本では、基本的にマーケティングや Web 系のログからのクリック系などがベースにあるようです。</description></item><item><title>ベイズ推論による機械学習入門</title><link>https://iimuz.github.io/scrapbook/book/introduction_to_machine_learning_by_bayesian_inference/</link><pubDate>Mon, 10 Aug 2020 16:52:17 +0000</pubDate><guid>https://iimuz.github.io/scrapbook/book/introduction_to_machine_learning_by_bayesian_inference/</guid><description> 講談社サイエンティフィック 著者: 須山敦志 発行日: 2017.10.20 メモ ベイズ深層学習 と同一の著者です。 ベイズ学習におけるモデルの構築と推論は下記のステップで行う。 モデルの構築: 観測データ $D$ と観測されていない未知の変数 $\bm{X}$ の同時確率 $P(D, \bm{X})$ を構築する。 推論の導出: 事後分布 $P(\bm{X}|D) = \frac{p(D, \bm{X})}{p(D)}$ を解析的あるいは近似で求める。 3.2 節で、離散確率分布の学習と予測ということで、 尤度と事前分布に共役分布を定義した場合の事後分布の導出を丁寧に説明しています。 ベルヌーイ分布から始まり、ポワソン分布まで書かれています。 ここでの例では、解析的に解が求まるため計算を追うと理解しやすいです。 予測分布における積分除去は、基本的に事前分布の正規化項に一致するため、 積分自体をする必要がなく、計算が楽です。</description></item><item><title>機械学習のための確率と統計</title><link>https://iimuz.github.io/scrapbook/book/probability_and_statistics_for_machine_learning/</link><pubDate>Mon, 10 Aug 2020 16:22:17 +0000</pubDate><guid>https://iimuz.github.io/scrapbook/book/probability_and_statistics_for_machine_learning/</guid><description>講談社サイエンティフィック 著者: 杉山将 発行日: 2015.4.7 メモ 基本的な確率と統計手法に関して説明されています。 どちらかというと、この本自体で学ぶというよりも、この本は辞書的に利用する感じが良さそうです。 導出などがきちんと書かれているので、他の本を読んでいて分からない展開が出てきたときに、 参考にすると非常に分かりやすくなるのではないかと思います。</description></item><item><title>ベイズ深層学習</title><link>https://iimuz.github.io/scrapbook/book/bayesian_deep_learning/</link><pubDate>Sun, 09 Aug 2020 15:41:13 +0000</pubDate><guid>https://iimuz.github.io/scrapbook/book/bayesian_deep_learning/</guid><description> ベイズ深層学習 発行: 2019.8.9 著者: 須山敦志 作って遊ぶ機械学習。: 著者のブログです。 GitHub sammy-suyama: 著者の GitHub リポジトリです。 メモ 基本的なベイズの概念から始まり、ベイズ深層学習まで解説してあります。 最終的には深層学習とガウス過程の関係に関する説明までたどり着きます。
非常に参考文献も多く、読みやすいです。 ただ、内容が難しく、数式を自力展開して追うところまではたどり着けていません。 また、実装などが掲載されているわけではないため、実装部分に関しては別途調査が必要です。
参考資料 2020.1.15 『ベイズ深層学習』が最高すぎた: ベイズ深層学習が良かったよという記事です。 GitHub tok41/try_bayesian_nn: 本の内容を実装してみた例です。</description></item><item><title>Hamiltonian Monte Carlo</title><link>https://iimuz.github.io/scrapbook/book/hamiltonian_monte_carlo/</link><pubDate>Thu, 30 Jan 2020 00:34:45 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/hamiltonian_monte_carlo/</guid><description> Wikipedia Hamiltonian Monte Carlo Metropolis Hastings Algorithm の改良版。</description></item><item><title>データ解析のための統計モデリング入門</title><link>https://iimuz.github.io/scrapbook/book/statistics_modeling_tutorial_for_data_analysis/</link><pubDate>Tue, 28 Jan 2020 21:34:35 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/statistics_modeling_tutorial_for_data_analysis/</guid><description> 岩波書店 著者: 久保 拓弥 刊行日: 2012.5.18 ISBN: 9784000069731 参考資料 本に記載の URL には既にアクセスできないため、関係していそうなリンクです。 GitHub [aviatesk/intro-statistical-modeling] R コードの参考用。</description></item><item><title>Python 実践データ分析 100 本ノック</title><link>https://iimuz.github.io/scrapbook/book/data_analysis_100_knock/</link><pubDate>Sun, 12 Jan 2020 14:22:33 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/data_analysis_100_knock/</guid><description>出版社: [秀和システム] 著者: 下山輝昌, 松田雄馬, 三木孝行 発行: 2019.9.27 ISBN: 9784798058757 自然言語処理100本ノックのWeb解析版のような感じです。 前処理とかが中心に書かれています。</description></item><item><title>機械学習しませんか</title><link>https://iimuz.github.io/scrapbook/book/play_machine_learning/</link><pubDate>Sun, 12 Jan 2020 14:15:14 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/play_machine_learning/</guid><description>出版社: ソシム 著者: 坂本 俊之, 片野 美都, クジラ飛行机 発行: 2019.12.17 ISBN-13: 978-4802611633 最初の導入としては良いのかもしれません。 中身としては導入部分だけなので、参考になるような部分はほとんどありませんでした。 あと、コーディング規約があまり揃っていないように見えるので、残念でした。 エンコーディング指定が一部のコードに入っていますが、PEP8 で非推奨のような気がします。</description></item><item><title>Kaggle で勝つデータ分析の技術</title><link>https://iimuz.github.io/scrapbook/book/win_at_kaggle/</link><pubDate>Sat, 11 Jan 2020 10:40:32 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/win_at_kaggle/</guid><description>技術評論社 出版: 技術評論社 著者: 門脇 大輔, 阪田 隆司, 保坂 桂佑, 平松 雄司 発行: 2019.10.9 Amazon GitHub ghmagazine/kagglebook: 公式のサンプルコードです。 評判の良い本です。
メモ 時系列データ分析で、幾つか参考になりそうなコンペ情報が載っていたのでメモしておきます。 来客数の将来予測: recruite restaurant visitor forecasting 金融市場の将来の変数の予測: two sigma financial modeling challenge 評価指標 Matthews Correlation Coefficient (MCC): 不均衡データに対してモデルの適性を適切に評価しやすい quadratic weighted kappa: マルチクラス分類でクラス間に順序関係がある場合に利用可能。(例えば、映画のレーティングなど) 特徴量の変換手法として下記が載っていました。 Box-cox 変換、 Jeo-Jonson 変換: Jeo-Jonson 変換の方は、 Box-Cox 変換で、さらに負の値を考慮した場合の変換となるようです。 RankGauss: 数値返還を順序に変換した後に、順序を保ったまま正規分布に近づける方法です。 sklearn の quontiletransfer を利用して n_quontiles を大きくし(例えば 100 とか)、distribution に normal を指定するようです。 仮に、元の分布が多峰性であっても、正規分布に近い形になるとのことです。 テーブルデータに対する多層パーセプトロンの参考ソリューション GitHub dkivaranovic/kaggledays-recruit: Recruit Restaurant Visitor Forecasting の 5 位ソリューション。 LightGBM なども掲載されていますが、 Keras を利用した全結合層タイプのネットワークが掲載されています。 KaggleNotebook shixw125: 1st Place NN Model(public:0.</description></item><item><title>アンチ整理術</title><link>https://iimuz.github.io/scrapbook/book/anti_clearaning/</link><pubDate>Sun, 05 Jan 2020 19:10:45 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/anti_clearaning/</guid><description>Amazon: アンチ整理術 出版: 日本実業出版社 著者: 森博嗣 発行: 2019.11.10 整理しないという整理術のようです。</description></item><item><title>RとStanではじめる ベイズ統計モデリングによるデータ分析入門</title><link>https://iimuz.github.io/scrapbook/book/bayes_modeling_using_r_stand/</link><pubDate>Sun, 05 Jan 2020 19:03:03 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/bayes_modeling_using_r_stand/</guid><description>講談社: R と Stan ではじめる ベイズ統計モデリングによるデータ分析入門 発行: 2019.7.8 著者: 馬場真哉 ISBN: 978-4-06-516536-2 一通り読了しました。 書かれている内容は限定的ですが、であるからこそ非常に分かりやすく読みやすい本でした。 学生の時に、この本があればもっと理解して色々な研究が出来たのになぁと感じます。
参考資料 Logics of blue: 著者のホームページ R と Stan ではじめる　ベイズ統計モデリングによるデータ分析入門：サポートページ R のインストール方法やベイズ統計や Stan プログラミングの参考資料も記載されています。 GitHub logics-of-blue/book-r-stan-bayesian-model-intro 著者によるリポジトリです。 書籍中で利用しているデータやコードが管理されています。 2019.8.13 『R と Stan ではじめるベイズ統計モデリングによるデータ分析入門』は「みどりぼん」に取って替わる次世代の統計モデリング＋ベイジアン入門書 メモ 第一部 MCMC モンテカルロ法: ランダムな値を生成する方法 Metropolis Hastings Algorithm (MH algorithm): ランダムに取得した値が前回の値よりもカーネル比の値が高い場合に採用するプロセスを繰り返す。 Hamiltonian Monte Carlo Method (HMC method): MH method の改良版。 モンテカルロ積分: パラメータの期待値を求めるためには、事後確率密度関数とパラメータの積分が必要になる。 計算できないので、ランダム生成した値の期待値で代用する。 誤差は発生するが、実用上問題ない。 定常分布: 状態遷移が安定して、変化しなくなった確率分布 マルコフ連鎖: 時系列において 1 つ前までの状態を考慮する。 繰り返し数(iter): 乱数の生成個数であり、 Stan においては 2000 の設定が多い。 バーンイン期間 (warmup): 初期値依存を軽減するために、乱数生成の初期区間を切り捨てる。 間引き(thin): 乱数生成において直前の値を参照するため乱数の自己相関を緩和するための方法。 thin=2 とすると、乱数を 2 回に 1 回だけ採用する。 チェーン(chains): 収束判定を行う 1 セットを指す。chains=4の設定が多い。 iter=2000, warmpup=1000 の場合は、1chain で 1000 個の乱数、4chains で 4000 個の乱数となる。 収束判定: 下記の指標の比により求めることが多い。例えば、下記の比が 1.</description></item><item><title>scikit-learnとTensorFlowによる実践機械学習</title><link>https://iimuz.github.io/scrapbook/book/machine_learning_using_scikit_learn_and_tensorflow/</link><pubDate>Sun, 05 Jan 2020 18:57:51 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/machine_learning_using_scikit_learn_and_tensorflow/</guid><description> オライリー: scikit-learnとTensorFlowによる実践機械学習 発行: 2018.4 著者: Aurélien Géron 監訳: 下田 倫大 訳: 長尾 高弘 ISBN: 978-4-87311-834-5</description></item><item><title>はじめてのパターン認識</title><link>https://iimuz.github.io/scrapbook/book/start_pattern_recognition/</link><pubDate>Sun, 05 Jan 2020 18:54:14 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/start_pattern_recognition/</guid><description> 森北出版株式会社: はじめてのパターン認識 発行: 2012.7 著者: 平井 有三 ISBN: 978-4-627-84971-6</description></item><item><title>Rによるやさしい統計学 Rの操作手順と統計学の基礎が身に付く！</title><link>https://iimuz.github.io/scrapbook/book/kindness_statistics_using_r/</link><pubDate>Sun, 05 Jan 2020 18:50:07 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/kindness_statistics_using_r/</guid><description> オーム社: Rによるやさしい統計学 Rの操作手順と統計学の基礎が身に付く！ 発行: 2018.1 著者: 山田 剛史, 杉澤 武俊, 村井 潤一郎 ISBN: 978-4-274-06710-5</description></item><item><title>Rによるデータサイエンス(第2版) データ解析の基礎から最新手法まで</title><link>https://iimuz.github.io/scrapbook/book/datascience_using_r/</link><pubDate>Sun, 05 Jan 2020 18:44:32 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/datascience_using_r/</guid><description> 森北出版 Rによるデータサイエンス(第2版) データ解析の基礎から最新手法まで 発行: 2017.3 著者: 金 明哲 ISBN: 978-4-627-09602-8</description></item><item><title>手を動かしながら学ぶ ビジネスに活かすデータマイニング</title><link>https://iimuz.github.io/scrapbook/book/handmade_learning_datamining_for_business/</link><pubDate>Sun, 05 Jan 2020 18:39:38 +0900</pubDate><guid>https://iimuz.github.io/scrapbook/book/handmade_learning_datamining_for_business/</guid><description> 技術評論社 手を動かしながら学ぶ　ビジネスに活かすデータマイニング 発売: 2014.8.22 著者: 尾崎隆 ISBN: ISBN 978-4-7741-6674-2</description></item></channel></rss>