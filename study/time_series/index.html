<!doctype html><html lang=en><head><title>Time series | しさく</title><meta charset=utf-8><meta name=generator content="Hugo 0.60.1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv=x-ua-compatible content="IE=edge"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Time Series"><meta name=description content="Wikipedia: 時系列  参考資料 Everything you can do with a time series  Kaggle Kernel: Everything you can do with a time series  時系列データ(特に、株価チャート)を中心としてチュートリアルを作成している。 ろ …"><meta property="og:description" content="Wikipedia: 時系列  参考資料 Everything you can do with a time series  Kaggle Kernel: Everything you can do with a time series  時系列データ(特に、株価チャート)を中心としてチュートリアルを作成している。 ろ …"><meta property="og:url" content="https://iimuz.github.io/scrapbook/study/time_series/"><meta property="og:image" content="images/%!s()"><meta name=twitter:card content="summary_large_image"><meta name=twitter:creator content><meta name=twitter:title content="Time Series"><meta property="twitter:description" content="Wikipedia: 時系列  参考資料 Everything you can do with a time series  Kaggle Kernel: Everything you can do with a time series  時系列データ(特に、株価チャート)を中心としてチュートリアルを作成している。 ろ …"><meta name=twitter:image content="images/%!s()"><link rel=apple-touch-icon sizes=180x180 href=https://iimuz.github.io/scrapbook/images/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://iimuz.github.io/scrapbook/images/icons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://iimuz.github.io/scrapbook/images/icons/favicon-16x16.png><link rel=manifest href=https://iimuz.github.io/scrapbook/images/icons/site.webmanifest><link rel=canonical href=https://iimuz.github.io/scrapbook/study/time_series/><link rel=stylesheet href=https://iimuz.github.io/scrapbook/css/styles.a1e1a9f0e58a84cfca79c98c11b9e900971b61f840c5fbe7f3ddad8ebcd9798517a0ea30089562091e9105239ce941ccc4953d8c3a0c08a2f5082ace791f0186.css integrity="sha512-oeGp8OWKhM/KecmMEbnpAJcbYfhAxfvn892tjrzZeYUXoOowCJViCR6RBSOc6UHMxJU9jDoMCKL1CCrOeR8Bhg=="><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.2/css/all.min.css></head><body><div class=nav-drop><div class=nav-body><a href=https://iimuz.github.io/scrapbook/search/ class=nav_item>search</a>
<a href=https://iimuz.github.io/scrapbook/tags/ class=nav_item>tags</a>
<a href=https://iimuz.github.io/scrapbook/categories/ class=nav_item>categories</a>
<a href=https://github.com/iimuz/til/ class=nav_item>til</a><div class=nav-close></div></div></div><header class=nav><nav class=nav-menu><a href=https://iimuz.github.io/scrapbook/ class="nav-brand nav_item">しさく</a><div class=nav_bar-wrap><div class=nav_bar></div></div></nav></header><main><section class=post_header style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)><h1 class=post_title>Time Series</h1></section><div class=post><article class=post_content><div><i class="far fa-calendar-check"></i>2020-01-05 15:12:41 +0900 +0900
<i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div><ul><li>Wikipedia: <a href=https://ja.wikipedia.org/wiki/%E6%99%82%E7%B3%BB%E5%88%97>時系列</a></li></ul><h2 id=heading>参考資料</h2><h3 id=everything-you-can-do-with-a-time-series>Everything you can do with a time series</h3><ul><li>Kaggle Kernel: <a href=https://www.kaggle.com/thebrownviking20/everything-you-can-do-with-a-time-series>Everything you can do with a time series</a></li></ul><p>時系列データ(特に、株価チャート)を中心としてチュートリアルを作成している。
ろうそく足チャートとかの説明もある。
ARMA モデルに始まり、SARIMA などの紹介もしている。</p><h3 id=time-series-basics-exploring-traditional-ts>Time series Basics: Exploring traditional TS</h3><ul><li>Kaggle Kernel: <a href=https://www.kaggle.com/jiegzhan/time-series-basics-exploring-traditional-ts>Time series Basics: Exploring traditional TS</a></li></ul><p>時系列単変量データの解析が中心のようです。ARMA モデルや ARIMA モデル、SARIMA に関して記載しています。
時系列多変量データに関しても商品データ(ショップ毎、アイテムごと)を利用して説明しています。
ただし、予測自体は単変量とほぼ変わらないようです。
欠損値の取り扱いなどに関しても記載されていないです。</p><h3 id=2018923--variational-autoencoder-keras>2018.9.23 時系列データで Variational AutoEncoder keras</h3><ul><li>学習する天然ニューラルネット</li><li><a href=https://aotamasaki.hatenablog.com/entry/2018/09/23/124152>時系列データで Variational AutoEncoder keras</a></li></ul><p>Autoencoder に RNN を適用して時系列用にした例</p><h3 id=20191018-attention-for-time-series-forecasting-and-classification>2019.10.18 Attention for time series forecasting and classification</h3><ul><li>towards data science</li><li><a href=https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d>Attention for time series forecasting and classification</a></li></ul><p>Attention を利用した時系列データでの分類と予測方法に関していくつかの文献を提示しています。</p><ul><li><a href=/scrapbook/study/modeling_long_and_short_term_temporal_patterns_with_deep_neural_networks/>Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks</a><ul><li>多変量の LSTM + Attention を利用した時系列予測の手法。</li></ul></li><li><a href=/scrapbook/study/temporal_pattern_attention_for_multivariate_time_series_forecasting/>Temporal Pattern Attention for Multivariate Time Series Forecasting</a><ul><li>多変量データに対して Attention を適用する方法。</li></ul></li><li><a href=/scrapbook/study/are_sixteen_heads_really_better_than_one/>Are Sixteen Heads Really Better than One?</a><ul><li>Multi-headed attention の有効性検証の論文。</li></ul></li><li><a href=/scrapbook/study/pay_less_attention_with_lightweight_and_dynamic_convolutions/>Pay Less Attention with Lightweight and Dynamic Convolutions</a><ul><li>Self-Attention の代替として Dynamic Convolution という高速な方法を提案している。</li></ul></li><li>GitHub huseinzol05 <a href=https://github.com/huseinzol05/Stock-Prediction-Models/blob/master/deep-learning/16.attention-is-all-you-need.ipynb>Stock-Prediction-Models/deep-learning/16.attention-is-all-you-need.ipynb</a><ul><li>ナイーブに Attention を時系列予測に利用している例です。</li></ul></li><li><a href=/scrapbook/study/attend_and_diagnose_clinical_time_series_analysis_using_attention_models/>Attend and Diagnose: Clinical Time Series Analysis using Attention Models</a><ul><li>Self-Attention を時系列問題に適用している例です。</li></ul></li><li><a href=/scrapbook/study/cdsa_cross_dimensional_self_attention_for_multivariate_geo_tagged_time_series_imputation/>CDSA: Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time Series Imputation</a><ul><li>時間、位置、センサデータの 3 つを利用して復元、予測するタスクに対して、
Cross Dimensional Self Attetion を提案している。</li></ul></li><li><a href=/scrapbook/study/enhancing_the_locality_and_breaking_the_memory_bottleneck_of_transofrmer_on_time_series_forecasting/>Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting</a><ul><li>Transformer を時系列データに適用し、メモリ効率などを向上している。</li></ul></li></ul><h3 id=heading1>その他</h3><ul><li>2018.9.4 Good Audience <a href=https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf>Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences</a></li><li>Tensorflow Tutorials: <a href=https://www.tensorflow.org/tutorials/structured_data/time_series#multi-step_model>Time series forecasting: Multi-Step model</a></li><li>2016.7.21 <a href=https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/>Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a></li></ul><div class=post_extra><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div></article><aside><h3>Referenced from</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/enhancing_the_locality_and_breaking_the_memory_bottleneck_of_transofrmer_on_time_series_forecasting/ title="Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/enhancing_the_locality_and_breaking_the_memory_bottleneck_of_transofrmer_on_time_series_forecasting/>Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/cdsa_cross_dimensional_self_attention_for_multivariate_geo_tagged_time_series_imputation/ title="CDSA: Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time Series Imputation" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/cdsa_cross_dimensional_self_attention_for_multivariate_geo_tagged_time_series_imputation/>CDSA: Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time Series Imputation</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/attend_and_diagnose_clinical_time_series_analysis_using_attention_models/ title="Attend and Diagnose: Clinical Time Series Analysis using Attention Models" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/attend_and_diagnose_clinical_time_series_analysis_using_attention_models/>Attend and Diagnose: Clinical Time Series Analysis using Attention Models</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/pay_less_attention_with_lightweight_and_dynamic_convolutions/ title="Pay Less Attention with Lightweight and Dynamic Convolutions" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/pay_less_attention_with_lightweight_and_dynamic_convolutions/>Pay Less Attention with Lightweight and Dynamic Convolutions</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/self_attention_with_functional_time_representation_learning/ title="Self-attention with Functional Time Representation Learning" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/self_attention_with_functional_time_representation_learning/>Self-attention with Functional Time Representation Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/temporal_pattern_attention_for_multivariate_time_series_forecasting/ title="Temporal Pattern Attention for Multivariate Time Series Forecasting" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/temporal_pattern_attention_for_multivariate_time_series_forecasting/>Temporal Pattern Attention for Multivariate Time Series Forecasting</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/modeling_long_and_short_term_temporal_patterns_with_deep_neural_networks/ title="Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/modeling_long_and_short_term_temporal_patterns_with_deep_neural_networks/>Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/time_series_anomaly_detection_prediction/ title="Time Series Anomaly Detection / Prediction" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/time_series_anomaly_detection_prediction/>Time Series Anomaly Detection / Prediction</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/matrix_profile/ title="Matrix Profile" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/matrix_profile/>Matrix Profile</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/a_closer_look_at_spatiotemporal_convolutions_for_action_recognition/ title="A Closer Look at Spatiotemporal Convolutions for Action Recognition" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/a_closer_look_at_spatiotemporal_convolutions_for_action_recognition/>A Closer Look at Spatiotemporal Convolutions for Action Recognition</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/ title="Learning Spatiotemporal Features with 3D Convolutional Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/>Learning Spatiotemporal Features with 3D Convolutional Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li></ul><h3>More from しさく</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/iccv/ title="International Conference on Computer Vision" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/iccv/>International Conference on Computer Vision</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/ title="Learning Spatiotemporal Features with 3D Convolutional Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/>Learning Spatiotemporal Features with 3D Convolutional Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/metric_learning/ title="Metric Learning" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/metric_learning/>Metric Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/joint_descriminative_and_generative_leanring_for_person_reidentification/ title="Joint Discriminative and Generative Learning for Person Re-identification" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/joint_descriminative_and_generative_leanring_for_person_reidentification/>Joint Discriminative and Generative Learning for Person Re-identification</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/tiny_video_networks/ title="Tiny Video Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/tiny_video_networks/>Tiny Video Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-30 21:19:21 +0900 +0900</div></div></div></li></ul></aside></div><script src=https://iimuz.github.io/scrapbook/js/autosize.min.js></script><script src=https://iimuz.github.io/scrapbook/js/timeago.js></script></main><svg width="0" height="0" class="hidden"><symbol viewBox="0 0 699.428 699.428" xmlns="http://www.w3.org/2000/svg" id="copy"><path d="M502.714.0H240.428C194.178.0 153 42.425 153 87.429l-25.267.59c-46.228.0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249.0 87.428-42.424 87.428-87.428h21.857c46.25.0 87.429-42.424 87.429-87.428v-349.19zM459 655.715H131.143c-22.95.0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95.0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337.0 87.975.0 87.975.0 45.419 40.872 86.882 87.428 86.882H612zm-65.572-349.715c-23.277.0-43.714-42.293-43.714-64.981V44.348L612 174.857zm-43.714 131.537H306c-12.065.0-21.857 9.77-21.857 21.835s9.792 21.835 21.857 21.835h196.714c12.065.0 21.857-9.771 21.857-21.835.0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065.0-21.857 9.77-21.857 21.834.0 12.066 9.792 21.836 21.857 21.836h196.714c12.065.0 21.857-9.77 21.857-21.836.0-12.064-9.792-21.834-21.857-21.834z"/></symbol><symbol viewBox="0 0 60.015 60.015" xmlns="http://www.w3.org/2000/svg" id="reply"><path d="M42.007.0h-24c-9.925.0-18 8.075-18 18v14c0 9.59 7.538 17.452 17 17.973v8.344a1.694 1.694.0 001.699 1.698c.44.0.873-.173 1.198-.498l1.876-1.876C26.708 52.713 33.259 50 40.227 50h1.78c9.925.0 18-8.075 18-18V18c0-9.925-8.075-18-18-18zm16 32c0 8.822-7.178 16-16 16h-1.78c-7.502.0-14.556 2.921-19.86 8.226l-1.359 1.359V44a1 1 0 10-2 0v3.949c-8.356-.52-15-7.465-15-15.949V18c0-8.822 7.178-16 16-16h24c8.822.0 16 7.178 16 16v14z"/></symbol></svg><footer class=footer><div class="footer_inner wrap pale"><p>&copy; <span class=year></span>しさく</p><p>Designed by <a href="<no value>" title="Linkedin Profile"><no value></a></p></div></footer><script src=https://iimuz.github.io/scrapbook/js/index.js></script></body></html>