<!doctype html><html lang=en><head><title>Joint discriminative and generative learning for person re identification | しさく</title><meta charset=utf-8><meta name=generator content="Hugo 0.60.1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv=x-ua-compatible content="IE=edge"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Joint Discriminative and Generative Learning for Person Re-identification"><meta name=description content="arXiv 投稿日: 2019.4.15 著者: Zhedong Zheng, Xiaodong Yang, Zhiding Yu, Liang Zheng, Yi Yang, Jan Kautz  NVIDIA から CVPR2019 の Oral セッションで発表された論文です。 GAN と Metric …"><meta property="og:description" content="arXiv 投稿日: 2019.4.15 著者: Zhedong Zheng, Xiaodong Yang, Zhiding Yu, Liang Zheng, Yi Yang, Jan Kautz  NVIDIA から CVPR2019 の Oral セッションで発表された論文です。 GAN と Metric …"><meta property="og:url" content="https://iimuz.github.io/scrapbook/study/joint_descriminative_and_generative_leanring_for_person_reidentification/"><meta property="og:image" content="images/%!s()"><meta name=twitter:card content="summary_large_image"><meta name=twitter:creator content><meta name=twitter:title content="Joint Discriminative and Generative Learning for Person Re-identification"><meta property="twitter:description" content="arXiv 投稿日: 2019.4.15 著者: Zhedong Zheng, Xiaodong Yang, Zhiding Yu, Liang Zheng, Yi Yang, Jan Kautz  NVIDIA から CVPR2019 の Oral セッションで発表された論文です。 GAN と Metric …"><meta name=twitter:image content="images/%!s()"><link rel=apple-touch-icon sizes=180x180 href=https://iimuz.github.io/scrapbook/images/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://iimuz.github.io/scrapbook/images/icons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://iimuz.github.io/scrapbook/images/icons/favicon-16x16.png><link rel=manifest href=https://iimuz.github.io/scrapbook/images/icons/site.webmanifest><link rel=canonical href=https://iimuz.github.io/scrapbook/study/joint_descriminative_and_generative_leanring_for_person_reidentification/><link rel=stylesheet href=https://iimuz.github.io/scrapbook/css/styles.a1e1a9f0e58a84cfca79c98c11b9e900971b61f840c5fbe7f3ddad8ebcd9798517a0ea30089562091e9105239ce941ccc4953d8c3a0c08a2f5082ace791f0186.css integrity="sha512-oeGp8OWKhM/KecmMEbnpAJcbYfhAxfvn892tjrzZeYUXoOowCJViCR6RBSOc6UHMxJU9jDoMCKL1CCrOeR8Bhg=="><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.2/css/all.min.css></head><body><div class=nav-drop><div class=nav-body><a href=https://iimuz.github.io/scrapbook/search/ class=nav_item>search</a>
<a href=https://iimuz.github.io/scrapbook/tags/ class=nav_item>tags</a>
<a href=https://iimuz.github.io/scrapbook/categories/ class=nav_item>categories</a>
<a href=https://github.com/iimuz/til/ class=nav_item>til</a><div class=nav-close></div></div></div><header class=nav><nav class=nav-menu><a href=https://iimuz.github.io/scrapbook/ class="nav-brand nav_item">しさく</a><div class=nav_bar-wrap><div class=nav_bar></div></div></nav></header><main><section class=post_header style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)><h1 class=post_title>Joint Discriminative and Generative Learning for Person Re-identification</h1></section><div class=post><article class=post_content><div><i class="far fa-calendar-check"></i>2020-01-05 12:41:36 +0900 +0900
<i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div><ul><li><a href=https://arxiv.org/abs/1904.07223>arXiv</a></li><li>投稿日: 2019.4.15</li><li>著者: Zhedong Zheng, Xiaodong Yang, Zhiding Yu, Liang Zheng, Yi Yang, Jan Kautz</li></ul><p>NVIDIA から CVPR2019 の Oral セッションで発表された論文です。
GAN と Metric Learning を組み合わせて人物の識別精度を向上しています。</p><h2 id=heading>参考文献</h2><h3 id=person-reidentification--joint-discriminative-and-generative-learning-for-perosn-reidentification->Person Re-identification 論文解説 Joint Discriminative and Generative Learning for Perosn Re-identification を読む</h3><ul><li><a href=https://qiita.com/pacifinapacific/items/5d1ba06591d6d41c6b5d>Qiita: Person Re-identification 論文解説 Joint Discriminative and Generative Learning for Perosn Re-identification を読む</a></li><li>投稿日: 2019.11.6</li></ul><div class=post_extra><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div></article><aside><h3>Referenced from</h3><ul class="posts aside"></ul><h3>arXiv.org</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/arxiv/ title=arXiv.org style=background-image:url(https://upload.wikimedia.org/wikipedia/commons/a/a8/ArXiv_web.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/arxiv/>arXiv.org</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul><h3>Computer Vision</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/computer_vision/ title="Computer Vision" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/computer_vision/>Computer Vision</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/ title="Learning Spatiotemporal Features with 3D Convolutional Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/>Learning Spatiotemporal Features with 3D Convolutional Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/tiny_video_networks/ title="Tiny Video Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/tiny_video_networks/>Tiny Video Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/crpr/ title="Conference on Computer Vision and Pattern Recognition (CVPR)" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/crpr/>Conference on Computer Vision and Pattern Recognition (CVPR)</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/deep_afinity_network_for_multiple_object_tracking/ title="Deep Affinity Network for Multiple Object Tracking" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_afinity_network_for_multiple_object_tracking/>Deep Affinity Network for Multiple Object Tracking</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/software/image_processing/ title=画像処理 style=background-image:url(https://cdn.pixabay.com/photo/2014/04/05/11/19/internet-315132_1280.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/software class=post_tag>software</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/software/image_processing/>画像処理</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/counterfactual_visual_explanations/ title="Counterfactual Visual Explanations" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/counterfactual_visual_explanations/>Counterfactual Visual Explanations</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/noise2noise_learning_image_restoration_without_clean_data/ title="Noise2Noise: Learning Image Restoration without Clean Data" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/noise2noise_learning_image_restoration_without_clean_data/>Noise2Noise: Learning Image Restoration without Clean Data</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul><h3>CVPR 2019</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/cvpr2019/ title="CVPR 2019" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/cvpr2019/>CVPR 2019</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/crpr/ title="Conference on Computer Vision and Pattern Recognition (CVPR)" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/crpr/>Conference on Computer Vision and Pattern Recognition (CVPR)</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/ title="Learning Spatiotemporal Features with 3D Convolutional Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/>Learning Spatiotemporal Features with 3D Convolutional Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/a_closer_look_at_spatiotemporal_convolutions_for_action_recognition/ title="A Closer Look at Spatiotemporal Convolutions for Action Recognition" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/a_closer_look_at_spatiotemporal_convolutions_for_action_recognition/>A Closer Look at Spatiotemporal Convolutions for Action Recognition</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul><h3>Deep Learning</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/deep_learning/ title="Deep Learning" style=background-image:url(https://cdn.pixabay.com/photo/2018/11/15/00/56/neural-network-3816319_960_720.png)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_learning/>Deep Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/efficientnet_rethinking_model_scaling_for_convolutional_neural_networks/ title="EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/efficientnet_rethinking_model_scaling_for_convolutional_neural_networks/>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/forecasting_remaining_useful_life_interpretable_deep_leanring_approach_via_variational_bayesian_inferences/ title="Forecasting remaining useful life: Interpretable deep learning approach via variational Bayesian inferences" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/forecasting_remaining_useful_life_interpretable_deep_leanring_approach_via_variational_bayesian_inferences/>Forecasting remaining useful life: Interpretable deep learning approach via variational Bayesian inferences</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/explainable_artificial_intelligence_xai_concepts_taxonomies_opportunities_and_challenges_toward_responsible_ai/ title="Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/explainable_artificial_intelligence_xai_concepts_taxonomies_opportunities_and_challenges_toward_responsible_ai/>Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/modern_neural_networks_generalize_on_small_data_sets/ title="Modern Neural Networks Generalize on Small Data Sets" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/modern_neural_networks_generalize_on_small_data_sets/>Modern Neural Networks Generalize on Small Data Sets</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/deep_learning_on_small_datasets_without_pre_training_using_cosine_loss/ title="Deep Learning on Small Datasets without Pre-Training using Cosine Loss" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_learning_on_small_datasets_without_pre_training_using_cosine_loss/>Deep Learning on Small Datasets without Pre-Training using Cosine Loss</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/condconv_conditional_parameterized_convolutions_for_efficient_inference/ title="CondConv: Conditionally Parameterized Convolutions for Efficient Inference" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/condconv_conditional_parameterized_convolutions_for_efficient_inference/>CondConv: Conditionally Parameterized Convolutions for Efficient Inference</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/dynamic_convolution_attention_over_convolution_kernels/ title="Dynamic Convolution: Attention over Convolution Kernels" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/dynamic_convolution_attention_over_convolution_kernels/>Dynamic Convolution: Attention over Convolution Kernels</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/cnn/ title="Convolutional Newral Network (CNN)" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/cnn/>Convolutional Newral Network (CNN)</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/modeling_long_and_short_term_temporal_patterns_with_deep_neural_networks/ title="Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/modeling_long_and_short_term_temporal_patterns_with_deep_neural_networks/>Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/transformer/ title=Transformer style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/transformer/>Transformer</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/bert/ title="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/bert/>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/deepfakes_and_beyond_a_survey_of_face_manipulation_and_fake_detection/ title="DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deepfakes_and_beyond_a_survey_of_face_manipulation_and_fake_detection/>DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/graph_neural_network/ title="Graph Neural Network (GNN)" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/graph_neural_network/>Graph Neural Network (GNN)</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/sanity_checks_for_saliency_maps/ title="Sanity Checks for Saliency Maps" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/sanity_checks_for_saliency_maps/>Sanity Checks for Saliency Maps</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/variational_autoencoder/ title="Variational Autoencoder" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/variational_autoencoder/>Variational Autoencoder</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/autoencoder/ title=Autoencoder style=background-image:url(https://deepage.net/img/deeplearning_autoencoder/autoencoder.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/autoencoder/>Autoencoder</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/iterative_energy_based_projection_on_a_normal_data_manifold_for_anomaly_localization/ title="Iterative energy-based projection on a normal data manifold for anomaly localization" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/iterative_energy_based_projection_on_a_normal_data_manifold_for_anomaly_localization/>Iterative energy-based projection on a normal data manifold for anomaly localization</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/singan_learning_a_generative_model_from_a_single_natural_image/ title="SinGAN: Learning a Generative Model from a Single Natural Image" style=background-image:url(https://webee.technion.ac.il/people/tomermic/SinGAN/SinGAN_files/image041.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/singan_learning_a_generative_model_from_a_single_natural_image/>SinGAN: Learning a Generative Model from a Single Natural Image</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/a_closer_look_at_spatiotemporal_convolutions_for_action_recognition/ title="A Closer Look at Spatiotemporal Convolutions for Action Recognition" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/a_closer_look_at_spatiotemporal_convolutions_for_action_recognition/>A Closer Look at Spatiotemporal Convolutions for Action Recognition</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/ title="Learning Spatiotemporal Features with 3D Convolutional Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/>Learning Spatiotemporal Features with 3D Convolutional Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/tiny_video_networks/ title="Tiny Video Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/tiny_video_networks/>Tiny Video Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/deep_afinity_network_for_multiple_object_tracking/ title="Deep Affinity Network for Multiple Object Tracking" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_afinity_network_for_multiple_object_tracking/>Deep Affinity Network for Multiple Object Tracking</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/attention/ title="Attention Is All You Need" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/attention/>Attention Is All You Need</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/show_attend_and_tell_neural_image_caption_generation_with_visual_attention/ title="Show, Attend and Tell: Neural Image Caption Generation with Visual Attention" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/show_attend_and_tell_neural_image_caption_generation_with_visual_attention/>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/detecting_and_explaining_crisis/ title="Detecting and Explaining Crisis" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/detecting_and_explaining_crisis/>Detecting and Explaining Crisis</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/interpretability/ title=Interpretability style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/interpretability/>Interpretability</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/smooth_grad_removing_noise_by_adding_noise/ title="SmoothGrad: removing noise by adding noise" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/smooth_grad_removing_noise_by_adding_noise/>SmoothGrad: removing noise by adding noise</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/mobilenetv2/ title="MobileNetV2: Inverted Residuals and Linear Bottlenecks" style=background-image:url(https://1.bp.blogspot.com/-M8UvZJWNW4E/WsKk-tbzp8I/AAAAAAAAChw/OqxBVPbDygMIQWGug4ZnHNDvuyK5FBMcQCLcBGAs/s640/image5.png)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/mobilenetv2/>MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/machine_learning/ title="Machine Learning" style=background-image:url(https://cdn.pixabay.com/photo/2015/08/28/08/51/board-911636_1280.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/machine_learning/>Machine Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/tensorflow/ title=TensorFlow style=background-image:url(https://upload.wikimedia.org/wikipedia/commons/1/11/TensorFlowLogo.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/tensorflow/>TensorFlow</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/network-architecture/ title="Network Architecture" style=background-image:url(https://cdn.pixabay.com/photo/2015/03/14/17/51/web-673485_1280.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/network-architecture/>Network Architecture</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/knowledge_distillation/ title="Knowledge Distillation" style=background-image:url(https://cdn.pixabay.com/photo/2013/07/13/13/48/chemistry-161575_1280.png)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/knowledge_distillation/>Knowledge Distillation</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/gan/ title="Generative adversarial network" style=background-image:url(https://developers.google.com/machine-learning/gan/images/gan_diagram.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/gan/>Generative adversarial network</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/counterfactual_visual_explanations/ title="Counterfactual Visual Explanations" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/counterfactual_visual_explanations/>Counterfactual Visual Explanations</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/benchmarking-model-based-reinforcement-learning/ title="Benchmarking Model-Based Reinforcement Learning" style="background-image:url(https://lh3.googleusercontent.com/JsrXuvxJ12kUsJz_d8cXX14Y7kE_XDti9UcsGAU44PE6JmZt_-zf1g71keNfjC9Sn59rwo8wCApmN8XGW744YJCssAOgqKZR1xJvD4FUbTGw46cn1N8YsxRQKorML35Mv8Y3c2jg-AzLlMnAb0Q9nDdDn7rdaYTFJN-qWK6NdFdriFUJSccHEaRjOg19jAYioWdwSXTY_94v2m21MxHp_U0kj6YQJn0eFZRLMoH_K_QmqF5CgtevdmaOP9pjYfMzUOQUoWhUb8RDw4dAqk1dRajVffFT2vzm932SW33Rs_usF6_pG5f1oBB9sluIQeaVIhoEZ-biWWZNu6ceLSwHpDfZbIHOOxINjOCjdPobRgWqADtyhXpv_orP05OqzEfkaKuuSCczOTIs0efKGzDr4uoGFg5v_QPy3ORIRQfhPjR1XNgVZgqoN5Cy5nNR9itnETMXeHNmuwm3hbm4e7VAj7cSkIKhsihX6f8AL-o1FRgTp_6r7bNoGyBXIkH7VECTSOYmCyhhV_tJf6WMUzF1AQdo3WDpx8dL_scO-bVYqmHq_oa8UjhI1WSha2IYNs-uqOjczqlzvbTT2wTN5Jim6YWZP2jJiRyTbdzcnA2pIPnWZvWjKPOxRAoIu3P0FB4opmI5HPPXKJWyfOzuggS1gmA9qZJDMJ1QhCfqBltAMrxq7AffV6rRzYeTWP09qwIhKHEjD4EYQww9MZ645mpIuBQ81EiFU1XPw1EQ_ffUSWQndg=s0)"></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/benchmarking-model-based-reinforcement-learning/>Benchmarking Model-Based Reinforcement Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/point_cloud_deep_servey/ title="三次元点群を扱うニューラルネットワークのサーベイ (ver.2)" style=background-image:url()></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/point_cloud_deep_servey/>三次元点群を扱うニューラルネットワークのサーベイ (ver.2)</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/software/medical_ai/ title="Medical AI 専門コース オンライン講義資料" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/software class=post_tag>software</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/software/medical_ai/>Medical AI 専門コース オンライン講義資料</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/software/chainer_tutorial/ title="Chainer Tutorial" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/software class=post_tag>software</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/software/chainer_tutorial/>Chainer Tutorial</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/training_data_dcgan/ title="DCGAN のためのデータセット調査" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/machine-learning class=post_tag>machine learning</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/training_data_dcgan/>DCGAN のためのデータセット調査</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/software/skills/ title=情報系の資格 style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/software class=post_tag>software</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/software/skills/>情報系の資格</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/ title="Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/>Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/larget_scale_learning_of_general_visual_representation_for_transfer/ title="Large Scale Learning of General Visual Representations for Transfer" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/larget_scale_learning_of_general_visual_representation_for_transfer/>Large Scale Learning of General Visual Representations for Transfer</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/noise2noise_learning_image_restoration_without_clean_data/ title="Noise2Noise: Learning Image Restoration without Clean Data" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/noise2noise_learning_image_restoration_without_clean_data/>Noise2Noise: Learning Image Restoration without Clean Data</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul><h3>Generative adversarial network</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/gan/ title="Generative adversarial network" style=background-image:url(https://developers.google.com/machine-learning/gan/images/gan_diagram.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/gan/>Generative adversarial network</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/a_style_based_generator_architecture_for_generative_adversarial_networks/ title="A Style-Based Generator Architecture for Generative Adversarial Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/a_style_based_generator_architecture_for_generative_adversarial_networks/>A Style-Based Generator Architecture for Generative Adversarial Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/smoothness_and_stability_in_gans/ title="Smoothness and Stability in GANs" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/smoothness_and_stability_in_gans/>Smoothness and Stability in GANs</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/singan_learning_a_generative_model_from_a_single_natural_image/ title="SinGAN: Learning a Generative Model from a Single Natural Image" style=background-image:url(https://webee.technion.ac.il/people/tomermic/SinGAN/SinGAN_files/image041.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/singan_learning_a_generative_model_from_a_single_natural_image/>SinGAN: Learning a Generative Model from a Single Natural Image</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/deep_learning/ title="Deep Learning" style=background-image:url(https://cdn.pixabay.com/photo/2018/11/15/00/56/neural-network-3816319_960_720.png)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_learning/>Deep Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/training_data_dcgan/ title="DCGAN のためのデータセット調査" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/machine-learning class=post_tag>machine learning</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/training_data_dcgan/>DCGAN のためのデータセット調査</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/ title="Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/>Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/a_style_based_generator_architecture_for_generative_adversarial_networks/ title="A Style-Based Generator Architecture for Generative Adversarial Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/a_style_based_generator_architecture_for_generative_adversarial_networks/>A Style-Based Generator Architecture for Generative Adversarial Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/generative_model/ title="Generative Model" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/generative_model/>Generative Model</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/smoothness_and_stability_in_gans/ title="Smoothness and Stability in GANs" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/smoothness_and_stability_in_gans/>Smoothness and Stability in GANs</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/singan_learning_a_generative_model_from_a_single_natural_image/ title="SinGAN: Learning a Generative Model from a Single Natural Image" style=background-image:url(https://webee.technion.ac.il/people/tomermic/SinGAN/SinGAN_files/image041.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/singan_learning_a_generative_model_from_a_single_natural_image/>SinGAN: Learning a Generative Model from a Single Natural Image</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/training_data_dcgan/ title="DCGAN のためのデータセット調査" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/machine-learning class=post_tag>machine learning</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/training_data_dcgan/>DCGAN のためのデータセット調査</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/ title="Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/unsupervisedanomalydetectionwithgenerativeadversarialnetworkstoguidemarkerdiscovery/>Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul><h3>Metric Learning</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/metric_learning/ title="Metric Learning" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/metric_learning/>Metric Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul><h3>NVIDIA Corporation</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/organization/nvidia/ title="NVIDIA Corporation" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/organization class=post_tag>organization</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/organization/nvidia/>NVIDIA Corporation</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul><h3>More from しさく</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/tiny_video_networks/ title="Tiny Video Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/tiny_video_networks/>Tiny Video Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/natural_language_processing/ title="Natural Language Processing" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/natural_language_processing/>Natural Language Processing</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/anomaly_detection/ title="Anomaly Detection" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/anomaly_detection/>Anomaly Detection</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/cvpr2018/ title=CVPR2018 style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/cvpr2018/>CVPR2018</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/iccv2015/ title=ICCV2015 style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/iccv2015/>ICCV2015</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-01-31 10:14:54 +0900 +0900</div></div></div></li></ul></aside></div><script src=https://iimuz.github.io/scrapbook/js/autosize.min.js></script><script src=https://iimuz.github.io/scrapbook/js/timeago.js></script></main><svg width="0" height="0" class="hidden"><symbol viewBox="0 0 699.428 699.428" xmlns="http://www.w3.org/2000/svg" id="copy"><path d="M502.714.0H240.428C194.178.0 153 42.425 153 87.429l-25.267.59c-46.228.0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249.0 87.428-42.424 87.428-87.428h21.857c46.25.0 87.429-42.424 87.429-87.428v-349.19zM459 655.715H131.143c-22.95.0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95.0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337.0 87.975.0 87.975.0 45.419 40.872 86.882 87.428 86.882H612zm-65.572-349.715c-23.277.0-43.714-42.293-43.714-64.981V44.348L612 174.857zm-43.714 131.537H306c-12.065.0-21.857 9.77-21.857 21.835s9.792 21.835 21.857 21.835h196.714c12.065.0 21.857-9.771 21.857-21.835.0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065.0-21.857 9.77-21.857 21.834.0 12.066 9.792 21.836 21.857 21.836h196.714c12.065.0 21.857-9.77 21.857-21.836.0-12.064-9.792-21.834-21.857-21.834z"/></symbol><symbol viewBox="0 0 60.015 60.015" xmlns="http://www.w3.org/2000/svg" id="reply"><path d="M42.007.0h-24c-9.925.0-18 8.075-18 18v14c0 9.59 7.538 17.452 17 17.973v8.344a1.694 1.694.0 001.699 1.698c.44.0.873-.173 1.198-.498l1.876-1.876C26.708 52.713 33.259 50 40.227 50h1.78c9.925.0 18-8.075 18-18V18c0-9.925-8.075-18-18-18zm16 32c0 8.822-7.178 16-16 16h-1.78c-7.502.0-14.556 2.921-19.86 8.226l-1.359 1.359V44a1 1 0 10-2 0v3.949c-8.356-.52-15-7.465-15-15.949V18c0-8.822 7.178-16 16-16h24c8.822.0 16 7.178 16 16v14z"/></symbol></svg><footer class=footer><div class="footer_inner wrap pale"><p>&copy; <span class=year></span>しさく</p><p>Designed by <a href="<no value>" title="Linkedin Profile"><no value></a></p></div></footer><script src=https://iimuz.github.io/scrapbook/js/index.js></script></body></html>