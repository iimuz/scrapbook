<!doctype html><html lang=en><head><title>Ar xiv.org | しさく</title><meta charset=utf-8><meta name=generator content="Hugo 0.63.1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv=x-ua-compatible content="IE=edge"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="arXiv.org"><meta name=description content="arXiv.org"><meta property="og:description" content="arXiv.org"><meta property="og:url" content="https://iimuz.github.io/scrapbook/study/arxiv/"><meta property="og:image" content="https://iimuz.github.io/scrapbook/images/https:/upload.wikimedia.org/wikipedia/commons/a/a8/ArXiv_web.svg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:creator content><meta name=twitter:title content="arXiv.org"><meta property="twitter:description" content="arXiv.org"><meta name=twitter:image content="https://iimuz.github.io/scrapbook/images/https:/upload.wikimedia.org/wikipedia/commons/a/a8/ArXiv_web.svg"><link rel=apple-touch-icon sizes=180x180 href=https://iimuz.github.io/scrapbook/images/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://iimuz.github.io/scrapbook/images/icons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://iimuz.github.io/scrapbook/images/icons/favicon-16x16.png><link rel=manifest href=https://iimuz.github.io/scrapbook/images/icons/site.webmanifest><link rel=canonical href=https://iimuz.github.io/scrapbook/study/arxiv/><link rel=stylesheet href=https://iimuz.github.io/scrapbook/css/styles.a1e1a9f0e58a84cfca79c98c11b9e900971b61f840c5fbe7f3ddad8ebcd9798517a0ea30089562091e9105239ce941ccc4953d8c3a0c08a2f5082ace791f0186.css integrity="sha512-oeGp8OWKhM/KecmMEbnpAJcbYfhAxfvn892tjrzZeYUXoOowCJViCR6RBSOc6UHMxJU9jDoMCKL1CCrOeR8Bhg=="><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.2/css/all.min.css></head><body><div class=nav-drop><div class=nav-body><a href=https://iimuz.github.io/scrapbook/search/ class=nav_item>search</a>
<a href=https://iimuz.github.io/scrapbook/tags/ class=nav_item>tags</a>
<a href=https://iimuz.github.io/scrapbook/categories/ class=nav_item>categories</a>
<a href=https://github.com/iimuz/til/ class=nav_item>til</a><div class=nav-close></div></div></div><header class=nav><nav class=nav-menu><a href=https://iimuz.github.io/scrapbook/ class="nav-brand nav_item">しさく</a><div class=nav_bar-wrap><div class=nav_bar></div></div></nav></header><main><section class=post_header style=background-image:url(https://upload.wikimedia.org/wikipedia/commons/a/a8/ArXiv_web.svg)><h1 class=post_title>arXiv.org</h1></section><div class=post><article class=post_content><div><i class="far fa-calendar-check"></i>2019-12-30 10:34:30 +0900 +0900
<i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div><ul><li><a href=https://arxiv.org/>arXiv.org</a></li></ul><div class=post_extra><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div></article><aside><h3>Referenced from</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/modeling_relational_data_with_graph_convolutional_networks/ title="Modeling Relational Data with Graph Convolutional Networks" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/modeling_relational_data_with_graph_convolutional_networks/>Modeling Relational Data with Graph Convolutional Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/the_dataset_nutrition_label_a_framework_to_drive_higher_data_quality_standards/ title="The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/the_dataset_nutrition_label_a_framework_to_drive_higher_data_quality_standards/>The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/model_cards_for_model_reporting/ title="Model Cards for Model Reporting" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/model_cards_for_model_reporting/>Model Cards for Model Reporting</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/phrase_based_and_neural_unsupervised_machine_translation/ title="Phrase-Based & Neural Unsupervised Machine Translation" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/phrase_based_and_neural_unsupervised_machine_translation/>Phrase-Based & Neural Unsupervised Machine Translation</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/improving_neural_machine_translation_models_with_monolingual_data/ title="Improving Neural Machine Translation Models with Monolingual Data" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/improving_neural_machine_translation_models_with_monolingual_data/>Improving Neural Machine Translation Models with Monolingual Data</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/data_distillation_towards_omni_supervised_learning/ title="Data Distillation: Towards Omni-Supervised Learning" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/data_distillation_towards_omni_supervised_learning/>Data Distillation: Towards Omni-Supervised Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/billion_scale_semi_supervised_learning_for_image_classification/ title="Billion-scale semi-supervised learning for image classification" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/billion_scale_semi_supervised_learning_for_image_classification/>Billion-scale semi-supervised learning for image classification</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/datasheets_for_datasets/ title="Datasheets for Datasets" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/datasheets_for_datasets/>Datasheets for Datasets</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/active_user_authentication_for_smartphones_a_challenge_data_set_and_benchmark_results/ title="Active User Authentication for Smartphones: A Challenge Data Set and Benchmark Results" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/active_user_authentication_for_smartphones_a_challenge_data_set_and_benchmark_results/>Active User Authentication for Smartphones: A Challenge Data Set and Benchmark Results</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/decaf_a_deep_convolutional_activation_feature_for_generic_visual_recognition/ title="Decaf: A deep convolutional activation feature for generic visual recognition" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/decaf_a_deep_convolutional_activation_feature_for_generic_visual_recognition/>Decaf: A deep convolutional activation feature for generic visual recognition</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_deep_features_for_one_class_classification/ title="Learning Deep Features for One-Class Classification" style="background-image:url(https://lh3.googleusercontent.com/v6AReh7m_uzy6DyoyVLQvBBiaPO85KIcww7Ux5aTOxWIE6T0kD703Dd8mHOpqSbUQ7iql6mRCU7pevuR3viKUhjChOpO3MMXPgrEkajPxclQ3cjXJ4F9v-mV7gLItcHd-N5Yx0IalL1fh3goLLalbRzDi8gQwydzrgD7gKOvc7uTcUM3IKojyj0_MZu2GocHZ2U284FCHlFOkZYhxNvPIbRaCFZE4_m99GINlgXiiUzNRWTgdFOSj469hNusn26kO2e9RfdyU6xjBoXOXzAo4_sM1dcn00KZ7jplME4SdtTuPiuNe9ViaVYsJX20ePTxzExDhW15SC4HwTpbPgWTqthbteYoeMDzzVzkdYh3QUE7KZBNCz8kA7KLTs-sYcQXzOCvV3NAonywWNPsvOplybSxIsfeiEqamfCi9_2wuBpJQ6IcxQRyB-Wmo2Zp_tblajOlCO7dT5l6q7_j0DgmSkBIVaPf1O3RtkK3Kz7yjXmwyVMX6MV58Ji_l5sXJmFIqT-9UAW8_SmyXIw-sZZGMNlbP9OrTgpWUAXOwWMYd-TE4mBHGBsCc342ViOGq4_2H-soMW9qKtqezCC2-HW9bjDNaTwgoHJuiwcD90qQBJrt2ZL2R7B8yl_CrTFpj8INRSGWW29159dGiL_wSU62Yi3Nosh4wYIXkMpLsBlb10B6DQ9wPZ8uQAbkopctpFS7JYgLj5EP0qkbyHimCBoDGkQ0Gnjoa2miSbbF5IiV5QbXU1E=s0)"></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_deep_features_for_one_class_classification/>Learning Deep Features for One-Class Classification</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/are_we_really_making_much_progress_a_worrying_analysis_of_recent_neural_recommendation_approaches/ title="Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/are_we_really_making_much_progress_a_worrying_analysis_of_recent_neural_recommendation_approaches/>Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/adversarially_learned_inference/ title="Adversarially Learned Inference" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/adversarially_learned_inference/>Adversarially Learned Inference</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_deep_representations_by_mutual_information_estimation_and_maximization/ title="Learning deep representations by mutual information estimation and maximization" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_deep_representations_by_mutual_information_estimation_and_maximization/>Learning deep representations by mutual information estimation and maximization</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/deep_temporal_clustering_fully_unsupervised_learning_of_time_domain_features/ title="Deep Temporal Clustering : Fully Unsupervised Learning of Time-Domain Features" style="background-image:url(https://lh3.googleusercontent.com/x2UF4RLnQ1ca4nk8xflikurRQch45-oECb4mc6-_46_zfat-2C_LBZ3UUVnIoeuuQaCUKbcv60H62FLppwKxq0SKVt-WvomEhfZBi7n7d4SwjZEAl7XKWYysiAvJ1hEKfaTaFUGfj5wKeDO3Po87arGu3YKhVHd7__18OkuquNRBFx7taa7E3_NBxqsSQHTsY-cBzaKohlIIEeNZy4dwp7BA0QeNRuDir9nWfVzsKox9I5qtEUJeVrk7Vzu8CUN6kCyIFvW_EcesxCsgakB6Th3xkHjr55Pg9Fl_PjzwruHcOdrnrJE7piOGIIMzKy5PDKrfRkBI-Q33leiBinp76CbOyiVasvO1vfDwhjKEylNyYmFyft0TrjhXBf9s5SMQLiQX_WOYEYEp6Uxb_uG4_p431CqSN0t-ubMYp0B6FvcYALt9mzDeJOH6zaPjNa0eJukiCGLw4AfJ7joseiYUEbtaQU_xRhHsl7Ti54hW9BHZ6I3N8DEwDpCobva-UYJ9ggJdtDwAvBWL7qh2Lc3ibexUc7Zb_qQ6RRbybWfw8ydoyN6clAUN9LFwb1wwLsyA5L6bkcqUKoLQ78nkfWFOhgo6y1rPbw7I-A4XPzTszEbhalHJ09bGxZSOXbCKCFmGa-mGvGibKIKZONCJvAYGOxLobMlSO6lNhNZUumM2_Lqc-Lba0KeXbxA77Ek_7hdZrfc7-Izuc0avOrdpKJXyVKUIOFfoyfIhoSfsg38eDD6srmk=s0)"></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_temporal_clustering_fully_unsupervised_learning_of_time_domain_features/>Deep Temporal Clustering : Fully Unsupervised Learning of Time-Domain Features</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/improving_unsupervised_detect_segmentation_by_applying_structural_similarity_to_autoencoder/ title="Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/improving_unsupervised_detect_segmentation_by_applying_structural_similarity_to_autoencoder/>Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/embedding_human_knowledge_into_deep_neural_network_via_attention_map/ title="Embedding Human Knowledge into Deep Neural Network via Attention Map" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/embedding_human_knowledge_into_deep_neural_network_via_attention_map/>Embedding Human Knowledge into Deep Neural Network via Attention Map</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/feature_gradients_scalable_feature_selection_via_discrete_relaxation/ title="Feature Gradients: Scalable Feature Selection via Discrete Relaxation" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/feature_gradients_scalable_feature_selection_via_discrete_relaxation/>Feature Gradients: Scalable Feature Selection via Discrete Relaxation</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/arcface_additive_angular_margin_loss_for_deep_face_recognition/ title="ArcFace: Additive Angular Margin Loss for Deep Face Recognition" style="background-image:url(https://lh3.googleusercontent.com/-JURNUj8LbcqAHYVM5_tMhaZsVdOnJlnL_BrdIhxFoiave_o7e3tw7S3N18S8XMGH8MJH4fAassw06rmtOqPZy5MqBWYnzLAL5DmTmCr4qq_WFN4qcxzlrpWwWzK8fmdfB-sDdX1OATPIrZrLvI1pPuGGGZaYDbmeoX6W7e5WkUN2q1wL0RvmDSUXaqHDpmsaymUQuiNyY3dsms36FAuAdnnrkT9aCTCS2kZ5PS_APqkEd-GuhuMNwwqBHliQS9Tq2PR94L7fR0XP99fOh7TV7Orf7hyN4XapODpcf5yK2GXXjoFMjj1bgY0oya1S25-dFjFclTX1KUW2jzIVptLslagDPlcB3gbDqzKVF2-3EcjZqtDdSlpS8ufgseATzvBPyQF8KkSSB5lWSjze2OGqFyZhfdZYn2fGc5R-NmjN5VG2QeTYU7YqlAtj2NjCb-66r-OHhyevm90jaewdYSaCV11kVHF0xNgkeIMYUGQ3hxpQeLfOPiQKNsTwZX06Mna32WDR_SJy1jOnqgokHEAEUGPBfUUi0bIgH8vNwauX44Qlj4yChUPzlGx_rtKE2oyCzH9Nm64JXHXfX6yWTcs9XJXrU3NfyWg5nejW2PvvDB-Do3savT0IlQMj9dsncWQjJgkzUBLQwilplx1iLvEQT4IN5-bUnULQFwgYjY_9Mf1HVN0zgDmwI30F0VxJAnHTQEWCH3PV3mRzRM4-c2TMcQMUvZ1y6z90PPUyTj_ds3xRkY=s0)"></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/arcface_additive_angular_margin_loss_for_deep_face_recognition/>ArcFace: Additive Angular Margin Loss for Deep Face Recognition</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/fixmatch_simplifying_semi_supervised_learning_with_consistency_and_confidence/ title="FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/fixmatch_simplifying_semi_supervised_learning_with_consistency_and_confidence/>FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/pixel_recurrent_neural_networks/ title="Pixel Recurrent Neural Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/pixel_recurrent_neural_networks/>Pixel Recurrent Neural Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/conditional_image_generation_with_pixelcnn_decoders/ title="Conditional Image Generation with PixelCNN Decoders" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/conditional_image_generation_with_pixelcnn_decoders/>Conditional Image Generation with PixelCNN Decoders</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/wavenet/ title="WaveNet: A Generative Model for Raw Audio" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/wavenet/>WaveNet: A Generative Model for Raw Audio</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/time_series_anomaly_detection_service_at_microsoft/ title="Time-Series Anomaly Detection Service at Microsoft" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/time_series_anomaly_detection_service_at_microsoft/>Time-Series Anomaly Detection Service at Microsoft</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/nearest_neighbour_induced_isolation_similarity_and_its_impact_on_density_based_clustering/ title="Nearest-Neighbour-Induced Isolation Similarity and its Impact on Density-Based Clustering" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/nearest_neighbour_induced_isolation_similarity_and_its_impact_on_density_based_clustering/>Nearest-Neighbour-Induced Isolation Similarity and its Impact on Density-Based Clustering</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/highly_comparative_feature_based_time_series_classification/ title="Highly comparative feature-based time-series classification" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/highly_comparative_feature_based_time_series_classification/>Highly comparative feature-based time-series classification</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/an_experimental_evaluation_of_nearest_neighbor_time_series_classification/ title="An Experimental Evaluation of Nearest Neighbour Time Series Classification" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/an_experimental_evaluation_of_nearest_neighbor_time_series_classification/>An Experimental Evaluation of Nearest Neighbour Time Series Classification</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/meta_analysis_of_the_anomaly_detection_problme/ title="A Meta-Analysis of the Anomaly Detection Problem" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/meta_analysis_of_the_anomaly_detection_problme/>A Meta-Analysis of the Anomaly Detection Problem</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/ngboost/ title=NGBoost style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/ngboost/>NGBoost</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/what_does_bert_look_at_an_analsys_of_berts_attention/ title="What Does BERT Look At? An Analysis of BERT's Attention" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/what_does_bert_look_at_an_analsys_of_berts_attention/>What Does BERT Look At? An Analysis of BERT's Attention</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/self_attention_with_functional_time_representation_learning/ title="Self-attention with Functional Time Representation Learning" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/self_attention_with_functional_time_representation_learning/>Self-attention with Functional Time Representation Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/temporal_pattern_attention_for_multivariate_time_series_forecasting/ title="Temporal Pattern Attention for Multivariate Time Series Forecasting" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/temporal_pattern_attention_for_multivariate_time_series_forecasting/>Temporal Pattern Attention for Multivariate Time Series Forecasting</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/modeling_long_and_short_term_temporal_patterns_with_deep_neural_networks/ title="Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/modeling_long_and_short_term_temporal_patterns_with_deep_neural_networks/>Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/ title="Learning Spatiotemporal Features with 3D Convolutional Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/learning_spatiotemporal_features_with_3d_convolutional_networks/>Learning Spatiotemporal Features with 3D Convolutional Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/joint_descriminative_and_generative_leanring_for_person_reidentification/ title="Joint Discriminative and Generative Learning for Person Re-identification" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/joint_descriminative_and_generative_leanring_for_person_reidentification/>Joint Discriminative and Generative Learning for Person Re-identification</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/tiny_video_networks/ title="Tiny Video Networks" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/tiny_video_networks/>Tiny Video Networks</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/deep_afinity_network_for_multiple_object_tracking/ title="Deep Affinity Network for Multiple Object Tracking" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_afinity_network_for_multiple_object_tracking/>Deep Affinity Network for Multiple Object Tracking</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/arxiv_times/ title="arXiv Times" style=background-image:url(https://github.com/arXivTimes/arXivTimes/raw/master/arXivTimesLogo.PNG)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/arxiv_times/>arXiv Times</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/counterfactual_visual_explanations/ title="Counterfactual Visual Explanations" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/counterfactual_visual_explanations/>Counterfactual Visual Explanations</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/benchmarking-model-based-reinforcement-learning/ title="Benchmarking Model-Based Reinforcement Learning" style="background-image:url(https://lh3.googleusercontent.com/JsrXuvxJ12kUsJz_d8cXX14Y7kE_XDti9UcsGAU44PE6JmZt_-zf1g71keNfjC9Sn59rwo8wCApmN8XGW744YJCssAOgqKZR1xJvD4FUbTGw46cn1N8YsxRQKorML35Mv8Y3c2jg-AzLlMnAb0Q9nDdDn7rdaYTFJN-qWK6NdFdriFUJSccHEaRjOg19jAYioWdwSXTY_94v2m21MxHp_U0kj6YQJn0eFZRLMoH_K_QmqF5CgtevdmaOP9pjYfMzUOQUoWhUb8RDw4dAqk1dRajVffFT2vzm932SW33Rs_usF6_pG5f1oBB9sluIQeaVIhoEZ-biWWZNu6ceLSwHpDfZbIHOOxINjOCjdPobRgWqADtyhXpv_orP05OqzEfkaKuuSCczOTIs0efKGzDr4uoGFg5v_QPy3ORIRQfhPjR1XNgVZgqoN5Cy5nNR9itnETMXeHNmuwm3hbm4e7VAj7cSkIKhsihX6f8AL-o1FRgTp_6r7bNoGyBXIkH7VECTSOYmCyhhV_tJf6WMUzF1AQdo3WDpx8dL_scO-bVYqmHq_oa8UjhI1WSha2IYNs-uqOjczqlzvbTT2wTN5Jim6YWZP2jJiRyTbdzcnA2pIPnWZvWjKPOxRAoIu3P0FB4opmI5HPPXKJWyfOzuggS1gmA9qZJDMJ1QhCfqBltAMrxq7AffV6rRzYeTWP09qwIhKHEjD4EYQww9MZ645mpIuBQ81EiFU1XPw1EQ_ffUSWQndg=s0)"></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/benchmarking-model-based-reinforcement-learning/>Benchmarking Model-Based Reinforcement Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/cold-case-the-lost-mnist-digits/ title="Cold Case: the Lost MNIST Digits" style="background-image:url(https://lh3.googleusercontent.com/zUBlDbK96k00QRfx0gHWAyJiloU-hzQXy1fX7e7zj3wEogAl00312y2e13j0y2pzyFlacVDHkDwW_aRDdpdMxNcAs0waI4cEk6JsVnFSAzbJRcSi6_q6AMHww1fnA0mTEOe-eNmzO0tW1earDwwVJSRIywKagVq-dyAihIWYW3RtPKkwmuO16zF2TIzrDoNEtA9ZyCWZD5XBiVC_wRcy0YMc-3iMaKNRVFAH-ne3WRclFZz6KSqjQs50kkjX2tChdK-BHjrRXRWWdXj4eIioZ-rGHIJsyeUCFff29sfd1Er0HY5WMycysghKE0YvMmY25LoIldepljMCf0NAx3KahbbaGs-ZuLwR1_I13v8ZExVQRAYWsH_x44usn0VkXAk2QXEKNsj34cE8mbAaKxM8hLl7kopI-sA2-bG0c68Wun9j_q6xtg58e64dYbwBpK8sGdgSGeu8nmwxRf53Nr0v8v1ZvhzgVAt0WjOzWeehBIocQJSo8edl3XfVTb5t5lkWkwdyPGuxoSwT7S_rmCeP0PzSxmClP2eCNOYHyzyHsfdu3IOZk044Dg34PudO67M6bTtiBIIN8kGGKmmhJe4XdvgAnIN1P0KIYgQLz-_ETLjMTduTNNBFPEww8SPBnvdg1Fhbnmb2C72BBK2_bkLmbMzxdWBR7YZynq4lmvf7y0iZNLiaEflYOyO5WgFB05F7HYY_XpR7DoIRkiC0PNbA6ni4u5Kf8-qXrKXpJENVEAmzsA=s0)"></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/cold-case-the-lost-mnist-digits/>Cold Case: the Lost MNIST Digits</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/noise2noise_learning_image_restoration_without_clean_data/ title="Noise2Noise: Learning Image Restoration without Clean Data" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/noise2noise_learning_image_restoration_without_clean_data/>Noise2Noise: Learning Image Restoration without Clean Data</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li></ul><h3>More from しさく</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/machine_learning/ title="Machine Learning" style=background-image:url(https://cdn.pixabay.com/photo/2015/08/28/08/51/board-911636_1280.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/machine_learning/>Machine Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/tensorflow/ title=TensorFlow style=background-image:url(https://upload.wikimedia.org/wikipedia/commons/1/11/TensorFlowLogo.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/tensorflow/>TensorFlow</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/network-architecture/ title="Network Architecture" style=background-image:url(https://cdn.pixabay.com/photo/2015/03/14/17/51/web-673485_1280.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/network-architecture/>Network Architecture</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/knowledge_distillation/ title="Knowledge Distillation" style=background-image:url(https://cdn.pixabay.com/photo/2013/07/13/13/48/chemistry-161575_1280.png)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/knowledge_distillation/>Knowledge Distillation</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/gan/ title="Generative adversarial network" style=background-image:url(https://developers.google.com/machine-learning/gan/images/gan_diagram.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/gan/>Generative adversarial network</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-05-14 23:03:21 +0000 UTC</div></div></div></li></ul></aside></div><script src=https://iimuz.github.io/scrapbook/js/autosize.min.js></script><script src=https://iimuz.github.io/scrapbook/js/timeago.js></script></main><svg width="0" height="0" class="hidden"><symbol viewBox="0 0 699.428 699.428" xmlns="http://www.w3.org/2000/svg" id="copy"><path d="M502.714.0H240.428C194.178.0 153 42.425 153 87.429l-25.267.59c-46.228.0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249.0 87.428-42.424 87.428-87.428h21.857c46.25.0 87.429-42.424 87.429-87.428v-349.19zM459 655.715H131.143c-22.95.0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95.0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337.0 87.975.0 87.975.0 45.419 40.872 86.882 87.428 86.882H612zm-65.572-349.715c-23.277.0-43.714-42.293-43.714-64.981V44.348L612 174.857zm-43.714 131.537H306c-12.065.0-21.857 9.77-21.857 21.835s9.792 21.835 21.857 21.835h196.714c12.065.0 21.857-9.771 21.857-21.835.0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065.0-21.857 9.77-21.857 21.834.0 12.066 9.792 21.836 21.857 21.836h196.714c12.065.0 21.857-9.77 21.857-21.836.0-12.064-9.792-21.834-21.857-21.834z"/></symbol><symbol viewBox="0 0 60.015 60.015" xmlns="http://www.w3.org/2000/svg" id="reply"><path d="M42.007.0h-24c-9.925.0-18 8.075-18 18v14c0 9.59 7.538 17.452 17 17.973v8.344a1.694 1.694.0 001.699 1.698c.44.0.873-.173 1.198-.498l1.876-1.876C26.708 52.713 33.259 50 40.227 50h1.78c9.925.0 18-8.075 18-18V18c0-9.925-8.075-18-18-18zm16 32c0 8.822-7.178 16-16 16h-1.78c-7.502.0-14.556 2.921-19.86 8.226l-1.359 1.359V44a1 1 0 10-2 0v3.949c-8.356-.52-15-7.465-15-15.949V18c0-8.822 7.178-16 16-16h24c8.822.0 16 7.178 16 16v14z"/></symbol></svg><footer class=footer><div class="footer_inner wrap pale"><p>&copy; <span class=year></span>しさく</p><p>Designed by <a href="<no value>" title="Linkedin Profile"><no value></a></p></div></footer><script src=https://iimuz.github.io/scrapbook/js/index.js></script></body></html>