<!doctype html><html lang=en><head><title>不均衡データ ( imbalanced data) | しさく</title><meta charset=utf-8><meta name=generator content="Hugo 0.63.1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv=x-ua-compatible content="IE=edge"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="不均衡データ (Imbalanced Data)"><meta name=description content="機械学習において学習データセットのデータがクラスごとにサンプル数が違う状態を指します。
概要 不均衡データに対するアプローチとしては下記の手法がある。
 データレベルのアプローチ: 多い方のラベルデータを減らしたり、 少ないほうのラベルデータを増やしたりする1 2 コスト考慮型学習: 少ないほうのラベルデータを誤分類す …"><meta property="og:description" content="機械学習において学習データセットのデータがクラスごとにサンプル数が違う状態を指します。
概要 不均衡データに対するアプローチとしては下記の手法がある。
 データレベルのアプローチ: 多い方のラベルデータを減らしたり、 少ないほうのラベルデータを増やしたりする1 2 コスト考慮型学習: 少ないほうのラベルデータを誤分類す …"><meta property="og:url" content="https://iimuz.github.io/scrapbook/study/imbalanced_data/"><meta property="og:image" content="https://iimuz.github.io/scrapbook/images/https:/cdn.pixabay.com/photo/2016/12/29/16/24/balance-1938874_960_720.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:creator content><meta name=twitter:title content="不均衡データ (Imbalanced Data)"><meta property="twitter:description" content="機械学習において学習データセットのデータがクラスごとにサンプル数が違う状態を指します。
概要 不均衡データに対するアプローチとしては下記の手法がある。
 データレベルのアプローチ: 多い方のラベルデータを減らしたり、 少ないほうのラベルデータを増やしたりする1 2 コスト考慮型学習: 少ないほうのラベルデータを誤分類す …"><meta name=twitter:image content="https://iimuz.github.io/scrapbook/images/https:/cdn.pixabay.com/photo/2016/12/29/16/24/balance-1938874_960_720.jpg"><link rel=apple-touch-icon sizes=180x180 href=https://iimuz.github.io/scrapbook/images/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://iimuz.github.io/scrapbook/images/icons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://iimuz.github.io/scrapbook/images/icons/favicon-16x16.png><link rel=manifest href=https://iimuz.github.io/scrapbook/images/icons/site.webmanifest><link rel=canonical href=https://iimuz.github.io/scrapbook/study/imbalanced_data/><link rel=stylesheet href=https://iimuz.github.io/scrapbook/css/styles.a1e1a9f0e58a84cfca79c98c11b9e900971b61f840c5fbe7f3ddad8ebcd9798517a0ea30089562091e9105239ce941ccc4953d8c3a0c08a2f5082ace791f0186.css integrity="sha512-oeGp8OWKhM/KecmMEbnpAJcbYfhAxfvn892tjrzZeYUXoOowCJViCR6RBSOc6UHMxJU9jDoMCKL1CCrOeR8Bhg=="><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.2/css/all.min.css></head><body><div class=nav-drop><div class=nav-body><a href=https://iimuz.github.io/scrapbook/search/ class=nav_item>search</a>
<a href=https://iimuz.github.io/scrapbook/tags/ class=nav_item>tags</a>
<a href=https://iimuz.github.io/scrapbook/categories/ class=nav_item>categories</a>
<a href=https://github.com/iimuz/til/ class=nav_item>til</a><div class=nav-close></div></div></div><header class=nav><nav class=nav-menu><a href=https://iimuz.github.io/scrapbook/ class="nav-brand nav_item">しさく</a><div class=nav_bar-wrap><div class=nav_bar></div></div></nav></header><main><section class=post_header style=background-image:url(https://cdn.pixabay.com/photo/2016/12/29/16/24/balance-1938874_960_720.jpg)><h1 class=post_title>不均衡データ (Imbalanced Data)</h1></section><div class=post><article class=post_content><div><i class="far fa-calendar-check"></i>2020-01-09 20:21:43 +0900 +0900
<i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div><p>機械学習において学習データセットのデータがクラスごとにサンプル数が違う状態を指します。</p><h2 id=概要>概要</h2><p>不均衡データに対するアプローチとしては下記の手法がある。</p><ul><li>データレベルのアプローチ:
多い方のラベルデータを減らしたり、
少ないほうのラベルデータを増やしたりする<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></li><li>コスト考慮型学習:
少ないほうのラベルデータを誤分類することに対して、
より重いペナルティを課すように損失関数を定義する<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></li><li>異常検知手法の適用: 少ないほうのラベルを異常値とみなす<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></li><li>モデル評価値の算出手法:
通常の accuracy からデータ数を考慮した accuracy を利用して評価する<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></li></ul><h2 id=データレベルのアプローチ>データレベルのアプローチ</h2><h3 id=undersampling>Undersampling</h3><p>多いほうのラベルデータを減らすことでデータの均衡をとる方法です。
一見すると簡単で有効そうに感じられるが幾つかの問題がある<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>。</p><ul><li>多いほうのラベルデータからランダムサンプルするだけでは、データに偏りが発生する。
予めクラスタ分析などを実施してからサンプリングを行う必要がある。<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></li><li>学習した分類器の分散が大きくなるため、 UnderBagging<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> のような平均化戦略をとる。
UnderBagging では、 Bagging でアンサンブルを行う。</li><li>事後分布がゆがむため、事前分布を用いて事後分布を修正する<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>。</li><li>Undersampling が有効な場合はどういう場合かは <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> で説明されている。</li></ul><h3 id=oversampling>Oversampling</h3><p>少ないほうのラベルデータを水増しすることでデータの均衡をとる方法です。
代表的な手法として、 Synthetic Minority Oversampling TEchnique (SMOTE)<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup> がある。
SMOTE は、データ点同士をつないだ線分譲の任意の点をランダムに人口データとして生成する手法。</p><p>SMOTE の拡張は下記のような方針に分類できる<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>。</p><ol><li>Oversampling のためのデータ点の選択方法</li><li>Undersampling を Oversampling の前後いずれで実行するか</li><li>補完方法</li><li>データ生成を次元削減などの処理に対していつ実施するか</li><li>データ生成に適応的な手法を利用するかどうか</li><li>再ラベル付けをするか</li><li>SMOTE 実施後のノイズ除去ステップを入れるかどうか</li></ol><p>SMOTE の拡張として、よく利用される方法は下記になる<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>。</p><ul><li>Borderline-SMOTE<sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup></li><li>AHC<sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup></li><li>ADSYN<sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup> <sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup></li><li>Safe-Level-SMOTE<sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup></li><li>DBSMOTE<sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup></li><li>ROSE<sup id=fnref:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup></li><li>MWMOTE<sup id=fnref:14><a href=#fn:14 class=footnote-ref role=doc-noteref>14</a></sup></li><li>MDO<sup id=fnref:15><a href=#fn:15 class=footnote-ref role=doc-noteref>15</a></sup></li><li>SMOTEENN, SMOTETomec<sup id=fnref:16><a href=#fn:16 class=footnote-ref role=doc-noteref>16</a></sup> <sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup></li></ul><p>クラス分類ではなく回帰問題の場合は、 SMOTER<sup id=fnref:17><a href=#fn:17 class=footnote-ref role=doc-noteref>17</a></sup> という方法が用いられる。
SMOTE は特殊な問題設定に特化した拡張も多く提案されている<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>。</p><h2 id=モデル評価値の算出手法>モデル評価値の算出手法</h2><p>モデル評価時に通常通り accuracy を計算するとデータ数が多いクラスに全てのラベルを設定することで、
一定の精度が出ているように見えます。
例えば、<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>では、下記のようなパターンに関して記載されています。
ただし、コメントに記載のケースでは balaned accuracy が 57% になりませんでした。
ただ、<sup id=fnref:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup>のケースと同じとはずなので、下記の計算で良いはずです。</p><table><thead><tr><th align=center></th><th align=right>actual positive</th><th align=right>actual negative</th></tr></thead><tbody><tr><td align=center>predicted positive</td><td align=right>40</td><td align=right>8</td></tr><tr><td align=center>predicted negative</td><td align=right>5</td><td align=right>2</td></tr></tbody></table><ul><li>$$ accuracy = \frac{40 + 2}{40 + 5 + 8 + 2} = 0.76 $$</li><li>$$ balanced accuracy = \frac{\frac{40}{40 + 5} + \frac{2}{8 + 2}}{2} = 0.54 $$</li></ul><p>Scikit-Learn の場合は、 <a href=https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules>&ldquo;balaned_accuracy&rdquo;</a> で計算できます。</p><h2 id=kaggle-関連>Kaggle 関連</h2><ul><li><a href=https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/56475#326705>TalkingData AdTracking Fraud Detection Challenge: Discussion 1st place</a><ul><li>上記コンペの 1 位解法に Negative downsampling してもあまりスコアが下がらず、
異なるシードで作られた 5 つのデータセットに対しての予測結果をバギングしたらスコアが上がったみたいです。</li></ul></li><li><a href=https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets>Resampling strategies for imbalanced datasets</a><ul><li>Imbalanced dataset に対する Kaggle Notebook です。</li></ul></li></ul><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>2019.3.5 Sansan Builders Box <a href=https://buildersbox.corp-sansan.com/entry/2019/03/05/110000>【ML Tech RPT. 】第 4 回 不均衡データ学習 (Learning from Imbalanced Data) を学ぶ(1)</a> <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>2012.5.8 StackExchange <a href=https://stats.stackexchange.com/questions/28029/training-a-decision-tree-against-unbalanced-data>Training a decision tree against unbalanced data</a> <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>S. Wang, K. Tang, and X. Yao, &ldquo;Diversity exploration and negative correlation learning on imbalanced data sets,&rdquo; in IJCNN, 2009. <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>M. Saerens, P. Latinne, and C. Decaestecker, &ldquo;Adjusting the outputs of a classifier to new a priori probabilities: a simple procedure,&rdquo; in NC, 2002. <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>A. Dal Pozzolo, O. Caelen, and G. Bontempi, &ldquo;When is undersampling effective in unbalanced classification tasks?,&rdquo; in ECML/PKDD, 2015. <a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p>N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, &ldquo;SMOTE: Synthetic minority over-sampling technique,&rdquo; in JAIR, 2002. <a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7 role=doc-endnote><p>A. Fernandez, S. Garcia, F. Herrera, and N. V. Chawla, &ldquo;SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary,&rdquo; in JAIR, 2018. <a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8 role=doc-endnote><p>H. Han, W. Y. Wang, and B. H. Mao, &ldquo;BorderlineSMOTE: A new oversampling method in imbalanced data sets learning,&rdquo; in ICIC, 2005. <a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:9 role=doc-endnote><p>G. Cohen, M. Hilario, H. Sax, S. Hugonnet, and A. Geissbuhler, &ldquo;Learning from imbalanced data in surveillance of nosocomial infection,&rdquo; in AI in medicine, 2006. <a href=#fnref:9 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:10 role=doc-endnote><p>H. He, Y. Bai, E. A. Garcia, and S. Li,&ldquo;ADASYN: Adaptive synthetic sampling approach for imbalanced learning,&rdquo; in IJCNN, 2008. <a href=#fnref:10 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:11 role=doc-endnote><p>python の不均衡データ学習用ライブラリ <a href=https://imbalanced-learn.readthedocs.io/en/stable/index.html>imbalanced-learn</a> で実装されている。 <a href=#fnref:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:12 role=doc-endnote><p>C. Bunkhumpornpat, K. Sinapiromsaran, and C. Lursinsap, &ldquo;Safe-level-SMOTE: Safe-level-synthetic minority over-sampling technique for handling the class imbalanced problem,&rdquo; in PAKDD, 2019. <a href=#fnref:12 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:13 role=doc-endnote><p>G. Menardi, and N. Torelli, &ldquo;Training and assessing classification rules with imbalanced data.,&rdquo; in DMKD, 2014. <a href=#fnref:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:14 role=doc-endnote><p>S. Barua, M. M. Islam, X. Yao, and K. Murase, &ldquo;MWMOTE-Majority weighted minority oversampling technique for imbalanced data set learning,&rdquo; in TKDE, 2014. <a href=#fnref:14 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:15 role=doc-endnote><p>L. Abdi, and S. Hashemi, &ldquo;To combat multi-class imbalanced problems by means of over-sampling techniques,&rdquo; in TKDE, 2016. <a href=#fnref:15 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:16 role=doc-endnote><p>G. E. A. P. A. Batista, R. C. Prati, and M. C. Monard, &ldquo;A study of the behaviour of several methods for balancing machine learning training data, " in KDD Explorations, 2004. <a href=#fnref:16 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:17 role=doc-endnote><p>L. Torgo, P. Branco, R. P. Ribeiro, and B. Pfahringer, &ldquo;Resampling strategies for regression,&rdquo; in ES, 2015. <a href=#fnref:17 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:18 role=doc-endnote><p>2015.12.18 MVPA Meanderings <a href=http://mvpa.blogspot.com/2015/12/balanced-accuracy-what-and-why.html>balanced accuracy: what and why?</a> <a href=#fnref:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section><div class=post_extra><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div></article><aside><h3>Referenced from</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/deep_learning_for_imbalanced_multimedia_data_classification/ title="Deep Learning for Imbalanced Multimedia Data Classification" style=background-image:url(image%20url)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/deep_learning_for_imbalanced_multimedia_data_classification/>Deep Learning for Imbalanced Multimedia Data Classification</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li></ul><h3>Kaggle</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/software/kaggle/ title=Kaggle style=background-image:url(https://upload.wikimedia.org/wikipedia/commons/7/7c/Kaggle_logo.png)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/software class=post_tag>software</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/software/kaggle/>Kaggle</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/book/win_at_kaggle/ title="Kaggle で勝つデータ分析の技術" style=background-image:url(https://gihyo.jp/assets/images/cover/2019/thumb/TH160_9784297108434.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/book class=post_tag>book</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/book/win_at_kaggle/>Kaggle で勝つデータ分析の技術</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/machine_learning/ title="Machine Learning" style=background-image:url(https://cdn.pixabay.com/photo/2015/08/28/08/51/board-911636_1280.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/machine_learning/>Machine Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/software/coder/ title=競技プログラミング style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/software class=post_tag>software</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/software/coder/>競技プログラミング</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li></ul><h3>Machine Learning</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/machine_learning/ title="Machine Learning" style=background-image:url(https://cdn.pixabay.com/photo/2015/08/28/08/51/board-911636_1280.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/machine_learning/>Machine Learning</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li></ul><h3>More from しさく</h3><ul class="posts aside"><li class=post_item><a class=post_card href=/scrapbook/study/sanity_checks_for_saliency_maps/ title="Sanity Checks for Saliency Maps" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/sanity_checks_for_saliency_maps/>Sanity Checks for Saliency Maps</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/variational_autoencoder/ title="Variational Autoencoder" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/variational_autoencoder/>Variational Autoencoder</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/autoencoder/ title=Autoencoder style=background-image:url(https://deepage.net/img/deeplearning_autoencoder/autoencoder.jpg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/autoencoder/>Autoencoder</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/iclr2020/ title=ICLR2020 style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/iclr2020/>ICLR2020</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li><li class=post_item><a class=post_card href=/scrapbook/study/iclr/ title="International Conference on Learning Representations (ICLR)" style=background-image:url(https://iimuz.github.io/scrapbook/images/thumbnail.svg)></a><div class=excerpt><div class=excerpt_meta><a href=https://iimuz.github.io/scrapbook/tags/study class=post_tag>study</a><div class=copy data-share="Share Story" data-copied="Link Copied"><svg><use xlink:href="#copy"/></svg></div></div><h3 class=post_link><a href=/scrapbook/study/iclr/>International Conference on Learning Representations (ICLR)</a></h3><div class=post_link><div><i class="far fa-edit"></i>2020-04-12 22:17:06 +0900 +0900</div></div></div></li></ul></aside></div><script src=https://iimuz.github.io/scrapbook/js/autosize.min.js></script><script src=https://iimuz.github.io/scrapbook/js/timeago.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css integrity=sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js integrity=sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},]});});</script></main><svg width="0" height="0" class="hidden"><symbol viewBox="0 0 699.428 699.428" xmlns="http://www.w3.org/2000/svg" id="copy"><path d="M502.714.0H240.428C194.178.0 153 42.425 153 87.429l-25.267.59c-46.228.0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249.0 87.428-42.424 87.428-87.428h21.857c46.25.0 87.429-42.424 87.429-87.428v-349.19zM459 655.715H131.143c-22.95.0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95.0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337.0 87.975.0 87.975.0 45.419 40.872 86.882 87.428 86.882H612zm-65.572-349.715c-23.277.0-43.714-42.293-43.714-64.981V44.348L612 174.857zm-43.714 131.537H306c-12.065.0-21.857 9.77-21.857 21.835s9.792 21.835 21.857 21.835h196.714c12.065.0 21.857-9.771 21.857-21.835.0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065.0-21.857 9.77-21.857 21.834.0 12.066 9.792 21.836 21.857 21.836h196.714c12.065.0 21.857-9.77 21.857-21.836.0-12.064-9.792-21.834-21.857-21.834z"/></symbol><symbol viewBox="0 0 60.015 60.015" xmlns="http://www.w3.org/2000/svg" id="reply"><path d="M42.007.0h-24c-9.925.0-18 8.075-18 18v14c0 9.59 7.538 17.452 17 17.973v8.344a1.694 1.694.0 001.699 1.698c.44.0.873-.173 1.198-.498l1.876-1.876C26.708 52.713 33.259 50 40.227 50h1.78c9.925.0 18-8.075 18-18V18c0-9.925-8.075-18-18-18zm16 32c0 8.822-7.178 16-16 16h-1.78c-7.502.0-14.556 2.921-19.86 8.226l-1.359 1.359V44a1 1 0 10-2 0v3.949c-8.356-.52-15-7.465-15-15.949V18c0-8.822 7.178-16 16-16h24c8.822.0 16 7.178 16 16v14z"/></symbol></svg><footer class=footer><div class="footer_inner wrap pale"><p>&copy; <span class=year></span>しさく</p><p>Designed by <a href="<no value>" title="Linkedin Profile"><no value></a></p></div></footer><script src=https://iimuz.github.io/scrapbook/js/index.js></script></body></html>